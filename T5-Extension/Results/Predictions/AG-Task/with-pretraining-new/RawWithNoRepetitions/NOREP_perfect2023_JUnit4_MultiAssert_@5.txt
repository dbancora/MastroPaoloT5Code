************************************
************************************
[+] input: testRejected() { HealthCheckRequest healthCheckRequest = new HealthCheckRequest(); RequestMeta requestMeta = new RequestMeta(); TpsCheckResponse tpsCheckResponse = new TpsCheckResponse(false, 5031, "rejected"); Mockito.when(tpsControlManager.check(any(TpsCheckRequest.class))).thenReturn(tpsCheckResponse); Response filterResponse = tpsControlRequestFilter.filter(healthCheckRequest, requestMeta, HealthCheckRequestHandler.class); Assert."<AssertPlaceHolder>"; Assert.assertEquals(NacosException.OVER_THRESHOLD, filterResponse.getErrorCode()); Assert.assertEquals("Tps Flow restricted:" + tpsCheckResponse.getMessage(), filterResponse.getMessage()); }
filter(Request request, RequestMeta meta, Class handlerClazz) {  Method method; try { method = getHandleMethod(handlerClazz); } catch (NacosException e) { return null; }  if (method.isAnnotationPresent(TpsControl.class) && TpsControlConfig.isTpsControlEnabled()) {  try { TpsControl tpsControl = method.getAnnotation(TpsControl.class); String pointName = tpsControl.pointName(); TpsCheckRequest tpsCheckRequest = null; String parseName = StringUtils.isBlank(tpsControl.name()) ? pointName : tpsControl.name(); RemoteTpsCheckRequestParser parser = RemoteTpsCheckRequestParserRegistry.getParser(parseName); if (parser != null) { tpsCheckRequest = parser.parse(request, meta); } if (tpsCheckRequest == null) { tpsCheckRequest = new TpsCheckRequest(); } if (StringUtils.isBlank(tpsCheckRequest.getPointName())) { tpsCheckRequest.setPointName(pointName); }  initTpsControlManager();  TpsCheckResponse check = tpsControlManager.check(tpsCheckRequest);  if (!check.isSuccess()) { Response response; try { response = super.getDefaultResponseInstance(handlerClazz); response.setErrorInfo(NacosException.OVER_THRESHOLD, "Tps Flow restricted:" + check.getMessage()); return response; } catch (Exception e) { com.alibaba.nacos.plugin.control.Loggers.TPS.warn("Tps check fail , request: {},exception:{}", request.getClass().getSimpleName(), e); return null; }  } } catch (Throwable throwable) { com.alibaba.nacos.plugin.control.Loggers.TPS.warn("Tps check exception , request: {},exception:{}", request.getClass().getSimpleName(), throwable); } }  return null; }
[*] target: assertNotNull(filterResponse)
[-] pred: org. junit. Assert. assertNotNull ( filterResponse )
************************************
************************************
[+] input: EntityStoreException { Superwidget superwidget = new Superwidget() .setId(UUID.randomUUID()) .setName("parent5"); Widget widget2 = new Widget() .setId(UUID.randomUUID()) .setSuperwidgetId(superwidget.getId()) .setName("Test2"); Widget widget3 = new Widget() .setId(UUID.randomUUID()) .setSuperwidgetId(superwidget.getId()) .setName("Test7"); Widget widget2_widget0 = new Widget() .setId(UUID.randomUUID()) .setSuperwidgetId(widget2.getId()) .setName("Test2_A"); Widget widget3_widget0 = new Widget() .setId(UUID.randomUUID()) .setSuperwidgetId(widget3.getId()) .setName("Test7_B"); Widget widget3_widget1 = new Widget() .setId(UUID.randomUUID()) .setSuperwidgetId(widget3.getId()) .setName("Test7_C"); assertEquals(5, subject.putAll(List.of(widget2, widget3, widget2_widget0, widget3_widget0, widget3_widget1)).size());  Collection<Widget> result = subject.getAll(Widget.class, Superwidget.class, List.of(superwidget.getId())); "<AssertPlaceHolder>"; }
size() { return store.size(); }
[*] target: assertEquals(2, result.size())
[-] pred: org. junit. Assert. assertEquals ( 2, result. size ( ) )
************************************
************************************
[+] input: testDecideFailedTask() { WorkflowDef workflowDef = createLinearWorkflow();  WorkflowModel workflow = new WorkflowModel(); workflow.setWorkflowDefinition(workflowDef); workflow.setStatus(WorkflowModel.Status.RUNNING);  TaskModel task = new TaskModel(); task.setTaskType("junit_task_l1"); task.setReferenceTaskName("s1"); task.setSeq(1); task.setRetried(false); task.setExecuted(false); task.setStatus(TaskModel.Status.FAILED);  WorkflowTask workflowTask = new WorkflowTask(); workflowTask.setTaskReferenceName("s1"); workflowTask.setName("junit_task_l1"); workflowTask.setTaskDefinition(new TaskDef("junit_task_l1")); task.setWorkflowTask(workflowTask);  workflow.getTasks().add(task);  DeciderOutcome deciderOutcome = deciderService.decide(workflow); "<AssertPlaceHolder>"; assertFalse(workflow.getTaskByRefName("s1").isExecuted()); assertTrue(workflow.getTaskByRefName("s1").isRetried()); assertEquals(1, deciderOutcome.tasksToBeUpdated.size()); assertEquals("s1", deciderOutcome.tasksToBeUpdated.get(0).getReferenceTaskName()); assertEquals(1, deciderOutcome.tasksToBeScheduled.size()); assertEquals("s1", deciderOutcome.tasksToBeScheduled.get(0).getReferenceTaskName()); assertFalse(deciderOutcome.isComplete); }
decide(WorkflowModel workflow) throws TerminateWorkflowException {  // In case of a new workflow the list of tasks will be empty. final List<TaskModel> tasks = workflow.getTasks(); // Filter the list of tasks and include only tasks that are not executed, // not marked to be skipped and not ready for rerun. // For a new workflow, the list of unprocessedTasks will be empty List<TaskModel> unprocessedTasks = tasks.stream() .filter(t -> !t.getStatus().equals(SKIPPED) && !t.isExecuted()) .collect(Collectors.toList());  List<TaskModel> tasksToBeScheduled = new LinkedList<>(); if (unprocessedTasks.isEmpty()) { // this is the flow that the new workflow will go through tasksToBeScheduled = startWorkflow(workflow); if (tasksToBeScheduled == null) { tasksToBeScheduled = new LinkedList<>(); } } return decide(workflow, tasksToBeScheduled); }
[*] target: assertNotNull(deciderOutcome)
[-] pred: org. junit. Assert. assertNotNull ( deciderOutcome )
************************************
************************************
[+] input: Exception { final DirCache tree0 = db.readDirCache(); final DirCache tree1 = db.readDirCache(); { final DirCacheBuilder b0 = tree0.builder(); final DirCacheBuilder b1 = tree1.builder();  b0.add(createEntry("a", REGULAR_FILE)); b0.add(createEntry("a.b", EXECUTABLE_FILE)); b1.add(createEntry("a/b", REGULAR_FILE)); b0.add(createEntry("a0b", SYMLINK));  b0.finish(); b1.finish(); assertEquals(3, tree0.getEntryCount()); assertEquals(1, tree1.getEntryCount()); }  try (NameConflictTreeWalk tw = new NameConflictTreeWalk(db)) { tw.addTree(new DirCacheIterator(tree0)); tw.addTree(new DirCacheIterator(tree1));  assertModes("a", REGULAR_FILE, TREE, tw); assertTrue(tw.isDirectoryFileConflict()); assertTrue(tw.isSubtree()); tw.enterSubtree(); assertModes("a/b", MISSING, REGULAR_FILE, tw); assertTrue(tw.isDirectoryFileConflict()); assertModes("a.b", EXECUTABLE_FILE, MISSING, tw); assertFalse(tw.isDirectoryFileConflict()); assertModes("a0b", SYMLINK, MISSING, tw); "<AssertPlaceHolder>"; } }
isDirectoryFileConflict() { return dfConflict != null; }
[*] target: assertFalse(tw.isDirectoryFileConflict())
[-] pred: org. junit. Assert. assertFalse ( tw. isDirectoryFileConflict() )
************************************
************************************
[+] input: testGetAllWorkflowDefsLatestVersions() { WorkflowDef def = new WorkflowDef(); def.setName("test1"); def.setVersion(1); def.setDescription("description"); def.setCreatedBy("unit_test"); def.setCreateTime(1L); def.setOwnerApp("ownerApp"); def.setUpdatedBy("unit_test2"); def.setUpdateTime(2L); metadataDAO.createWorkflowDef(def);  def.setName("test2"); metadataDAO.createWorkflowDef(def); def.setVersion(2); metadataDAO.createWorkflowDef(def);  def.setName("test3"); def.setVersion(1); metadataDAO.createWorkflowDef(def); def.setVersion(2); metadataDAO.createWorkflowDef(def); def.setVersion(3); metadataDAO.createWorkflowDef(def);  // Placed the values in a map because they might not be stored in order of defName. // To test, needed to confirm that the versions are correct for the definitions. Map<String, WorkflowDef> allMap = metadataDAO.getAllWorkflowDefsLatestVersions().stream() .collect(Collectors.toMap(WorkflowDef::getName, Function.identity()));  "<AssertPlaceHolder>"; assertEquals(4, allMap.size()); assertEquals(1, allMap.get("test1").getVersion()); assertEquals(2, allMap.get("test2").getVersion()); assertEquals(3, allMap.get("test3").getVersion()); }
getAllWorkflowDefsLatestVersions() { final String GET_ALL_WORKFLOW_DEF_LATEST_VERSIONS_QUERY = "SELECT json_data FROM meta_workflow_def wd WHERE wd.version = (SELECT MAX(version) FROM meta_workflow_def wd2 WHERE wd2.name = wd.name)"; return queryWithTransaction( GET_ALL_WORKFLOW_DEF_LATEST_VERSIONS_QUERY, q -> q.executeAndFetch(WorkflowDef.class)); }
[*] target: assertNotNull(allMap)
[-] pred: org. junit. Assert. assertNotNull ( allMap )
************************************
************************************
[+] input: test_next() { output.authorizerPresent(); output.nextExtensionOrDefault(); task.onSuccess(output);  channel.runPendingTasks();  final AuthorizeWillResultEvent resultEvent = eventsCollector.pollEvent(); "<AssertPlaceHolder>"; assertTrue(resultEvent.getResult().isAuthorizerPresent()); assertNull(resultEvent.getResult().getAckReasonCode()); assertNull(resultEvent.getResult().getReasonString()); }
onSuccess(@Nullable final PublishAuthorizerOutputImpl output) { if (output == null) { //this does not happen return; }  DisconnectReasonCode disconnectReasonCode = null; AckReasonCode reasonCode = null; String reasonString = null;  switch (output.getAuthorizationState()) { case DISCONNECT: disconnectReasonCode = output.getDisconnectReasonCode(); reasonCode = output.getAckReasonCode() != null ? output.getAckReasonCode() : AckReasonCode.NOT_AUTHORIZED; reasonString = output.getReasonString() != null ? output.getReasonString() : getReasonString(connect); break; case FAIL: reasonCode = output.getAckReasonCode() != null ? output.getAckReasonCode() : AckReasonCode.NOT_AUTHORIZED; reasonString = output.getReasonString() != null ? output.getReasonString() : getReasonString(connect); break; case UNDECIDED: if (!output.isAuthorizerPresent()) { //providers never returned an authorizer, same as continue break; } reasonCode = AckReasonCode.NOT_AUTHORIZED; reasonString = getReasonString(connect); break; case SUCCESS: reasonCode = AckReasonCode.SUCCESS; break; case CONTINUE: break; default: //no state left throw new IllegalStateException("Unknown type"); }  final PublishAuthorizerResult result = new PublishAuthorizerResult(reasonCode, reasonString, output.isAuthorizerPresent(), disconnectReasonCode); ctx.pipeline().fireUserEventTriggered(new PluginAuthorizerServiceImpl.AuthorizeWillResultEvent(connect, result)); }
[*] target: assertNotNull(resultEvent)
[-] pred: org. junit. Assert. assertNotNull ( resultEvent )
************************************
************************************
[+] input: testFastIterator() { BlockList<Integer> list = new BlockList<>(4); int cnt = BlockList.BLOCK_SIZE * 3;  for (int i = 0; i < cnt; i++) list.add(Integer.valueOf(42 + i)); assertEquals(cnt, list.size());  Iterator<Integer> itr = list.iterator(); for (int i = 0; i < cnt; i++) { assertTrue(itr.hasNext()); assertEquals(Integer.valueOf(42 + i), itr.next()); } "<AssertPlaceHolder>"; }
hasNext() { return index < size; }
[*] target: assertFalse(itr.hasNext())
[-] pred: org. junit. Assert. assertFalse ( itr. hasNext() )
************************************
************************************
[+] input: testExceedsChainLength_DuringScanOfA() { HistogramDiff hd = new HistogramDiff(); hd.setFallbackAlgorithm(null); hd.setMaxChainLength(3);  SequenceComparator<RawText> cmp = new SequenceComparator<>() {  @Override public boolean equals(RawText a, int ai, RawText b, int bi) { return RawTextComparator.DEFAULT.equals(a, ai, b, bi); }  @Override public int hash(RawText a, int ai) { return 1; } };  EditList r = hd.diff(cmp, t("RabS"), t("QabT")); "<AssertPlaceHolder>"; assertEquals(new Edit(0, 4, 0, 4), r.get(0)); }
setMaxChainLength(int maxLen) { maxChainLength = maxLen; }
[*] target: assertEquals(1, r.size())
[-] pred: org. junit. Assert. assertEquals ( 1, r. size ( ) )
************************************
************************************
[+] input: Exception { StartWorkflow startWorkflow = new StartWorkflow(); startWorkflow.setName("testWorkflow"); startWorkflow.getInput().put("testInput", "${testId}"); startWorkflow.setCorrelationId("${correlationId}");  Map<String, String> taskToDomain = new HashMap<>(); taskToDomain.put("*", "dev"); startWorkflow.setTaskToDomain(taskToDomain);  Action action = new Action(); action.setAction(Type.start_workflow); action.setStart_workflow(startWorkflow);  Object payload = objectMapper.readValue( "{"correlationId":"test-id", "testId":"test_1"}", Object.class);  WorkflowDef workflowDef = new WorkflowDef(); workflowDef.setName("testWorkflow"); workflowDef.setVersion(1);  when(workflowExecutor.startWorkflow(any())).thenReturn("workflow_1");  Map<String, Object> output = actionProcessor.execute(action, payload, "testEvent", "testMessage");  "<AssertPlaceHolder>"; assertEquals("workflow_1", output.get("workflowId"));  ArgumentCaptor<StartWorkflowInput> startWorkflowInputArgumentCaptor = ArgumentCaptor.forClass(StartWorkflowInput.class);  verify(workflowExecutor).startWorkflow(startWorkflowInputArgumentCaptor.capture()); StartWorkflowInput capturedValue = startWorkflowInputArgumentCaptor.getValue();  assertEquals("test_1", capturedValue.getWorkflowInput().get("testInput")); assertEquals("test-id", capturedValue.getCorrelationId()); assertEquals( "testMessage", capturedValue.getWorkflowInput().get("conductor.event.messageId")); assertEquals("testEvent", capturedValue.getWorkflowInput().get("conductor.event.name")); assertEquals(taskToDomain, capturedValue.getTaskToDomain()); }
execute( Action action, Object payloadObject, String event, String messageId) {  LOGGER.debug( "Executing action: {} for event: {} with messageId:{}", action.getAction(), event, messageId);  Object jsonObject = payloadObject; if (action.isExpandInlineJSON()) { jsonObject = jsonUtils.expand(payloadObject); }  switch (action.getAction()) { case start_workflow: return startWorkflow(action, jsonObject, event, messageId); case complete_task: return completeTask( action, jsonObject, action.getComplete_task(), TaskModel.Status.COMPLETED, event, messageId); case fail_task: return completeTask( action, jsonObject, action.getFail_task(), TaskModel.Status.FAILED, event, messageId); default: break; } throw new UnsupportedOperationException( "Action not supported " + action.getAction() + " for event " + event); }
[*] target: assertNotNull(output)
[-] pred: org. junit. Assert. assertNotNull ( output )
************************************
************************************
[+] input: shouldIterateBackwardOverAllSegments() { iterator = new SegmentIterator<>( Arrays.asList(segmentTwo, segmentOne).iterator(), //store should pass the segments in the right order hasNextCondition, Bytes.wrap("a".getBytes()), Bytes.wrap("z".getBytes()), false);  assertTrue(iterator.hasNext()); assertEquals("d", new String(iterator.peekNextKey().get())); assertEquals(KeyValue.pair("d", "4"), toStringKeyValue(iterator.next()));  assertTrue(iterator.hasNext()); assertEquals("c", new String(iterator.peekNextKey().get())); assertEquals(KeyValue.pair("c", "3"), toStringKeyValue(iterator.next()));  assertTrue(iterator.hasNext()); assertEquals("b", new String(iterator.peekNextKey().get())); assertEquals(KeyValue.pair("b", "2"), toStringKeyValue(iterator.next()));  assertTrue(iterator.hasNext()); assertEquals("a", new String(iterator.peekNextKey().get())); assertEquals(KeyValue.pair("a", "1"), toStringKeyValue(iterator.next()));  "<AssertPlaceHolder>"; }
hasNext() { boolean hasNext = false; while ((currentIterator == null || !(hasNext = hasNextConditionHasNext()) || !currentSegment.isOpen()) && segments.hasNext()) { close(); currentSegment = segments.next(); try { if (forward) { currentIterator = currentSegment.range(from, to); } else { currentIterator = currentSegment.reverseRange(from, to); } } catch (final InvalidStateStoreException e) { // segment may have been closed so we ignore it. } } return currentIterator != null && hasNext; }
[*] target: assertFalse(iterator.hasNext())
[-] pred: org. junit. Assert. assertFalse ( iterator. hasNext ( ) )
************************************
************************************
[+] input: shouldFindTask() { TaskSummary taskSummary = TestUtils.loadTaskSnapshot(objectMapper, "task_summary"); indexDAO.indexTask(taskSummary);  List<TaskSummary> tasks = tryFindResults(() -> searchTaskSummary(taskSummary)); "<AssertPlaceHolder>"; assertEquals(taskSummary, tasks.get(0)); }
indexTask(TaskSummary task) { try { long startTime = Instant.now().toEpochMilli(); String taskId = task.getTaskId(); String docType = StringUtils.isBlank(docTypeOverride) ? TASK_DOC_TYPE : docTypeOverride;  indexObject(taskIndexName, docType, taskId, task); long endTime = Instant.now().toEpochMilli(); LOGGER.debug( "Time taken {} for  indexing task:{} in workflow: {}", endTime - startTime, taskId, task.getWorkflowId()); Monitors.recordESIndexTime("index_task", TASK_DOC_TYPE, endTime - startTime); Monitors.recordWorkerQueueSize( "indexQueue", ((ThreadPoolExecutor) executorService).getQueue().size()); } catch (Exception e) { LOGGER.error("Failed to index task: {}", task.getTaskId(), e); } }
[*] target: assertEquals(1, tasks.size())
[-] pred: org. junit. Assert. assertEquals ( 1, tasks. size ( ) )
************************************
************************************
[+] input: shouldNotAbortBatchRepeatedly() { context.abortTransaction(); assertTrue(context.shouldAbortBatch()); "<AssertPlaceHolder>"; }
shouldAbortBatch() { checkBatchRequestsConsistency(); boolean result = batchAbortRequested; batchAbortRequested = false; return result; }
[*] target: assertFalse(context.shouldAbortBatch())
[-] pred: org. junit. Assert. assertFalse ( context. shouldAbortBatch() )
************************************
************************************
[+] input: combinationTest2() { List<List<Integer>> lists = Lists.newArrayList( Lists.newArrayList(1, 2, 2), Lists.newArrayList(21, 22), Lists.newArrayList(31, 32)); int resultCount = 1; for (List<Integer> list : lists) { resultCount *= list.size(); } CombinationIterator<Integer> it = new CombinationIterator<>(lists); for (int i = 0; i < resultCount; ++i) { List<Integer> combination = it.next(); System.out.println(combination); Assert.assertEquals(3, combination.size()); if (1 == i) { Assert.assertEquals(1, (int) combination.get(0)); Assert.assertEquals(21, (int) combination.get(1)); Assert.assertEquals(32, (int) combination.get(2)); } } Assert."<AssertPlaceHolder>"; }
hasNext() { while (!iteratorStack.isEmpty()) { Iterator<T> peekIt = iteratorStack.peek(); if (peekIt.hasNext()) { resultStack.push(peekIt.next()); if (resultStack.size() == lists.size()) { return true; } initIteratorStack(); continue; } if (1 == iteratorStack.size()) { return false; } iteratorStack.pop(); resultStack.pop(); } return false; }
[*] target: assertFalse(it.hasNext())
[-] pred: org. junit. Assert. assertFalse ( it. hasNext() )
************************************
************************************
[+] input: testClearMethod() { IndexedLinkedPageList pages = new IndexedLinkedPageList(); for (int i = 0; i < 10; i++) { Assert.assertTrue(pages.add(Page.emptyPage(i))); } pages.clear(); Assert."<AssertPlaceHolder>"; }
getLast() { if (this.elementCounter.get() == 0) { return null; } return this.lastNode.getContent(); }
[*] target: assertNull(pages.getLast())
[-] pred: org. junit. Assert. assertNull ( pages. getLast() )
************************************
************************************
[+] input: Exception { final ByteBuf byteBuf = Bytes.prefixBytes(new byte[0], Unpooled.buffer()); final int size = byteBuf.readUnsignedShort();  "<AssertPlaceHolder>"; assertEquals(false, byteBuf.isReadable()); }
prefixBytes(final byte[] bytes, final ByteBuf buffer) { checkNotNull(bytes); checkNotNull(buffer);  buffer.writeShort(bytes.length); buffer.writeBytes(bytes);  return buffer; }
[*] target: assertEquals(0, size)
[-] pred: org. junit. Assert. assertEquals ( 0, size )
************************************
************************************
[+] input: shouldReturnKeyValueStore() { final GlobalStateStoreProvider provider = new GlobalStateStoreProvider(stores); final List<ReadOnlyKeyValueStore<String, String>> stores = provider.stores("kv-store", QueryableStoreTypes.keyValueStore()); "<AssertPlaceHolder>"; for (final ReadOnlyKeyValueStore<String, String> store : stores) { assertThat(store, instanceOf(ReadOnlyKeyValueStore.class)); assertThat(store, not(instanceOf(TimestampedKeyValueStore.class))); } }
stores(final String storeName, final QueryableStoreType<T> queryableStoreType) { final StateStore store = globalStateStores.get(storeName); if (store == null || !queryableStoreType.accepts(store)) { return Collections.emptyList(); } if (!store.isOpen()) { throw new InvalidStateStoreException("the state store, " + storeName + ", is not open."); } if (store instanceof TimestampedKeyValueStore && queryableStoreType instanceof QueryableStoreTypes.KeyValueStoreType) { return (List<T>) Collections.singletonList(new ReadOnlyKeyValueStoreFacade((TimestampedKeyValueStore<Object, Object>) store)); } else if (store instanceof TimestampedWindowStore && queryableStoreType instanceof QueryableStoreTypes.WindowStoreType) { return (List<T>) Collections.singletonList(new ReadOnlyWindowStoreFacade((TimestampedWindowStore<Object, Object>) store)); } return (List<T>) Collections.singletonList(store); }
[*] target: assertEquals(1, stores.size())
[-] pred: org. junit. Assert. assertEquals ( 1, stores. size ( ) )
************************************
************************************
[+] input: test_get_tls_no_cert() { clientConnection.setAuthCipherSuite("cipher"); clientConnection.setAuthProtocol("TLSv1.2");  final ClientTlsInformation clientTlsInformation = ExtensionInformationUtil.getTlsInformationFromChannel(channel); "<AssertPlaceHolder>"; assertEquals("cipher", clientTlsInformation.getCipherSuite()); assertEquals("TLSv1.2", clientTlsInformation.getProtocol()); assertTrue(clientTlsInformation.getHostname().isEmpty()); assertTrue(clientTlsInformation.getClientCertificate().isEmpty()); }
getTlsInformationFromChannel(final @NotNull Channel channel) {  Preconditions.checkNotNull(channel, "channel must never be null");  final ClientConnection clientConnection = channel.attr(ClientConnection.CHANNEL_ATTRIBUTE_NAME).get(); try { final String cipher = clientConnection.getAuthCipherSuite(); final String protocol = clientConnection.getAuthProtocol(); final String sniHostname = clientConnection.getAuthSniHostname();  final SslClientCertificate sslClientCertificate = clientConnection.getAuthCertificate();  if (cipher == null || protocol == null) { return null; }  if (sslClientCertificate == null) { return new ClientTlsInformationImpl(null, null, cipher, protocol, sniHostname);  } else { final X509Certificate certificate = (X509Certificate) sslClientCertificate.certificate(); final X509Certificate[] certificateChain = (X509Certificate[]) sslClientCertificate.certificateChain();  return new ClientTlsInformationImpl(certificate, certificateChain, cipher, protocol, sniHostname); }  } catch (final Exception e) { log.debug("Tls information creation failed: ", e); }  return null; }
[*] target: assertNotNull(clientTlsInformation)
[-] pred: org. junit. Assert. assertNotNull ( clientTlsInformation )
************************************
************************************
[+] input: Exception { // three topics final CountDownLatch authorizeLatch1 = new CountDownLatch(1); final CountDownLatch authorizeLatch2 = new CountDownLatch(1);  when(authorizers.areAuthorizersAvailable()).thenReturn(true); when(authorizers.getAuthorizerProviderMap()).thenReturn(createPublishAuthorizerMap(authorizeLatch1, authorizeLatch2));  final PUBLISH publish = TestMessageUtil.createMqtt5Publish("topic", QoS.AT_LEAST_ONCE);  channel.attr(ClientConnection.CHANNEL_ATTRIBUTE_NAME).get().setIncomingPublishesSkipRest(true);  pluginAuthorizerService.authorizePublish(channelHandlerContext, publish);  await().pollInterval(Duration.ofMillis(100)).until(() -> { final ClientAuthorizers extensionClientAuthorizers = channel.attr(ClientConnection.CHANNEL_ATTRIBUTE_NAME).get().getExtensionClientAuthorizers(); "<AssertPlaceHolder>"; if (extensionClientAuthorizers.getPublishAuthorizersMap().size() != 1) { channel.runPendingTasks(); channel.runScheduledPendingTasks(); return false; } return true; });  assertFalse(authorizeLatch1.await(1, TimeUnit.SECONDS)); assertFalse(authorizeLatch2.await(0, TimeUnit.SECONDS));  final ClientAuthorizers extensionClientAuthorizers = channel.attr(ClientConnection.CHANNEL_ATTRIBUTE_NAME).get().getExtensionClientAuthorizers(); assertNotNull(extensionClientAuthorizers); assertEquals(1, extensionClientAuthorizers.getPublishAuthorizersMap().size()); }
authorizePublish(final @NotNull ChannelHandlerContext ctx, final @NotNull PUBLISH msg) {  //We first check if the topic is allowed to be published if (!Topics.isValidTopicToPublish(msg.getTopic())) { disconnectWithReasonCode(ctx, "an invalid topic ('" + msg.getTopic() + "')", "an invalid topic"); return; }  // if $ topics are not allowed if (!allowDollarTopics && Topics.isDollarTopic(msg.getTopic())) { final String reason = "a topic that starts with '$'"; disconnectWithReasonCode(ctx, reason + " ('" + msg.getTopic() + "')", reason); return; }   final String clientId = ctx.channel().attr(ClientConnection.CHANNEL_ATTRIBUTE_NAME).get().getClientId();  if (clientId == null) { //we must process the msg in every case ! incomingPublishService.processPublish(ctx, msg, null); return; }  if (!authorizers.areAuthorizersAvailable()) { incomingPublishService.processPublish(ctx, msg, null); return; }  final Map<String, AuthorizerProvider> providerMap = authorizers.getAuthorizerProviderMap(); if (providerMap.isEmpty()) { incomingPublishService.processPublish(ctx, msg, null); return; }  final ClientAuthorizers clientAuthorizers = getClientAuthorizers(ctx);  final AuthorizerProviderInput authorizerProviderInput = new AuthorizerProviderInputImpl(ctx.channel(), serverInformation, clientId);  final PublishAuthorizerInputImpl input = new PublishAuthorizerInputImpl(msg, ctx.channel(), clientId); final PublishAuthorizerOutputImpl output = new PublishAuthorizerOutputImpl(asyncer);  final SettableFuture<PublishAuthorizerOutputImpl> publishProcessedFuture = executePublishAuthorizer(clientId, providerMap, clientAuthorizers, authorizerProviderInput, input, output, ctx);  Futures.addCallback( publishProcessedFuture, new PublishAuthorizationProcessedTask(msg, ctx, mqttServerDisconnector, incomingPublishService), MoreExecutors.directExecutor()); }
[*] target: assertNotNull(extensionClientAuthorizers)
[-] pred: org. junit. Assert. assertNotNull ( extensionClientAuthorizers )
************************************
************************************
[+] input: findFirstNonLoopbackAddress() { InetAddress address = InetUtils.findFirstNonLoopbackAddress();  Assert."<AssertPlaceHolder>"; Assert.assertFalse(address.isLoopbackAddress()); }
findFirstNonLoopbackAddress() { InetAddress result = null;  try { int lowest = Integer.MAX_VALUE; for (Enumeration<NetworkInterface> nics = NetworkInterface.getNetworkInterfaces(); nics.hasMoreElements(); ) { NetworkInterface ifc = nics.nextElement(); if (ifc.isUp()) { LOG.debug("Testing interface: " + ifc.getDisplayName()); if (ifc.getIndex() < lowest || result == null) { lowest = ifc.getIndex(); } else { continue; }  if (!ignoreInterface(ifc.getDisplayName())) { for (Enumeration<InetAddress> addrs = ifc.getInetAddresses(); addrs.hasMoreElements(); ) { InetAddress address = addrs.nextElement(); boolean isLegalIpVersion = InternetAddressUtil.PREFER_IPV6_ADDRESSES ? address instanceof Inet6Address : address instanceof Inet4Address; if (isLegalIpVersion && !address.isLoopbackAddress() && isPreferredAddress(address)) { LOG.debug("Found non-loopback interface: " + ifc.getDisplayName()); result = address; } } } } } } catch (IOException ex) { LOG.error("Cannot get first non-loopback address", ex); }  if (result != null) { return result; }  try { return InetAddress.getLocalHost(); } catch (UnknownHostException e) { LOG.error("Unable to retrieve localhost", e); }  return null; }
[*] target: assertNotNull(address)
[-] pred: org. junit. Assert. assertNotNull ( address )
************************************
************************************
[+] input: testParseModeChange() { final FileHeader fh = data("diff --git a/a b b/a b\n" + "old mode 100644\n" + "new mode 100755\n"); assertParse(fh); assertEquals("a b", fh.getOldPath()); assertEquals("a b", fh.getNewPath());  assertSame(FileHeader.ChangeType.MODIFY, fh.getChangeType()); assertSame(FileHeader.PatchType.UNIFIED, fh.getPatchType()); "<AssertPlaceHolder>";  assertNull(fh.getOldId()); assertNull(fh.getNewId());  assertSame(FileMode.REGULAR_FILE, fh.getOldMode()); assertSame(FileMode.EXECUTABLE_FILE, fh.getNewMode()); assertEquals(0, fh.getScore()); }
hasMetaDataChanges() { return changeType != ChangeType.MODIFY || newMode != oldMode; }
[*] target: assertTrue(fh.hasMetaDataChanges())
[-] pred: org. junit. Assert. assertTrue ( fh. hasMetaDataChanges() )
************************************
************************************
[+] input: test_fail() { output.authorizerPresent(); output.failAuthorization(); task.onSuccess(output);  channel.runPendingTasks();  final AuthorizeWillResultEvent resultEvent = eventsCollector.pollEvent(); "<AssertPlaceHolder>"; assertEquals(AckReasonCode.NOT_AUTHORIZED, resultEvent.getResult().getAckReasonCode()); assertEquals( "Not allowed to connect with Will Publish for unauthorized topic 'topic' with QoS '2' and retain 'false'", resultEvent.getResult().getReasonString()); }
onSuccess(@Nullable final PublishAuthorizerOutputImpl output) { if (output == null) { //this does not happen return; }  DisconnectReasonCode disconnectReasonCode = null; AckReasonCode reasonCode = null; String reasonString = null;  switch (output.getAuthorizationState()) { case DISCONNECT: disconnectReasonCode = output.getDisconnectReasonCode(); reasonCode = output.getAckReasonCode() != null ? output.getAckReasonCode() : AckReasonCode.NOT_AUTHORIZED; reasonString = output.getReasonString() != null ? output.getReasonString() : getReasonString(connect); break; case FAIL: reasonCode = output.getAckReasonCode() != null ? output.getAckReasonCode() : AckReasonCode.NOT_AUTHORIZED; reasonString = output.getReasonString() != null ? output.getReasonString() : getReasonString(connect); break; case UNDECIDED: if (!output.isAuthorizerPresent()) { //providers never returned an authorizer, same as continue break; } reasonCode = AckReasonCode.NOT_AUTHORIZED; reasonString = getReasonString(connect); break; case SUCCESS: reasonCode = AckReasonCode.SUCCESS; break; case CONTINUE: break; default: //no state left throw new IllegalStateException("Unknown type"); }  final PublishAuthorizerResult result = new PublishAuthorizerResult(reasonCode, reasonString, output.isAuthorizerPresent(), disconnectReasonCode); ctx.pipeline().fireUserEventTriggered(new PluginAuthorizerServiceImpl.AuthorizeWillResultEvent(connect, result)); }
[*] target: assertNotNull(resultEvent)
[-] pred: org. junit. Assert. assertNotNull ( resultEvent )
************************************
************************************
[+] input: test_queue_size_modified() { assertNull(clientSettings.getQueueSizeMaximum()); clientSettings.setClientQueueSizeMaximum(123L); assertEquals(123L, clientSettings.getQueueSizeMaximum().longValue()); "<AssertPlaceHolder>"; }
isModified() { return modified; }
[*] target: assertTrue(clientSettings.isModified())
[-] pred: org. junit. Assert. assertTrue ( clientSettings. isModified() )
************************************
************************************
[+] input: testRemovePage() { IndexedLinkedPageList pages = new IndexedLinkedPageList(); for (int i = 0; i < 10; i++) { Assert.assertTrue(pages.add(Page.emptyPage(i))); } Assert.assertTrue(pages.remove(Page.emptyPage(3))); Assert."<AssertPlaceHolder>"; int counter = 0; for (Page page : pages) { counter++; Assert.assertNotEquals(3, page.getPhysicalPageId()); } Assert.assertEquals(9, counter); }
size() { return this.elementCounter.get(); }
[*] target: assertEquals(9, pages.size())
[-] pred: org. junit. Assert. assertEquals ( 9, pages. size() )
************************************
************************************
[+] input: testDecideWithLoopTask() { WorkflowDef workflowDef = createLinearWorkflow();  WorkflowModel workflow = new WorkflowModel(); workflow.setWorkflowDefinition(workflowDef); workflow.setStatus(WorkflowModel.Status.RUNNING);  TaskModel task1 = new TaskModel(); task1.setTaskType("junit_task_l1"); task1.setReferenceTaskName("s1"); task1.setSeq(1); task1.setIteration(1); task1.setRetried(false); task1.setExecuted(false); task1.setStatus(TaskModel.Status.COMPLETED);  workflow.getTasks().add(task1);  DeciderOutcome deciderOutcome = deciderService.decide(workflow); "<AssertPlaceHolder>";  assertFalse(workflow.getTaskByRefName("s1").isRetried()); assertEquals(1, deciderOutcome.tasksToBeUpdated.size()); assertEquals("s1", deciderOutcome.tasksToBeUpdated.get(0).getReferenceTaskName()); assertEquals(1, deciderOutcome.tasksToBeScheduled.size()); assertEquals("s2__1", deciderOutcome.tasksToBeScheduled.get(0).getReferenceTaskName()); assertFalse(deciderOutcome.isComplete); }
decide(WorkflowModel workflow) throws TerminateWorkflowException {  // In case of a new workflow the list of tasks will be empty. final List<TaskModel> tasks = workflow.getTasks(); // Filter the list of tasks and include only tasks that are not executed, // not marked to be skipped and not ready for rerun. // For a new workflow, the list of unprocessedTasks will be empty List<TaskModel> unprocessedTasks = tasks.stream() .filter(t -> !t.getStatus().equals(SKIPPED) && !t.isExecuted()) .collect(Collectors.toList());  List<TaskModel> tasksToBeScheduled = new LinkedList<>(); if (unprocessedTasks.isEmpty()) { // this is the flow that the new workflow will go through tasksToBeScheduled = startWorkflow(workflow); if (tasksToBeScheduled == null) { tasksToBeScheduled = new LinkedList<>(); } } return decide(workflow, tasksToBeScheduled); }
[*] target: assertNotNull(deciderOutcome)
[-] pred: org. junit. Assert. assertNotNull ( deciderOutcome )
************************************
************************************
[+] input: testMarkAndUnMark() { BitMap bitmap = new BitMap(100); assertEquals(100, bitmap.getSize()); assertTrue(bitmap.isAllUnmarked()); assertFalse(bitmap.isAllMarked()); for (int i = 0; i < 100; i++) { bitmap.mark(i); assertTrue(bitmap.isMarked(i)); if (i == 50) { assertFalse(bitmap.isAllMarked()); assertFalse(bitmap.isAllUnmarked()); } } assertTrue(bitmap.isAllMarked()); assertFalse(bitmap.isAllUnmarked()); for (int i = 0; i < 100; i++) { bitmap.unmark(i); assertFalse(bitmap.isMarked(i)); } assertTrue(bitmap.isAllUnmarked()); "<AssertPlaceHolder>"; }
isAllMarked() { int j; for (j = 0; j < size / Byte.SIZE; j++) { if (bits[j] != (byte) 0XFF) { return false; } } for (j = 0; j < size % Byte.SIZE; j++) { if ((bits[size / Byte.SIZE] & BIT_UTIL[j]) == 0) { return false; } } return true; }
[*] target: assertFalse(bitmap.isAllMarked())
[-] pred: org. junit. Assert. assertFalse ( bitmap. isAllMarked() )
************************************
************************************
[+] input: shouldEnableRackAwareAssignorWithStandbyDescribingTopics() { final MockInternalTopicManager spyTopicManager = spy(mockInternalTopicManager); doReturn( Collections.singletonMap( TP_0_NAME, Collections.singletonList( new TopicPartitionInfo(0, NODE_0, Arrays.asList(REPLICA_1), Collections.emptyList()) ) ) ).when(spyTopicManager).getTopicPartitionInfo(Collections.singleton(TP_0_NAME));  doReturn( Collections.singletonMap( CHANGELOG_TP_0_NAME, Collections.singletonList( new TopicPartitionInfo(0, NODE_0, Arrays.asList(REPLICA_1), Collections.emptyList()) ) ) ).when(spyTopicManager).getTopicPartitionInfo(Collections.singleton(CHANGELOG_TP_0_NAME));  final RackAwareTaskAssignor assignor = spy(new RackAwareTaskAssignor( getClusterWithNoNode(), getTaskTopicPartitionMapForTask0(), getTaskChangeLogTopicPartitionMapForTask0(), getTopologyGroupTaskMap(), getProcessRacksForProcess0(), spyTopicManager, getRackAwareEnabledConfigWithStandby(1), time ));  assertTrue(assignor.canEnableRackAwareAssignor()); verify(assignor, times(1)).populateTopicsToDescribe(anySet(), eq(false)); verify(assignor, times(1)).populateTopicsToDescribe(anySet(), eq(true));  final Map<TopicPartition, Set<String>> racksForPartition = assignor.racksForPartition(); final Map<TopicPartition, Set<String>> expected = mkMap( mkEntry(TP_0_0, mkSet(RACK_1, RACK_2)), mkEntry(CHANGELOG_TP_0_0, mkSet(RACK_1, RACK_2)) ); "<AssertPlaceHolder>"; }
racksForPartition() { return Collections.unmodifiableMap(racksForPartition); }
[*] target: assertEquals(expected, racksForPartition)
[-] pred: org. junit. Assert. assertEquals ( expected, racksForPartition )
************************************
************************************
[+] input: testServerInfoSet() { RpcClient.ServerInfo serverInfo = new RpcClient.ServerInfo(); String ip = "127.0.0.1"; int port = 80; serverInfo.setServerIp(ip); serverInfo.setServerPort(port); assertEquals("127.0.0.1:80", serverInfo.getAddress()); assertEquals(port, serverInfo.getServerPort()); assertEquals(ip, serverInfo.getServerIp()); String expected = "{serverIp = '127.0.0.1', server main port = 80}"; "<AssertPlaceHolder>"; }
toString() { return "{serverIp = '" + serverIp + ''' + ", server main port = " + serverPort + '}'; }
[*] target: assertEquals(expected, serverInfo.toString())
[-] pred: org. junit. Assert. assertEquals ( expected, serverInfo. toString ( ) )
************************************
************************************
[+] input: findByIdAndProjectId_getTemplate_succeed() { DatabaseChangeChangingOrderTemplateEntity databaseChangeChangingOrderTemplateEntity = create(); Optional<DatabaseChangeChangingOrderTemplateEntity> result = templateRepository.findByIdAndProjectId(databaseChangeChangingOrderTemplateEntity.getId(), PROJECT_ID); DatabaseChangeChangingOrderTemplateEntity templateEntity = result.get(); "<AssertPlaceHolder>"; assertEquals(databaseChangeChangingOrderTemplateEntity, templateEntity); }
findByIdAndProjectId(Long id, Long projectId);
[*] target: assertNotNull(templateEntity)
[-] pred: org. junit. Assert. assertNotNull ( templateEntity )
************************************
************************************
[+] input: shouldReturnTimestampedKeyValueStoreAsKeyValueStore() { final GlobalStateStoreProvider provider = new GlobalStateStoreProvider(stores); final List<ReadOnlyKeyValueStore<String, ValueAndTimestamp<String>>> stores = provider.stores("ts-kv-store", QueryableStoreTypes.keyValueStore()); "<AssertPlaceHolder>"; for (final ReadOnlyKeyValueStore<String, ValueAndTimestamp<String>> store : stores) { assertThat(store, instanceOf(ReadOnlyKeyValueStore.class)); assertThat(store, not(instanceOf(TimestampedKeyValueStore.class))); } }
stores(final String storeName, final QueryableStoreType<T> queryableStoreType) { final StateStore store = globalStateStores.get(storeName); if (store == null || !queryableStoreType.accepts(store)) { return Collections.emptyList(); } if (!store.isOpen()) { throw new InvalidStateStoreException("the state store, " + storeName + ", is not open."); } if (store instanceof TimestampedKeyValueStore && queryableStoreType instanceof QueryableStoreTypes.KeyValueStoreType) { return (List<T>) Collections.singletonList(new ReadOnlyKeyValueStoreFacade((TimestampedKeyValueStore<Object, Object>) store)); } else if (store instanceof TimestampedWindowStore && queryableStoreType instanceof QueryableStoreTypes.WindowStoreType) { return (List<T>) Collections.singletonList(new ReadOnlyWindowStoreFacade((TimestampedWindowStore<Object, Object>) store)); } return (List<T>) Collections.singletonList(store); }
[*] target: assertEquals(1, stores.size())
[-] pred: org. junit. Assert. assertEquals ( 1, stores. size ( ) )
************************************
************************************
[+] input: test_AES256_BASE64() { String raw = RandomStringUtils.random(256); Encryption encryption = createEncryption(EncryptionAlgorithm.AES256_BASE64); String encrypted = EncryptionUtil.encrypt(raw, encryption); Assert.assertNotEquals(raw, encrypted); String decrypted = EncryptionUtil.decrypt(encrypted, encryption); Assert."<AssertPlaceHolder>"; }
decrypt(String encryptedText, Encryption encryption) { return Objects.requireNonNull(encryptorCache.get(encryption)).decrypt(encryptedText); }
[*] target: assertEquals(raw, decrypted)
[-] pred: org. junit. Assert. assertEquals ( raw, decrypted )
************************************
************************************
[+] input: testGetSubscribedService() { Collection<Service> subscribedService = clientServiceIndexesManager.getSubscribedService();  Assert."<AssertPlaceHolder>"; Assert.assertEquals(subscribedService.size(), 1); }
getSubscribedService() { return subscriberIndexes.keySet(); }
[*] target: assertNotNull(subscribedService)
[-] pred: org. junit. Assert. assertNotNull ( subscribedService )
************************************
************************************
[+] input: testNoRecords() { CommittableOffsets committableOffsets = submittedRecords.committableOffsets(); assertTrue(committableOffsets.isEmpty());  committableOffsets = submittedRecords.committableOffsets(); assertTrue(committableOffsets.isEmpty());  committableOffsets = submittedRecords.committableOffsets(); "<AssertPlaceHolder>";  assertNoRemainingDeques(); }
isEmpty() { return numCommittableMessages == 0 && numUncommittableMessages == 0 && offsets.isEmpty(); }
[*] target: assertTrue(committableOffsets.isEmpty())
[-] pred: org. junit. Assert. assertTrue ( committableOffsets. isEmpty() )
************************************
************************************
[+] input: Exception { // create file1 on master RevCommit firstInMaster = writeFileAndCommit(FILE1, "Add file1", "1", "2", "3"); // change in master writeFileAndCommit(FILE1, "change file1 in master", "1master", "2", "3");  checkFile(FILE1, "1master", "2", "3"); // create a topic branch based on the first commit createBranch(firstInMaster, "refs/heads/topic"); checkoutBranch("refs/heads/topic"); // we have the old content again checkFile(FILE1, "1", "2", "3");  // add a line (non-conflicting) writeFileAndCommit(FILE1, "add a line to file1 in topic", "1", "2", "3", "4topic");  // change first line (conflicting) writeFileAndCommit(FILE1, "change file1 in topic\n\nThis is conflicting", "1topic", "2", "3", "4topic");  // change second line (not conflicting) writeFileAndCommit(FILE1, "change file1 in topic again", "1topic", "2topic", "3", "4topic");  RebaseResult res = git.rebase().setUpstream("refs/heads/master").call(); assertEquals(Status.STOPPED, res.getStatus());  // continue should throw a meaningful exception try { res = git.rebase().setOperation(Operation.CONTINUE).call(); fail("Expected Exception not thrown"); } catch (UnmergedPathsException e) { // expected }  // merge the file; the second topic commit should go through writeFileAndAdd(FILE1, "1topic", "2", "3", "4topic");  res = git.rebase().setOperation(Operation.CONTINUE).call(); "<AssertPlaceHolder>"; assertEquals(Status.OK, res.getStatus()); assertEquals(RepositoryState.SAFE, db.getRepositoryState());  ObjectId headId = db.resolve(Constants.HEAD); try (RevWalk rw = new RevWalk(db)) { RevCommit rc = rw.parseCommit(headId); RevCommit parent = rw.parseCommit(rc.getParent(0)); assertEquals("change file1 in topic\n\nThis is conflicting", parent .getFullMessage()); } }
call() throws GitAPIException, NoHeadException, RefNotFoundException, WrongRepositoryStateException { newHead = null; lastStepWasForward = false; checkCallable(); checkParameters(); commitConfig = repo.getConfig().get(CommitConfig.KEY); try { switch (operation) { case ABORT: try { return abort(RebaseResult.ABORTED_RESULT); } catch (IOException ioe) { throw new JGitInternalException(ioe.getMessage(), ioe); } case PROCESS_STEPS: case SKIP: case CONTINUE: String upstreamCommitId = rebaseState.readFile(ONTO); try { upstreamCommitName = rebaseState.readFile(ONTO_NAME); } catch (FileNotFoundException e) { // Fall back to commit ID if file doesn't exist (e.g. rebase // was started by C Git) upstreamCommitName = upstreamCommitId; } this.upstreamCommit = walk.parseCommit(repo .resolve(upstreamCommitId)); preserveMerges = rebaseState.getRewrittenDir().isDirectory(); break; case BEGIN: autoStash(); if (stopAfterInitialization || !walk.isMergedInto( walk.parseCommit(repo.resolve(Constants.HEAD)), upstreamCommit)) { org.eclipse.jgit.api.Status status = Git.wrap(repo) .status().setIgnoreSubmodules(IgnoreSubmoduleMode.ALL).call(); if (status.hasUncommittedChanges()) { List<String> list = new ArrayList<>(); list.addAll(status.getUncommittedChanges()); return RebaseResult.uncommittedChanges(list); } } RebaseResult res = initFilesAndRewind(); if (stopAfterInitialization) { return RebaseResult.INTERACTIVE_PREPARED_RESULT; } if (res != null) { if (!autoStashApply()) { res = RebaseResult.STASH_APPLY_CONFLICTS_RESULT; } if (rebaseState.getDir().exists()) { FileUtils.delete(rebaseState.getDir(), FileUtils.RECURSIVE); } return res; } }  if (monitor.isCancelled()) return abort(RebaseResult.ABORTED_RESULT);  if (operation == Operation.CONTINUE) { newHead = continueRebase(); List<RebaseTodoLine> doneLines = repo.readRebaseTodo( rebaseState.getPath(DONE), true); RebaseTodoLine step = doneLines.get(doneLines.size() - 1); if (newHead != null && step.getAction() != Action.PICK) { RebaseTodoLine newStep = new RebaseTodoLine( step.getAction(), AbbreviatedObjectId.fromObjectId(newHead), step.getShortMessage()); RebaseResult result = processStep(newStep, false); if (result != null) return result; } File amendFile = rebaseState.getFile(AMEND); boolean amendExists = amendFile.exists(); if (amendExists) { FileUtils.delete(amendFile); } if (newHead == null && !amendExists) { // continueRebase() returns null only if no commit was // neccessary. This means that no changes where left over // after resolving all conflicts. In this case, cgit stops // and displays a nice message to the user, telling him to // either do changes or skip the commit instead of continue. return RebaseResult.NOTHING_TO_COMMIT_RESULT; } }  if (operation == Operation.SKIP) newHead = checkoutCurrentHead();  List<RebaseTodoLine> steps = repo.readRebaseTodo( rebaseState.getPath(GIT_REBASE_TODO), false); if (steps.isEmpty()) { return finishRebase(walk.parseCommit(repo.resolve(Constants.HEAD)), false); } if (isInteractive()) { interactiveHandler.prepareSteps(steps); repo.writeRebaseTodoFile(rebaseState.getPath(GIT_REBASE_TODO), steps, false); } checkSteps(steps); for (RebaseTodoLine step : steps) { popSteps(1); RebaseResult result = processStep(step, true); if (result != null) { return result; } } return finishRebase(newHead, lastStepWasForward); } catch (CheckoutConflictException cce) { return RebaseResult.conflicts(cce.getConflictingPaths()); } catch (IOException ioe) { throw new JGitInternalException(ioe.getMessage(), ioe); } }
[*] target: assertNotNull(res)
[-] pred: org. junit. Assert. assertNotNull ( res )
************************************
************************************
[+] input: testBuilderHeader() { Header header = NamingHttpUtil.builderHeader(); Assert."<AssertPlaceHolder>"; Assert.assertEquals(header.getValue(HttpHeaderConsts.CLIENT_VERSION_HEADER), VersionUtils.version); Assert.assertEquals(header.getValue(HttpHeaderConsts.USER_AGENT_HEADER), VersionUtils.getFullClientVersion()); Assert.assertEquals(header.getValue(HttpHeaderConsts.ACCEPT_ENCODING), "gzip,deflate,sdch"); Assert.assertEquals(header.getValue(HttpHeaderConsts.CONNECTION), "Keep-Alive"); Assert.assertNotNull(header.getValue(HttpHeaderConsts.REQUEST_ID)); Assert.assertEquals(header.getValue(HttpHeaderConsts.REQUEST_MODULE), "Naming"); }
builderHeader() { Header header = Header.newInstance(); header.addParam(HttpHeaderConsts.CLIENT_VERSION_HEADER, VersionUtils.version); header.addParam(HttpHeaderConsts.USER_AGENT_HEADER, VersionUtils.getFullClientVersion()); header.addParam(HttpHeaderConsts.ACCEPT_ENCODING, "gzip,deflate,sdch"); header.addParam(HttpHeaderConsts.CONNECTION, "Keep-Alive"); header.addParam(HttpHeaderConsts.REQUEST_ID, UuidUtils.generateUuid()); header.addParam(HttpHeaderConsts.REQUEST_MODULE, "Naming"); return header; }
[*] target: assertNotNull(header)
[-] pred: org. junit. Assert. assertNotNull ( header )
************************************
************************************
[+] input: test_get_tls_with_cert() {  clientConnection.setAuthCipherSuite("cipher"); clientConnection.setAuthProtocol("TLSv1.2");  final SslClientCertificate clientCertificate = Mockito.mock(SslClientCertificate.class);  clientConnection.setAuthCertificate(clientCertificate);  final X509Certificate[] chain = new X509Certificate[3]; chain[0] = new TestCert(); chain[1] = new TestCert(); chain[2] = new TestCert();  final TestCert testCert = new TestCert();  when(clientCertificate.certificate()).thenReturn(testCert); when(clientCertificate.certificateChain()).thenReturn(chain);  final ClientTlsInformation clientTlsInformation = ExtensionInformationUtil.getTlsInformationFromChannel(channel); "<AssertPlaceHolder>"; assertEquals("cipher", clientTlsInformation.getCipherSuite()); assertEquals("TLSv1.2", clientTlsInformation.getProtocol()); assertTrue(clientTlsInformation.getHostname().isEmpty()); assertTrue(clientTlsInformation.getClientCertificate().isPresent()); assertNotNull(((TlsInformation) clientTlsInformation).getCertificate()); assertNotNull(((TlsInformation) clientTlsInformation).getCertificateChain()); }
getTlsInformationFromChannel(final @NotNull Channel channel) {  Preconditions.checkNotNull(channel, "channel must never be null");  final ClientConnection clientConnection = channel.attr(ClientConnection.CHANNEL_ATTRIBUTE_NAME).get(); try { final String cipher = clientConnection.getAuthCipherSuite(); final String protocol = clientConnection.getAuthProtocol(); final String sniHostname = clientConnection.getAuthSniHostname();  final SslClientCertificate sslClientCertificate = clientConnection.getAuthCertificate();  if (cipher == null || protocol == null) { return null; }  if (sslClientCertificate == null) { return new ClientTlsInformationImpl(null, null, cipher, protocol, sniHostname);  } else { final X509Certificate certificate = (X509Certificate) sslClientCertificate.certificate(); final X509Certificate[] certificateChain = (X509Certificate[]) sslClientCertificate.certificateChain();  return new ClientTlsInformationImpl(certificate, certificateChain, cipher, protocol, sniHostname); }  } catch (final Exception e) { log.debug("Tls information creation failed: ", e); }  return null; }
[*] target: assertNotNull(clientTlsInformation)
[-] pred: org. junit. Assert. assertNotNull ( clientTlsInformation )
************************************
************************************
[+] input: testParseMethodBasedOperation() { BeanOperations beanOperations = parser.parse(MethodBasedOperationBean.class); Collection<AssembleOperation> operations = beanOperations.getAssembleOperations(); Assert."<AssertPlaceHolder>";  AssembleOperation op1 = CollectionUtils.get(operations, 0); Assert.assertNotNull(op1); Assert.assertEquals("getId", op1.getId()); Assert.assertEquals("getId", op1.getKey()); Assert.assertEquals("test1", op1.getContainer());  AssembleOperation op2 = CollectionUtils.get(operations, 1); Assert.assertNotNull(op2); Assert.assertEquals("takeId", op2.getId()); Assert.assertEquals("takeId", op2.getKey()); Assert.assertEquals("test2", op2.getContainer()); }
parse(AnnotatedElement element) throws OperationParseException { Objects.requireNonNull(element, "the element to be parsed cannot be null"); try { return parseIfNecessary(element); } catch (Exception e) { throw new OperationParseException(e); } }
[*] target: assertEquals(2, operations.size())
[-] pred: org. junit. Assert. assertEquals ( 2, operations. size ( ) )
************************************
************************************
[+] input: createPostRequestForAsk() { BardRequest bardRequest = BardRequest.newEmptyBardRequest(); bardRequest.setStrSNlM0e("xxx1"); Request request = BardUtils.createPostRequestForAsk(token, bardRequest); Assert."<AssertPlaceHolder>"; Assert.assertEquals("POST", request.method()); }
createPostRequestForAsk(String token, BardRequest bardRequest) { return createBuilderWithBardHeader(token) .url(createHttpBuilderForAsk().build()) .method("POST", buildRequestBodyForAsk(bardRequest)) .build(); }
[*] target: assertNotNull(request)
[-] pred: org. junit. Assert. assertNotNull ( request )
************************************
************************************
[+] input: Exception { final SettableFuture<PublishStatus> future = SettableFuture.create(); final PUBLISH publish = new PUBLISHFactory.Mqtt3Builder() .withHivemqId("hivemqId") .withPayload(new byte[]{0}) .withTopic("topic") .withQoS(QoS.AT_MOST_ONCE) .withOnwardQos(QoS.AT_MOST_ONCE) .withMessageExpiryInterval(MESSAGE_EXPIRY_INTERVAL_NOT_SET) .withPublishId(1L) .withPersistence(publishPayloadPersistence) .build();  final PublishWithFuture publishWithFuture = new PublishWithFuture(publish, future, false, publishPayloadPersistence); final boolean messageDropped = handler.checkChannelNotWritable(ctx, publishWithFuture, promise); "<AssertPlaceHolder>"; assertEquals(PublishStatus.CHANNEL_NOT_WRITABLE, future.get()); verify(promise).setSuccess(); verify(messageDroppedService).notWritable("clientId", "topic", 0); }
checkChannelNotWritable(final ChannelHandlerContext ctx, final @NotNull Object msg, final @NotNull ChannelPromise promise) throws Exception { if (!ctx.channel().isWritable()) {  if (msg instanceof PUBLISH) { if (notWritableMessages.get() < notWritableQueueSize) { notWritableMessages.incrementAndGet(); promise.addListeners(decrementCounterListener); return false; }  final PUBLISH publish = (PUBLISH) msg; if ((publish).getQoS() == QoS.AT_MOST_ONCE) { if (msg instanceof PublishWithFuture) { final SettableFuture<PublishStatus> future = ((PublishWithFuture) msg).getFuture(); future.set(PublishStatus.CHANNEL_NOT_WRITABLE); } //Drop message final String clientId = ctx.channel().attr(ClientConnection.CHANNEL_ATTRIBUTE_NAME).get().getClientId(); log.trace("Dropped qos 0 message for client {} on topic {} because the channel was not writable", clientId, publish.getTopic()); messageDroppedService.notWritable(clientId, publish.getTopic(), publish.getQoS().getQosNumber()); promise.setSuccess(); return true; } } }  return false; }
[*] target: assertTrue(messageDropped)
[-] pred: org. junit. Assert. assertTrue ( messageDropped )
************************************
************************************
[+] input: shouldBalanceAssignmentWithMoreCost() { final Map<Subtopology, Set<TaskId>> tasksForTopicGroup = mkMap( mkEntry(new Subtopology(0, null), mkSet(TASK_0_0, TASK_0_1)), mkEntry(new Subtopology(1, null), mkSet(TASK_1_1)) ); final RackAwareTaskAssignor assignor = new RackAwareTaskAssignor( getClusterForAllTopics(), getTaskTopicPartitionMapForAllTasks(), mkMap(), tasksForTopicGroup, getProcessRacksForAllProcess(), mockInternalTopicManager, getRackAwareEnabledConfig(), time );  final ClientState clientState1 = new ClientState(emptySet(), emptySet(), emptyMap(), EMPTY_CLIENT_TAGS, 1); final ClientState clientState2 = new ClientState(emptySet(), emptySet(), emptyMap(), EMPTY_CLIENT_TAGS, 1);  clientState1.assignActiveTasks(mkSet(TASK_0_0, TASK_1_1)); clientState2.assignActive(TASK_0_1);  // task_0_0 has same rack as UUID_2 // task_0_1 has same rack as UUID_2 // task_1_1 has same rack as UUID_2 // UUID_5 is not in same rack as any task final SortedMap<UUID, ClientState> clientStateMap = new TreeMap<>(mkMap( mkEntry(UUID_2, clientState1), mkEntry(UUID_5, clientState2) )); final SortedSet<TaskId> taskIds = mkSortedSet(TASK_0_0, TASK_0_1, TASK_1_1);  assertTrue(assignor.canEnableRackAwareAssignor()); final int expectedCost = stateful ? 10 : 1; final long originalCost = assignor.activeTasksCost(taskIds, clientStateMap, trafficCost, nonOverlapCost); assertEquals(expectedCost, originalCost);  final long cost = assignor.optimizeActiveTasks(taskIds, clientStateMap, trafficCost, nonOverlapCost); "<AssertPlaceHolder>";  if (stateful || assignmentStrategy.equals(StreamsConfig.RACK_AWARE_ASSIGNMENT_STRATEGY_MIN_TRAFFIC)) { // Even though assigning all tasks to UUID_2 will result in min cost, but it's not balanced // assignment. That's why TASK_0_1 is still assigned to UUID_5 assertEquals(mkSet(TASK_0_0, TASK_1_1), clientState1.activeTasks()); assertEquals(mkSet(TASK_0_1), clientState2.activeTasks()); } else { assertEquals(mkSet(TASK_0_0, TASK_0_1), clientState1.activeTasks()); assertEquals(mkSet(TASK_1_1), clientState2.activeTasks()); } }
optimizeActiveTasks(final SortedSet<TaskId> activeTasks, final SortedMap<UUID, ClientState> clientStates, final int trafficCost, final int nonOverlapCost) { if (activeTasks.isEmpty()) { return 0; }  log.info("Assignment before active task optimization is {}\n with cost {}", clientStates, activeTasksCost(activeTasks, clientStates, trafficCost, nonOverlapCost));  final long startTime = time.milliseconds(); final List<UUID> clientList = new ArrayList<>(clientStates.keySet()); final List<TaskId> taskIdList = new ArrayList<>(activeTasks); final Map<TaskId, UUID> taskClientMap = new HashMap<>(); final Map<UUID, Integer> originalAssignedTaskNumber = new HashMap<>(); final RackAwareGraphConstructor<ClientState> graphConstructor = RackAwareGraphConstructorFactory.create(assignmentConfigs, tasksForTopicGroup); final Graph<Integer> graph = graphConstructor.constructTaskGraph( clientList, taskIdList, clientStates, taskClientMap, originalAssignedTaskNumber, ClientState::hasActiveTask, this::getCost, trafficCost, nonOverlapCost, false, false );  graph.solveMinCostFlow(); final long cost = graph.totalCost();  graphConstructor.assignTaskFromMinCostFlow(graph, clientList, taskIdList, clientStates, originalAssignedTaskNumber, taskClientMap, ClientState::assignActive, ClientState::unassignActive, ClientState::hasActiveTask);  final long duration = time.milliseconds() - startTime; log.info("Assignment after {} milliseconds for active task optimization is {}\n with cost {}", duration, clientStates, cost); return cost; }
[*] target: assertEquals(expectedCost, cost)
[-] pred: org. junit. Assert. assertEquals ( expectedCost, cost )
************************************
************************************
[+] input: testToTargetState() { assertEquals(TargetState.STARTED, CreateConnectorRequest.InitialState.RUNNING.toTargetState()); assertEquals(TargetState.PAUSED, CreateConnectorRequest.InitialState.PAUSED.toTargetState()); assertEquals(TargetState.STOPPED, CreateConnectorRequest.InitialState.STOPPED.toTargetState());  CreateConnectorRequest createConnectorRequest = new CreateConnectorRequest("test-name", Collections.emptyMap(), null); "<AssertPlaceHolder>"; }
initialTargetState() { if (initialState != null) { return initialState.toTargetState(); } else { return null; } }
[*] target: assertNull(createConnectorRequest.initialTargetState())
[-] pred: org. junit. Assert. assertNull ( createConnectorRequest. initialTargetState() )
************************************
************************************
[+] input: test_constructMqtt5_withUserProperties() { final Mqtt5UserProperties userProperties = Mqtt5UserProperties.of( new MqttUserProperty("user1", "value1"), new MqttUserProperty("user2", "value2"), new MqttUserProperty("user3", "value3"));  final PUBREL origin = new PUBREL(1, Mqtt5PubRelReasonCode.PACKET_IDENTIFIER_NOT_FOUND, "reasonString", userProperties); final PubrelPacketImpl packet = new PubrelPacketImpl(origin);  final PUBREL merged = PUBREL.from(packet);  "<AssertPlaceHolder>"; assertNotSame(origin, merged); assertPUBRELequals(origin, merged); }
from(final @NotNull PubrelPacketImpl packet) { return new PUBREL( packet.getPacketIdentifier(), Mqtt5PubRelReasonCode.from(packet.getReasonCode()), packet.getReasonString().orElse(null), Mqtt5UserProperties.of(packet.getUserProperties().asInternalList())); }
[*] target: assertNotNull(merged)
[-] pred: org. junit. Assert. assertNotNull ( merged )
************************************
************************************
[+] input: testLoadSnapshot() { ConcurrentMap<Service, ServiceMetadata> map = new ConcurrentHashMap<>(); Service service = Service.newService("namespace", "group", "name"); map.put(service, new ServiceMetadata());  Serializer aDefault = SerializeFactory.getDefault(); serviceMetadataSnapshotOperation.loadSnapshot(aDefault.serialize(map));  Map<Service, ServiceMetadata> serviceMetadataSnapshot = namingMetadataManager.getServiceMetadataSnapshot(); Assert."<AssertPlaceHolder>"; Assert.assertEquals(serviceMetadataSnapshot.size(), 1); }
loadSnapshot(byte[] snapshotBytes) { metadataManager.loadServiceMetadataSnapshot(serializer.deserialize(snapshotBytes)); }
[*] target: assertNotNull(serviceMetadataSnapshot)
[-] pred: org. junit. Assert. assertNotNull ( serviceMetadataSnapshot )
************************************
************************************
[+] input: testGetOptionalBean() {  applicationContext.register(BaseTestBean.class);  applicationContext.refresh();  BaseTestBean testBean = getOptionalBean(applicationContext, "baseTestBean", BaseTestBean.class);  Assert."<AssertPlaceHolder>";  assertEquals("Hello,World", testBean.getName());  }
getOptionalBean(ListableBeanFactory beanFactory, String beanName, Class<T> beanType) {  if (!hasText(beanName)) { return null; }  String[] beanNames = of(beanName);  List<T> beans = getBeans(beanFactory, beanNames, beanType);  return isEmpty(beans) ? null : beans.get(0); }
[*] target: assertNotNull(testBean)
[-] pred: org. junit. Assert. assertNotNull ( testBean )
************************************
************************************
[+] input: IOException { db.getObjectDatabase().getReaderOptions().setStreamFileThreshold(512); DfsBlockCache.reconfigure(new DfsBlockCacheConfig() .setBlockSize(512) .setBlockLimit(2048));  byte[] data = new TestRng(JGitTestUtil.getName()).nextBytes(8192); try (DfsInserter ins = (DfsInserter) db.newObjectInserter()) { ins.setCompressionLevel(Deflater.NO_COMPRESSION); ObjectId id1 = ins.insert(Constants.OBJ_BLOB, data); assertEquals(0, db.getObjectDatabase().listPacks().size());  try (ObjectReader reader = ins.newReader()) { assertSame(ins, reader.getCreatedFromInserter()); assertTrue(Arrays.equals(data, readStream(reader.open(id1)))); assertEquals(0, db.getObjectDatabase().listPacks().size()); } ins.flush();  } List<DfsPackDescription> packs = db.getObjectDatabase().listPacks(); "<AssertPlaceHolder>"; assertTrue(packs.get(0).getFileSize(PackExt.PACK) > 2048); }
flush() throws IOException { if (packDsc == null) return;  if (packOut == null) throw new IOException();  byte[] packHash = packOut.writePackFooter(); packDsc.addFileExt(PACK); packDsc.setFileSize(PACK, packOut.getCount()); packOut.close(); packOut = null;  sortObjectsById();  PackIndex index = writePackIndex(packDsc, packHash, objectList); writeObjectSizeIndex(packDsc, objectList); db.commitPack(Collections.singletonList(packDsc), null); rollback = false;  DfsPackFile p = db.createDfsPackFile(cache, packDsc); if (index != null) p.setPackIndex(index); db.addPack(p); clear(); }
[*] target: assertEquals(1, packs.size())
[-] pred: org. junit. Assert. assertEquals ( 1, packs. size ( ) )
************************************
************************************
[+] input: test_abort() {  final IterationContextImpl iterationContext = new IterationContextImpl();  assertFalse(iterationContext.isAborted());  iterationContext.abortIteration();  "<AssertPlaceHolder>"; }
isAborted() { return aborted.get(); }
[*] target: assertTrue(iterationContext.isAborted())
[-] pred: org. junit. Assert. assertTrue ( iterationContext. isAborted() )
************************************
************************************
[+] input: JsonProcessingException { serviceInfo.setReachProtectionThreshold(true); serviceInfo.setJsonFromServer(mapper.writeValueAsString(serviceInfo)); ServiceInfo actual = mapper.readValue(serviceInfo.getJsonFromServer(), ServiceInfo.class); assertEquals(StringUtils.EMPTY, actual.getJsonFromServer()); "<AssertPlaceHolder>"; }
isReachProtectionThreshold() { return reachProtectionThreshold; }
[*] target: assertTrue(actual.isReachProtectionThreshold())
[-] pred: org. junit. Assert. assertTrue ( actual. isReachProtectionThreshold() )
************************************
************************************
[+] input: Exception { Collection<ReflogEntry> reflog = git.reflog() .setRef(Constants.R_HEADS + "b1").call(); "<AssertPlaceHolder>"; assertEquals(2, reflog.size()); ReflogEntry[] reflogs = reflog.toArray(new ReflogEntry[0]); assertEquals(reflogs[0].getComment(), "commit: Removed file"); assertEquals(reflogs[0].getNewId(), commit2.getId()); assertEquals(reflogs[0].getOldId(), commit1.getId()); assertEquals(reflogs[1].getComment(), "branch: Created from commit Initial commit"); assertEquals(reflogs[1].getNewId(), commit1.getId()); assertEquals(reflogs[1].getOldId(), ObjectId.zeroId()); }
call() throws GitAPIException, InvalidRefNameException { checkCallable();  try { ReflogReader reader = repo.getReflogReader(ref); if (reader == null) throw new RefNotFoundException(MessageFormat.format( JGitText.get().refNotResolved, ref)); return reader.getReverseEntries(); } catch (IOException e) { throw new InvalidRefNameException(MessageFormat.format( JGitText.get().cannotRead, ref), e); } }
[*] target: assertNotNull(reflog)
[-] pred: org. junit. Assert. assertNotNull ( reflog )
************************************
************************************
[+] input: Exception { ServerReloadRequest request = new ServerReloadRequest(); request.setReloadCount(10); request.setReloadServer("1.1.1.1"); request.setRequestId("1"); String json = mapper.writeValueAsString(request); System.out.println(json); Assert."<AssertPlaceHolder>"; Assert.assertTrue(json.contains(""reloadCount":10")); Assert.assertTrue(json.contains(""reloadServer":"1.1.1.1"")); Assert.assertTrue(json.contains(""module":"internal"")); Assert.assertTrue(json.contains(""requestId":"1"")); }
setReloadServer(String reloadServer) { this.reloadServer = reloadServer; }
[*] target: assertNotNull(json)
[-] pred: org. junit. Assert. assertNotNull ( json )
************************************
************************************
[+] input: testDoubleReadLockByAllReleaseAndWriteLock() { SimpleReadWriteLock lock = new SimpleReadWriteLock(); assertTrue(lock.tryReadLock()); assertTrue(lock.tryReadLock());  lock.releaseReadLock(); lock.releaseReadLock();  "<AssertPlaceHolder>"; }
tryWriteLock() { if (!isFree()) { return false; } else { status = -1; return true; } }
[*] target: assertTrue(lock.tryWriteLock())
[-] pred: org. junit. Assert. assertTrue ( lock. tryWriteLock() )
************************************
************************************
[+] input: testGetLocationFixedPath() { when(properties.getConnectionString()).thenReturn(azuriteConnectionString); AzureBlobPayloadStorage azureBlobPayloadStorage = new AzureBlobPayloadStorage(idGenerator, properties); String path = "somewhere"; ExternalStorageLocation externalStorageLocation = azureBlobPayloadStorage.getLocation( ExternalPayloadStorage.Operation.READ, ExternalPayloadStorage.PayloadType.WORKFLOW_INPUT, path); "<AssertPlaceHolder>"; assertEquals(path, externalStorageLocation.getPath()); assertNotNull(externalStorageLocation.getUri()); }
getLocation( Operation operation, PayloadType payloadType, String path) { try { ExternalStorageLocation externalStorageLocation = new ExternalStorageLocation();  String objectKey; if (StringUtils.isNotBlank(path)) { objectKey = path; } else { objectKey = getObjectKey(payloadType); } externalStorageLocation.setPath(objectKey);  BlockBlobClient blockBlobClient = blobContainerClient.getBlobClient(objectKey).getBlockBlobClient(); String blobUrl = Utility.urlDecode(blockBlobClient.getBlobUrl());  if (sasTokenCredential != null) { blobUrl = blobUrl + "?" + sasTokenCredential.getSasToken(); } else { BlobSasPermission blobSASPermission = new BlobSasPermission(); if (operation.equals(Operation.READ)) { blobSASPermission.setReadPermission(true); } else if (operation.equals(Operation.WRITE)) { blobSASPermission.setWritePermission(true); blobSASPermission.setCreatePermission(true); } BlobServiceSasSignatureValues blobServiceSasSignatureValues = new BlobServiceSasSignatureValues( OffsetDateTime.now(ZoneOffset.UTC).plusSeconds(expirationSec), blobSASPermission); blobUrl = blobUrl + "?" + blockBlobClient.generateSas(blobServiceSasSignatureValues); }  externalStorageLocation.setUri(blobUrl); return externalStorageLocation; } catch (BlobStorageException e) { String msg = "Error communicating with Azure"; LOGGER.error(msg, e); throw new NonTransientException(msg, e); } }
[*] target: assertNotNull(externalStorageLocation)
[-] pred: org. junit. Assert. assertNotNull ( externalStorageLocation )
************************************
************************************
[+] input: testWebUtil() { SecuritySession session = Mockito.mock(SecuritySession.class); Mockito.when(session.getId()).thenReturn("abcde"); Mockito.when(session.getTimeoutMillis()).thenReturn(100000L); Cookie cookie = WebUtil.generateSecurityCookie(session); Assert."<AssertPlaceHolder>"; Assert.assertEquals(cookie.getValue(), session.getId()); Assert.assertEquals(cookie.getMaxAge(), TimeUnit.SECONDS.convert(session.getTimeoutMillis(), TimeUnit.MILLISECONDS)); Assert.assertTrue(cookie.isHttpOnly()); Assert.assertEquals(cookie.getPath(), "/"); }
generateSecurityCookie(@NonNull SecuritySession session) { Cookie cookie = new Cookie(SecurityConstants.CUSTOM_COOKIE_NAME, (String) session.getId()); cookie.setHttpOnly(true); long maxAgeSeconds = TimeUnit.SECONDS.convert(session.getTimeoutMillis(), TimeUnit.MILLISECONDS); if (maxAgeSeconds > Integer.MAX_VALUE) { cookie.setMaxAge(Integer.MAX_VALUE); } else { cookie.setMaxAge((int) maxAgeSeconds); } cookie.setPath("/"); return cookie; }
[*] target: assertNotNull(cookie)
[-] pred: org. junit. Assert. assertNotNull ( cookie )
************************************
************************************
[+] input: shouldFindTask() { TaskSummary taskSummary = TestUtils.loadTaskSnapshot(objectMapper, "task_summary"); indexDAO.indexTask(taskSummary);  List<TaskSummary> tasks = tryFindResults(() -> searchTaskSummary(taskSummary)); "<AssertPlaceHolder>"; assertEquals(taskSummary, tasks.get(0)); }
indexTask(TaskSummary task) { try { long startTime = Instant.now().toEpochMilli(); String id = task.getTaskId(); byte[] doc = objectMapper.writeValueAsBytes(task); String docType = StringUtils.isBlank(docTypeOverride) ? TASK_DOC_TYPE : docTypeOverride;  UpdateRequest req = new UpdateRequest(taskIndexName, docType, id); req.doc(doc, XContentType.JSON); req.upsert(doc, XContentType.JSON); indexObject(req, TASK_DOC_TYPE); long endTime = Instant.now().toEpochMilli(); LOGGER.debug( "Time taken {} for  indexing task:{} in workflow: {}", endTime - startTime, task.getTaskId(), task.getWorkflowId()); Monitors.recordESIndexTime("index_task", TASK_DOC_TYPE, endTime - startTime); Monitors.recordWorkerQueueSize( "indexQueue", ((ThreadPoolExecutor) executorService).getQueue().size()); } catch (Exception e) { LOGGER.error("Failed to index task: {}", task.getTaskId(), e); } }
[*] target: assertEquals(1, tasks.size())
[-] pred: org. junit. Assert. assertEquals ( 1, tasks. size ( ) )
************************************
************************************
[+] input: NacosException { rpcClient.rpcClientStatus.set(RpcClientStatus.RUNNING); rpcClient.currentConnection = connection; doThrow(new NacosException()).when(connection).asyncRequest(any(), any()); RequestCallBack<?> requestCallBack = mock(RequestCallBack.class); doReturn(10000L).when(requestCallBack).getTimeout(); Exception exception = null;  try { rpcClient.asyncRequest(null, requestCallBack); } catch (NacosException e) { exception = e; }  verify(connection, atLeastOnce()).asyncRequest(any(), any()); verify(rpcClient).switchServerAsyncOnRequestFail(); Assert."<AssertPlaceHolder>"; assertEquals(RpcClientStatus.UNHEALTHY, rpcClient.rpcClientStatus.get()); }
switchServerAsyncOnRequestFail() { switchServerAsync(null, true); }
[*] target: assertNotNull(exception)
[-] pred: org. junit. Assert. assertNotNull ( exception )
************************************
************************************
[+] input: testSetRootLevel() { Logger root = logger("root"); root.setLevel(Level.ERROR);  Logger p = logger("a.b.c.p"); Logger x = logger("a.b.c.p.X"); Logger y = logger("a.b.c.p.Y"); Logger z = logger("a.b.c.p.Z"); Logger w = logger("a.b.c.s.W"); x.setLevel(Level.INFO); y.setLevel(Level.INFO); z.setLevel(Level.INFO); w.setLevel(Level.INFO);  Loggers loggers = new TestLoggers(root, x, y, z, w);  List<String> modified = loggers.setLevel("root", Level.DEBUG); assertEquals(Arrays.asList("a.b.c.p.X", "a.b.c.p.Y", "a.b.c.p.Z", "a.b.c.s.W", "root"), modified);  assertNull(p.getLevel());  assertEquals(root.getLevel(), Level.DEBUG);  assertEquals(w.getLevel(), Level.DEBUG); assertEquals(x.getLevel(), Level.DEBUG); assertEquals(y.getLevel(), Level.DEBUG); assertEquals(z.getLevel(), Level.DEBUG);  Map<String, LoggerLevel> expectedLevels = new HashMap<>(); expectedLevels.put("root", new LoggerLevel(Level.DEBUG.toString(), INITIAL_TIME)); expectedLevels.put("a.b.c.p.X", new LoggerLevel(Level.DEBUG.toString(), INITIAL_TIME)); expectedLevels.put("a.b.c.p.Y", new LoggerLevel(Level.DEBUG.toString(), INITIAL_TIME)); expectedLevels.put("a.b.c.p.Z", new LoggerLevel(Level.DEBUG.toString(), INITIAL_TIME)); expectedLevels.put("a.b.c.s.W", new LoggerLevel(Level.DEBUG.toString(), INITIAL_TIME));  Map<String, LoggerLevel> actualLevels = loggers.allLevels(); "<AssertPlaceHolder>"; }
allLevels() { Map<String, LoggerLevel> result = new TreeMap<>();  Enumeration<org.apache.log4j.Logger> enumeration = currentLoggers(); Collections.list(enumeration) .stream() .filter(logger -> logger.getLevel() != null) .forEach(logger -> result.put(logger.getName(), loggerLevel(logger)));  org.apache.log4j.Logger root = rootLogger(); if (root.getLevel() != null) { result.put(ROOT_LOGGER_NAME, loggerLevel(root)); }  return result; }
[*] target: assertEquals(expectedLevels, actualLevels)
[-] pred: org. junit. Assert. assertEquals ( expectedLevels, actualLevels )
************************************
************************************
[+] input: testSingleAck() { Map<String, Object> offset = newOffset();  SubmittedRecord submittedRecord = submittedRecords.submit(PARTITION1, offset); CommittableOffsets committableOffsets = submittedRecords.committableOffsets(); // Record has been submitted but not yet acked; cannot commit offsets for it yet assertFalse(committableOffsets.isEmpty()); assertEquals(Collections.emptyMap(), committableOffsets.offsets()); assertMetadata(committableOffsets, 0, 1, 1, 1, PARTITION1); assertNoEmptyDeques();  submittedRecord.ack(); committableOffsets = submittedRecords.committableOffsets(); // Record has been acked; can commit offsets for it assertFalse(committableOffsets.isEmpty()); assertEquals(Collections.singletonMap(PARTITION1, offset), committableOffsets.offsets()); assertMetadataNoPending(committableOffsets, 1);  // Everything has been ack'd and consumed; make sure that it's been cleaned up to avoid memory leaks assertNoRemainingDeques();  committableOffsets = submittedRecords.committableOffsets(); // Old offsets should be wiped assertEquals(Collections.emptyMap(), committableOffsets.offsets()); "<AssertPlaceHolder>"; }
isEmpty() { return numCommittableMessages == 0 && numUncommittableMessages == 0 && offsets.isEmpty(); }
[*] target: assertTrue(committableOffsets.isEmpty())
[-] pred: org. junit. Assert. assertTrue ( committableOffsets. isEmpty() )
************************************
************************************
[+] input: IOException { String path = "test/payload";  Map<String, Object> payload = new HashMap<>(); payload.put("key1", "value1"); payload.put("key2", 200); byte[] payloadBytes = objectMapper.writeValueAsString(payload).getBytes(); when(externalPayloadStorage.download(path)) .thenReturn(new ByteArrayInputStream(payloadBytes));  Map<String, Object> result = externalPayloadStorageUtils.downloadPayload(path); "<AssertPlaceHolder>"; assertEquals(payload, result); }
downloadPayload(String path) { try (InputStream inputStream = externalPayloadStorage.download(path)) { return objectMapper.readValue( IOUtils.toString(inputStream, StandardCharsets.UTF_8), Map.class); } catch (TransientException te) { throw te; } catch (Exception e) { LOGGER.error("Unable to download payload from external storage path: {}", path, e); throw new NonTransientException( "Unable to download payload from external storage path: " + path, e); } }
[*] target: assertNotNull(result)
[-] pred: org. junit. Assert. assertNotNull ( result )
************************************
************************************
[+] input: listDatabaseChangingOrderTemplates_useQueryCondition_succeed() { Database database = new Database(); when(databaseService.listDatabasesByIds(any())).thenReturn(Arrays.asList(database)); createDatabaseChangingOrderTemplate_saveEntity_succeed(); Pageable pageable = Pageable.unpaged(); QueryDatabaseChangeChangingOrderParams params = QueryDatabaseChangeChangingOrderParams.builder() .projectId(PROJECT_ID).creatorId(CURRENT_USER_ID).name(TEMPLATE_NAME).build(); Page<DatabaseChangeChangingOrderTemplateResp> result = templateService.listTemplates(pageable, params); Assert."<AssertPlaceHolder>"; Assert.assertEquals(1, result.getContent().size()); }
listTemplates(@NotNull Pageable pageable, @NotNull @Valid QueryDatabaseChangeChangingOrderParams params) { projectPermissionValidator.checkProjectRole(params.getProjectId(), ResourceRoleName.all()); Specification<DatabaseChangeChangingOrderTemplateEntity> specification = Specification .where(DatabaseChangeChangingOrderTemplateSpecs.projectIdEquals(params.getProjectId())) .and(params.getName() == null ? null : DatabaseChangeChangingOrderTemplateSpecs.nameLikes(params.getName())) .and(params.getCreatorId() == null ? null : DatabaseChangeChangingOrderTemplateSpecs .creatorIdIn(Collections.singleton(params.getCreatorId()))); Page<DatabaseChangeChangingOrderTemplateEntity> pageResult = templateRepository.findAll(specification, pageable); List<DatabaseChangeChangingOrderTemplateEntity> entityList = pageResult.getContent(); if (CollectionUtils.isEmpty(entityList)) { return Page.empty(); } List<Long> databaseIds = entityList.stream() .flatMap(entity -> entity.getDatabaseSequences().stream()) .flatMap(Collection::stream) .distinct().collect(Collectors.toList()); Map<Long, DatabaseChangeDatabase> id2DatabaseChangeDatabase = databaseService.listDatabasesDetailsByIds(databaseIds).stream() .collect(Collectors.toMap(Database::getId, DatabaseChangeDatabase::new)); List<DatabaseChangeChangingOrderTemplateResp> templateRespList = entityList.stream().map(entity -> { DatabaseChangeChangingOrderTemplateResp templateResp = new DatabaseChangeChangingOrderTemplateResp(); templateResp.setId(entity.getId()); templateResp.setName(entity.getName()); templateResp.setCreatorId(entity.getCreatorId()); templateResp.setProjectId(entity.getProjectId()); templateResp.setOrganizationId(entity.getOrganizationId()); templateResp.setEnabled(entity.getEnabled()); List<List<DatabaseChangeDatabase>> databaseSequenceList = entity.getDatabaseSequences().stream() .map(s -> s.stream().map(id2DatabaseChangeDatabase::get) .collect(Collectors.toList())) .collect(Collectors.toList()); templateResp.setDatabaseSequenceList(databaseSequenceList); return templateResp; }).collect(Collectors.toList()); return new PageImpl<>(templateRespList, pageable, pageResult.getTotalElements()); }
[*] target: assertNotNull(result)
[-] pred: org. junit. Assert. assertNotNull ( result )
************************************
************************************
[+] input: IOException { ResourceManager manager = getResourceManager(); ResourceSpec defaultEntity = getDefaultResourceEntity(manager);  TableTemplate entity = defaultEntity.getTemplates().get(0); List<DataRecord> permissions = getDataRecords(defaultEntity, manager, entity); Assert.assertEquals(1, permissions.size());  DataRecord permission = permissions.get(0); DataRecordRepository repository = new DataRecordRepository(dataSource); Assert.assertFalse(repository.exists(permission)); repository.save(permission); Assert."<AssertPlaceHolder>"; }
exists(@NonNull DataRecord record) { List<DataSpec> conditions = record.getUniqueKeyData(); String sql = generateSelectSql(record.getTableName(), "COUNT(1)", conditions); List<Long> result = query(sql, conditions, (resultSet, i) -> resultSet.getLong(1)); Verify.singleton(result, "Count(1) has to be singleton"); return result.get(0) >= 1; }
[*] target: assertTrue(repository.exists(permission))
[-] pred: org. junit. Assert. assertTrue ( repository. exists ( permission ) )
************************************
************************************
[+] input: IOException { byte[] x = new byte[5]; int n = is.read(x); "<AssertPlaceHolder>"; assertArrayEquals(new byte[] { 0x00, 0x01, 0x02, 0x03, 0x04 }, x); }
read(byte[] b) throws IOException { nullCheck(); return read(b, 0, b.length); }
[*] target: assertEquals(5, n)
[-] pred: org. junit. Assert. assertEquals ( 5, n )
************************************
************************************
[+] input: testEquals() { ServerConfigAbility ability = new ServerConfigAbility(); ability.setSupportRemoteMetrics(true); assertEquals(ability, ability); assertFalse(ability.equals(null)); assertFalse(ability.equals(new ClientConfigAbility())); ServerConfigAbility newOne = new ServerConfigAbility(); assertNotEquals(ability, newOne); newOne.setSupportRemoteMetrics(true); "<AssertPlaceHolder>"; }
setSupportRemoteMetrics(boolean supportRemoteMetrics) { this.supportRemoteMetrics = supportRemoteMetrics; }
[*] target: assertEquals(ability, newOne)
[-] pred: org. junit. Assert. assertEquals ( ability, newOne )
************************************
************************************
[+] input: testWebUtilWithIntMaxValue() { SecuritySession session = Mockito.mock(SecuritySession.class); Mockito.when(session.getId()).thenReturn("abcde"); Mockito.when(session.getTimeoutMillis()).thenReturn(Integer.MAX_VALUE * 1000L + 100000); Cookie cookie = WebUtil.generateSecurityCookie(session); Assert."<AssertPlaceHolder>"; Assert.assertEquals(cookie.getValue(), session.getId()); Assert.assertEquals(cookie.getMaxAge(), Integer.MAX_VALUE); Assert.assertTrue(cookie.isHttpOnly()); Assert.assertEquals(cookie.getPath(), "/"); }
generateSecurityCookie(@NonNull SecuritySession session) { Cookie cookie = new Cookie(SecurityConstants.CUSTOM_COOKIE_NAME, (String) session.getId()); cookie.setHttpOnly(true); long maxAgeSeconds = TimeUnit.SECONDS.convert(session.getTimeoutMillis(), TimeUnit.MILLISECONDS); if (maxAgeSeconds > Integer.MAX_VALUE) { cookie.setMaxAge(Integer.MAX_VALUE); } else { cookie.setMaxAge((int) maxAgeSeconds); } cookie.setPath("/"); return cookie; }
[*] target: assertNotNull(cookie)
[-] pred: org. junit. Assert. assertNotNull ( cookie )
************************************
************************************
[+] input: testDecodeFromTraceTransData() { String messageBody = new StringBuilder() .append("Pub").append(TraceConstants.CONTENT_SPLITOR) .append(System.currentTimeMillis()).append(TraceConstants.CONTENT_SPLITOR) .append("DefaultRegion").append(TraceConstants.CONTENT_SPLITOR) .append("PID-test").append(TraceConstants.CONTENT_SPLITOR) .append("topic-test").append(TraceConstants.CONTENT_SPLITOR) .append("AC1415116D1418B4AAC217FE1B4E0000").append(TraceConstants.CONTENT_SPLITOR) .append("Tags").append(TraceConstants.CONTENT_SPLITOR) .append("Keys").append(TraceConstants.CONTENT_SPLITOR) .append("127.0.0.1:10911").append(TraceConstants.CONTENT_SPLITOR) .append(26).append(TraceConstants.CONTENT_SPLITOR) .append(245).append(TraceConstants.CONTENT_SPLITOR) .append(MessageType.Normal_Msg.ordinal()).append(TraceConstants.CONTENT_SPLITOR) .append("0A9A002600002A9F0000000000002329").append(TraceConstants.CONTENT_SPLITOR) .append(true).append(TraceConstants.CONTENT_SPLITOR) .append(UtilAll.ipToIPv4Str(UtilAll.getIP())).append(TraceConstants.FIELD_SPLITOR) .toString(); String key = "AC1415116D1418B4AAC217FE1B4E0000"; List<TraceView> traceViews = TraceView.decodeFromTraceTransData(key, messageBody); Assert.assertEquals(traceViews.size(), 1); Assert.assertEquals(traceViews.get(0).getMsgId(), key);  key = "AD4233434334AAC217FEFFD0000"; traceViews = TraceView.decodeFromTraceTransData(key, messageBody); Assert."<AssertPlaceHolder>"; }
decodeFromTraceTransData(String key, String messageBody) { List<TraceView> messageTraceViewList = new ArrayList<TraceView>(); if (messageBody == null || messageBody.length() <= 0) { return messageTraceViewList; }  List<TraceContext> traceContextList = TraceDataEncoder.decoderFromTraceDataString(messageBody);  for (TraceContext context : traceContextList) { TraceView messageTraceView = new TraceView(); TraceBean traceBean = context.getTraceBeans().get(0); if (!traceBean.getMsgId().equals(key)) { continue; } messageTraceView.setCostTime(context.getCostTime()); messageTraceView.setGroupName(context.getGroupName()); if (context.isSuccess()) { messageTraceView.setStatus("success"); } else { messageTraceView.setStatus("failed"); } messageTraceView.setKeys(traceBean.getKeys()); messageTraceView.setMsgId(traceBean.getMsgId()); messageTraceView.setTags(traceBean.getTags()); messageTraceView.setTopic(traceBean.getTopic()); messageTraceView.setMsgType(context.getTraceType().name()); messageTraceView.setOffSetMsgId(traceBean.getOffsetMsgId()); messageTraceView.setTimeStamp(context.getTimeStamp()); messageTraceView.setStoreHost(traceBean.getStoreHost()); messageTraceView.setClientHost(traceBean.getClientHost()); messageTraceViewList.add(messageTraceView); } return messageTraceViewList; }
[*] target: assertEquals(traceViews.size(), 0)
[-] pred: org. junit. Assert. assertEquals ( traceViews. size ( ), 0 )
************************************
************************************
[+] input: Exception { File a = writeTrashFile("a.txt", "a"); File b = writeTrashFile("a/a.txt", "sub a"); File dir = b.getParentFile(); git.clean().setCleanDirectories(true).call(); "<AssertPlaceHolder>"; assertFalse(dir.exists()); }
call() throws NoWorkTreeException, GitAPIException { Set<String> files = new TreeSet<>(); try { StatusCommand command = new StatusCommand(repo); Status status = command.call();  Set<String> untrackedFiles = new TreeSet<>(status.getUntracked()); Set<String> untrackedDirs = new TreeSet<>( status.getUntrackedFolders());  FS fs = getRepository().getFS(); for (String p : status.getIgnoredNotInIndex()) { File f = new File(repo.getWorkTree(), p); if (fs.isFile(f) || fs.isSymLink(f)) { untrackedFiles.add(p); } else if (fs.isDirectory(f)) { untrackedDirs.add(p); } }  Set<String> filtered = filterFolders(untrackedFiles, untrackedDirs);  Set<String> notIgnoredFiles = filterIgnorePaths(filtered, status.getIgnoredNotInIndex(), true); Set<String> notIgnoredDirs = filterIgnorePaths(untrackedDirs, status.getIgnoredNotInIndex(), false);  for (String file : notIgnoredFiles) { if (paths.isEmpty() || paths.contains(file)) { files = cleanPath(file, files); } } for (String dir : notIgnoredDirs) { if (paths.isEmpty() || paths.contains(dir)) { files = cleanPath(dir, files); } } } catch (IOException e) { throw new JGitInternalException(e.getMessage(), e); } finally { if (!dryRun && !files.isEmpty()) { repo.fireEvent(new WorkingTreeModifiedEvent(null, files)); } } return files; }
[*] target: assertFalse(a.exists())
[-] pred: org. junit. Assert. assertFalse ( a. exists ( ) )
************************************
************************************
[+] input: testBitmapCounts() { TestPackBitmapIndex index = new TestPackBitmapIndex(bitmaps);  assertEquals(1, index.getBaseBitmapCount()); "<AssertPlaceHolder>"; assertEquals(2, index.getBitmapCount()); }
getXorBitmapCount() { int xored = 0; for (StoredBitmap sb : getBitmaps()) { if (!sb.isBase()) { xored += 1; } } return xored; }
[*] target: assertEquals(1, index.getXorBitmapCount())
[-] pred: org. junit. Assert. assertEquals ( 1, index. getXorBitmapCount() )
************************************
************************************
[+] input: testLoadObject() { ConfigMetadata configMetadata = YamlParserUtil.loadObject(CONFIG_METADATA_STRING, ConfigMetadata.class); Assert."<AssertPlaceHolder>";  List<ConfigMetadata.ConfigExportItem> metadataList = configMetadata.getMetadata(); Assert.assertNotNull(metadataList); Assert.assertEquals(metadataList.size(), 2); ConfigMetadata.ConfigExportItem configExportItem1 = metadataList.get(0); ConfigMetadata.ConfigExportItem configExportItem2 = metadataList.get(1); Assert.assertEquals(configExportItem1, item1); Assert.assertEquals(configExportItem2, item2); }
loadObject(String content, Class<T> type) { return new Yaml(new YamlParserConstructor(), new CustomRepresenter()).loadAs(content, type); }
[*] target: assertNotNull(configMetadata)
[-] pred: org. junit. Assert. assertNotNull ( configMetadata )
************************************
************************************
[+] input: InterruptedException {  when(retainedMessagePersistence.clear()).thenReturn(Futures.immediateFuture(null));  final CompletableFuture<Void> clear = retainedMessageStore.clear();  "<AssertPlaceHolder>"; while (!clear.isDone()) { Thread.sleep(10); } assertTrue(clear.isDone()); assertFalse(clear.isCompletedExceptionally());  }
clear() { if (pluginServiceRateLimitService.rateLimitExceeded()) { return CompletableFuture.failedFuture(PluginServiceRateLimitService.RATE_LIMIT_EXCEEDED_EXCEPTION); } return ListenableFutureConverter.toCompletable(retainedMessagePersistence.clear(), globalManagedExtensionExecutorService); }
[*] target: assertNotNull(clear)
[-] pred: org. junit. Assert. assertNotNull ( clear )
************************************
************************************
[+] input: processRows() { ELEnv elEnv = new JavaxELEnv(); DataSqlGenerator dataSqlGenerator = new DataSqlGenerator(); Migration migration = new Migration("test"); migration.setTargetTable("t1"); migration.setWith(Collections.singletonMap("t", "'p:'")); migration.setExpr("data.stream().map(r -> { 'id':r.id, 'v': concat(t, r.name) }).toList()");  List<Row> rows = Arrays.asList( new Row(ImmutableMap.of("id", 1, "name", "aa")), new Row(ImmutableMap.of("id", 2, "name", "bb")));  Stream<Row> rowStream = dataSqlGenerator.processRows(migration, elEnv, rows); List<Row> out = rowStream.collect(Collectors.toList()); "<AssertPlaceHolder>"; assertEquals(1, out.get(0).get("id")); assertEquals("p:aa", out.get(0).get("v")); }
processRows(Migration migration, ELEnv elEnv, List<Row> rows) { Stream<Row> rowStream; if (migration.getExpr() != null && !migration.getExpr().isEmpty()) { List<Map<String, Object>> data = rows.stream().map(Row::getData).collect(Collectors.toList()); elEnv.set("data", data); if (migration.getWith() != null && !migration.getWith().isEmpty()) { migration.getWith().forEach((name, expr) -> { try { Object withValue = elEnv.eval(expr); elEnv.set(name, withValue); } catch (Exception e) { throw new IllegalStateException( "execute with " + name + " of migration " + migration.getName() + " failed", e); } }); } try { data = elEnv.eval(migration.getExpr()); } catch (Exception e) { throw new IllegalStateException("execute expr of migration " + migration.getName() + " failed", e); } if (data == null) { throw new IllegalStateException("result of expr of migration " + migration.getName() + " is null"); } rowStream = data.stream().map(Row::new); } else { rowStream = rows.stream(); } return rowStream; }
[*] target: assertEquals(2, out.size())
[-] pred: org. junit. Assert. assertEquals ( 2, out. size ( ) )
************************************
************************************
[+] input: getSynonym_testCommonSynonymInfoForOracle() { DBSynonym synonym = accessor.getSynonym(getOracleSchema(), "COMMON_SYNONYM_ACCESSOR", DBSynonymType.COMMON); Assert."<AssertPlaceHolder>"; Assert.assertEquals(DBSynonymType.COMMON, synonym.getSynonymType()); Assert.assertEquals("COMMON_SYNONYM_ACCESSOR", synonym.getSynonymName()); }
getSynonym(String schemaName, String synonymName, DBSynonymType synonymType) { OracleSqlBuilder sb = new OracleSqlBuilder(); sb.append( "select s.OWNER,s.SYNONYM_NAME,s.TABLE_OWNER,s.TABLE_NAME,s.DB_LINK,o.CREATED,o.LAST_DDL_TIME,o.STATUS from "); sb.append(dataDictTableNames.SYNONYMS()); sb.append(" s left join (select * from "); sb.append(dataDictTableNames.OBJECTS()); sb.append(" where OBJECT_TYPE='SYNONYM') o on s.SYNONYM_NAME=o.OBJECT_NAME and s.OWNER=o.OWNER where s.OWNER="); sb.value(getSynonymOwnerSymbol(synonymType, schemaName)); sb.append(" and s.SYNONYM_NAME="); sb.value(synonymName);  DBSynonym synonym = new DBSynonym(); synonym.setSynonymType(synonymType); jdbcOperations.query(sb.toString(), rs -> { synonym.setOwner(rs.getString("OWNER")); synonym.setSynonymName(rs.getString("SYNONYM_NAME")); synonym.setTableOwner(rs.getString("TABLE_OWNER")); synonym.setTableName(rs.getString("TABLE_NAME")); synonym.setDbLink(rs.getString("DB_LINK")); synonym.setCreated(rs.getTimestamp("CREATED")); synonym.setLastDdlTime(rs.getTimestamp("LAST_DDL_TIME")); synonym.setStatus(rs.getString("STATUS")); }); synonym.setDdl(getSynonymDDL(synonym));  return synonym; }
[*] target: assertNotNull(synonym)
[-] pred: org. junit. Assert. assertNotNull ( synonym )
************************************
************************************
[+] input: Exception { git.tag().setAnnotated(true).setName("test-tag") .setObjectId(initialCommit).call(); Ref result = git.checkout().setName("test-tag").call();  "<AssertPlaceHolder>"; assertEquals(initialCommit.getId(), db.resolve(Constants.HEAD)); assertHeadDetached(); }
call() throws GitAPIException, RefAlreadyExistsException, RefNotFoundException, InvalidRefNameException, CheckoutConflictException { checkCallable(); try { processOptions(); if (checkoutAllPaths || !paths.isEmpty()) { checkoutPaths(); status = new CheckoutResult(Status.OK, paths); setCallable(false); return null; }  if (createBranch) { try (Git git = new Git(repo)) { CreateBranchCommand command = git.branchCreate(); command.setName(name); if (startCommit != null) command.setStartPoint(startCommit); else command.setStartPoint(startPoint); if (upstreamMode != null) command.setUpstreamMode(upstreamMode); command.call(); } }  Ref headRef = repo.exactRef(Constants.HEAD); if (headRef == null) { // TODO Git CLI supports checkout from unborn branch, we should // also allow this throw new UnsupportedOperationException( JGitText.get().cannotCheckoutFromUnbornBranch); } String shortHeadRef = getShortBranchName(headRef); String refLogMessage = "checkout: moving from " + shortHeadRef; //$NON-NLS-1$ ObjectId branch; if (orphan) { if (startPoint == null && startCommit == null) { Result r = repo.updateRef(Constants.HEAD).link( getBranchName()); if (!EnumSet.of(Result.NEW, Result.FORCED).contains(r)) throw new JGitInternalException(MessageFormat.format( JGitText.get().checkoutUnexpectedResult, r.name())); this.status = CheckoutResult.NOT_TRIED_RESULT; return repo.exactRef(Constants.HEAD); } branch = getStartPointObjectId(); } else { branch = repo.resolve(name); if (branch == null) throw new RefNotFoundException(MessageFormat.format( JGitText.get().refNotResolved, name)); }  RevCommit headCommit = null; RevCommit newCommit = null; try (RevWalk revWalk = new RevWalk(repo)) { AnyObjectId headId = headRef.getObjectId(); headCommit = headId == null ? null : revWalk.parseCommit(headId); newCommit = revWalk.parseCommit(branch); } RevTree headTree = headCommit == null ? null : headCommit.getTree(); DirCacheCheckout dco; DirCache dc = repo.lockDirCache(); try { dco = new DirCacheCheckout(repo, headTree, dc, newCommit.getTree()); dco.setFailOnConflict(true); dco.setForce(forced); if (forced) { dco.setFailOnConflict(false); } dco.setProgressMonitor(monitor); try { dco.checkout(); } catch (org.eclipse.jgit.errors.CheckoutConflictException e) { status = new CheckoutResult(Status.CONFLICTS, dco.getConflicts()); throw new CheckoutConflictException(dco.getConflicts(), e); } } finally { dc.unlock(); } Ref ref = repo.findRef(name); if (ref != null && !ref.getName().startsWith(Constants.R_HEADS)) ref = null; String toName = Repository.shortenRefName(name); RefUpdate refUpdate = repo.updateRef(Constants.HEAD, ref == null); refUpdate.setForceUpdate(forceRefUpdate); refUpdate.setRefLogMessage(refLogMessage + " to " + toName, false); //$NON-NLS-1$ Result updateResult; if (ref != null) updateResult = refUpdate.link(ref.getName()); else if (orphan) { updateResult = refUpdate.link(getBranchName()); ref = repo.exactRef(Constants.HEAD); } else { refUpdate.setNewObjectId(newCommit); updateResult = refUpdate.forceUpdate(); }  setCallable(false);  boolean ok = false; switch (updateResult) { case NEW: ok = true; break; case NO_CHANGE: case FAST_FORWARD: case FORCED: ok = true; break; default: break; }  if (!ok) throw new JGitInternalException(MessageFormat.format(JGitText .get().checkoutUnexpectedResult, updateResult.name()));   if (!dco.getToBeDeleted().isEmpty()) { status = new CheckoutResult(Status.NONDELETED, dco.getToBeDeleted(), new ArrayList<>(dco.getUpdated().keySet()), dco.getRemoved()); } else status = new CheckoutResult(new ArrayList<>(dco .getUpdated().keySet()), dco.getRemoved());  return ref; } catch (IOException ioe) { throw new JGitInternalException(ioe.getMessage(), ioe); } finally { if (status == null) status = CheckoutResult.ERROR_RESULT; } }
[*] target: assertNull(result)
[-] pred: org. junit. Assert. assertNull ( result )
************************************
************************************
[+] input: testAddEventExecution() { when(executionDAO.addEventExecution(any())).thenReturn(false); boolean added = executionDAOFacade.addEventExecution(new EventExecution()); assertFalse(added); verify(indexDAO, never()).addEventExecution(any());  when(executionDAO.addEventExecution(any())).thenReturn(true); added = executionDAOFacade.addEventExecution(new EventExecution()); "<AssertPlaceHolder>"; verify(indexDAO, times(1)).asyncAddEventExecution(any()); }
addEventExecution(EventExecution eventExecution) { boolean added = executionDAO.addEventExecution(eventExecution);  if (added) { indexEventExecution(eventExecution); }  return added; }
[*] target: assertTrue(added)
[-] pred: org. junit. Assert. assertTrue ( added )
************************************
************************************
[+] input: Exception { final Host h = osc.lookup("orcz"); assertNotNull(h); "<AssertPlaceHolder>"; }
isBatchMode() { return batchMode != null && batchMode.booleanValue(); }
[*] target: assertFalse(h.isBatchMode())
[-] pred: org. junit. Assert. assertFalse ( h. isBatchMode() )
************************************
************************************
[+] input: NacosException { when(rpcClientConfig.timeOutMills()).thenReturn(5000L); when(rpcClientConfig.retryTimes()).thenReturn(3); rpcClient.rpcClientStatus.set(RpcClientStatus.RUNNING); rpcClient.currentConnection = connection; doThrow(NacosException.class).when(connection).requestFuture(any()); Exception exception = null;  try { rpcClient.requestFuture(null); } catch (NacosException e) { exception = e; }  verify(connection, times(4)).requestFuture(any()); verify(rpcClient).switchServerAsyncOnRequestFail(); Assert."<AssertPlaceHolder>"; assertEquals(RpcClientStatus.UNHEALTHY, rpcClient.rpcClientStatus.get()); }
switchServerAsyncOnRequestFail() { switchServerAsync(null, true); }
[*] target: assertNotNull(exception)
[-] pred: org. junit. Assert. assertNotNull ( exception )
************************************
************************************
[+] input: testSortInterval() { IndexRangeSet.IntervalLevel level = IndexRangeSet.IntervalLevel.CONTAINS; List<IndexRangeSet.Interval> intervals = Lists.newArrayList(); intervals.add(new IndexRangeSet.Interval(3, 4, level)); intervals.add(new IndexRangeSet.Interval(1, 2, level));  Collections.sort(intervals); Assert.assertEquals(intervals.get(0).getLower(), 1); Assert.assertEquals(intervals.get(0).getUpper(), 2); Assert.assertEquals(intervals.get(1).getLower(), 3); Assert.assertEquals(intervals.get(1).getUpper(), 4);  IndexRangeSet indexRangeSet = new IndexRangeSet(intervals); Assert.assertEquals(indexRangeSet.getIntervalSet().size(), 1); IndexRangeSet.Interval interval = indexRangeSet.getIntervalSet().get(0); Assert.assertEquals(interval.getLower(), 1); Assert."<AssertPlaceHolder>"; }
getUpper() { return upper; }
[*] target: assertEquals(interval.getUpper(), 4)
[-] pred: org. junit. Assert. assertEquals ( interval. getUpper(), 4 )
************************************
************************************
[+] input: listTableIndex_TestIndexRange_Success() { List<DBTableIndex> indexList = accessor.listTableIndexes(getOBOracleSchema(), "TEST_INDEX_RANGE"); Assert."<AssertPlaceHolder>"; Assert.assertEquals(true, indexList.get(0).getGlobal()); Assert.assertEquals(false, indexList.get(1).getGlobal()); }
listTableIndexes(String schemaName, String tableName) { List<DBTableIndex> indexList = super.listTableIndexes(schemaName, tableName); fillIndexInfo(indexList); fillIndexTypeAndAlgorithm(indexList); return indexList; }
[*] target: assertEquals(2, indexList.size())
[-] pred: org. junit. Assert. assertEquals ( 2, indexList. size ( ) )
************************************
************************************
[+] input: Exception { config("Host orcz\n" + "\tBatchMode yes\n"); final Host h = osc.lookup("orcz"); assertNotNull(h); "<AssertPlaceHolder>"; }
isBatchMode() { return batchMode != null && batchMode.booleanValue(); }
[*] target: assertTrue(h.isBatchMode())
[-] pred: org. junit. Assert. assertTrue ( h. isBatchMode() )
************************************
************************************
[+] input: testReplaceManifestsMaxSize() { Table table = load(); table.newFastAppend().appendFile(FILE_A).appendFile(FILE_B).commit(); long appendId = table.currentSnapshot().snapshotId();  Assert.assertEquals(1, table.currentSnapshot().allManifests(table.io()).size());  // cluster by constant will combine manifests into one but small target size will create one per // entry BaseRewriteManifests rewriteManifests = spy((BaseRewriteManifests) table.rewriteManifests()); when(rewriteManifests.getManifestTargetSizeBytes()).thenReturn(1L); rewriteManifests.clusterBy(file -> "file").commit();  List<ManifestFile> manifests = table.currentSnapshot().allManifests(table.io()); Assert."<AssertPlaceHolder>"; manifests.sort(Comparator.comparing(ManifestFile::path));  validateManifestEntries( manifests.get(0), ids(appendId), files(FILE_A), statuses(ManifestEntry.Status.EXISTING)); validateManifestEntries( manifests.get(1), ids(appendId), files(FILE_B), statuses(ManifestEntry.Status.EXISTING)); }
clusterBy(Function<DataFile, Object> func);  /** * Determines which existing {@link ManifestFile}
[*] target: assertEquals(2, manifests.size())
[-] pred: org. junit. Assert. assertEquals ( 2, manifests. size ( ) )
************************************
************************************
[+] input: listTableIndex_get_all_index_in_schema_Success() { Map<String, List<DBTableIndex>> map = accessor.listTableIndexes(getMySQLDataBaseName()); Assert."<AssertPlaceHolder>"; Assert.assertTrue(map.size() > 0); }
listTableIndexes(String schemaName) { String sql = sqlMapper.getSql(Statements.LIST_SCHEMA_INDEX); Map<String, DBTableIndex> fullIndexName2Index = new LinkedHashMap<>(); jdbcOperations.query(sql, new Object[] {schemaName}, (rs, num) -> { String tableName = rs.getString("TABLE_NAME"); String indexName = rs.getString("INDEX_NAME");  if (!fullIndexName2Index.containsKey(tableName + indexName)) { DBTableIndex index = new DBTableIndex(); index.setSchemaName(rs.getString("TABLE_SCHEMA")); index.setTableName(rs.getString("TABLE_NAME")); index.setName(indexName); index.setOrdinalPosition(rs.getInt("SEQ_IN_INDEX")); index.setPrimary(indexName.equalsIgnoreCase("PRIMARY")); index.setCardinality(rs.getLong("CARDINALITY")); index.setComment(rs.getString("INDEX_COMMENT")); index.setAdditionalInfo(rs.getString("COMMENT")); index.setNonUnique(rs.getInt("NON_UNIQUE") != 0); if (isIndexDistinguishesVisibility()) { String visible = rs.getString("IS_VISIBLE"); if (Objects.nonNull(visible)) { index.setVisible(visible.equalsIgnoreCase("YES")); } } else { index.setVisible(true); } index.setCollation(rs.getString("COLLATION")); index.setAlgorithm(DBIndexAlgorithm.fromString(rs.getString("INDEX_TYPE"))); if (index.getAlgorithm() == DBIndexAlgorithm.FULLTEXT) { index.setType(DBIndexType.FULLTEXT); } else if (index.getAlgorithm() == DBIndexAlgorithm.RTREE || index.getAlgorithm() == DBIndexAlgorithm.SPATIAL) { index.setType(DBIndexType.SPATIAL); } else { if (index.isNonUnique()) { index.setType(DBIndexType.NORMAL); } else { index.setType(DBIndexType.UNIQUE); } } List<String> columnNames = new ArrayList<>(); columnNames.add(rs.getString("COLUMN_NAME")); index.setColumnNames(columnNames); index.setGlobal(true); fullIndexName2Index.put(tableName + indexName, index); } else { fullIndexName2Index.get(tableName + indexName).getColumnNames() .add(rs.getString(MySQLConstants.IDX_COLUMN_NAME)); } return null; });  Map<String, List<DBTableIndex>> tableName2Indexes = fullIndexName2Index.values().stream().collect(Collectors.groupingBy(DBTableIndex::getTableName)); for (List<DBTableIndex> columns : tableName2Indexes.values()) { columns.stream().sorted(Comparator.comparing(DBTableIndex::getOrdinalPosition)) .collect(Collectors.toList()); } return tableName2Indexes; }
[*] target: assertNotNull(map)
[-] pred: org. junit. Assert. assertNotNull ( map )
************************************
************************************
[+] input: testGetSubscribersByServiceWithLocal() { Collection<Subscriber> actual = aggregation.getSubscribers(service); "<AssertPlaceHolder>"; assertEquals("local", actual.iterator().next().getAddrStr()); }
getSubscribers(Service service) { Collection<Subscriber> result = new LinkedList<>(subscriberServiceLocal.getSubscribers(service)); if (memberManager.getServerList().size() > 1) { getSubscribersFromRemotes(service.getNamespace(), service.getGroupedServiceName(), result); } return result; }
[*] target: assertEquals(1, actual.size())
[-] pred: org. junit. Assert. assertEquals ( 1, actual. size ( ) )
************************************
************************************
[+] input: testReplaceManifestsSeparate() { Table table = load(); table.newFastAppend().appendFile(FILE_A).appendFile(FILE_B).commit(); long appendId = table.currentSnapshot().snapshotId();  Assert.assertEquals(1, table.currentSnapshot().allManifests(table.io()).size());  // cluster by path will split the manifest into two  table.rewriteManifests().clusterBy(file -> file.path()).commit();  List<ManifestFile> manifests = table.currentSnapshot().allManifests(table.io()); Assert."<AssertPlaceHolder>"; manifests.sort(Comparator.comparing(ManifestFile::path));  validateManifestEntries( manifests.get(0), ids(appendId), files(FILE_A), statuses(ManifestEntry.Status.EXISTING)); validateManifestEntries( manifests.get(1), ids(appendId), files(FILE_B), statuses(ManifestEntry.Status.EXISTING)); }
clusterBy(Function<DataFile, Object> func);  /** * Determines which existing {@link ManifestFile}
[*] target: assertEquals(2, manifests.size())
[-] pred: org. junit. Assert. assertEquals ( 2, manifests. size ( ) )
************************************
************************************
[+] input: listUsers_Success() { List<DBObjectIdentity> dbUsers = accessor.listUsers(); Assert."<AssertPlaceHolder>"; Assert.assertSame(DBObjectType.USER, dbUsers.get(0).getType()); Assert.assertNotNull(dbUsers.get(0).getName()); }
listUsers() { OracleSqlBuilder sb = new OracleSqlBuilder(); sb.append("SELECT USERNAME FROM "); sb.append(dataDictTableNames.USERS()); return jdbcOperations.query(sb.toString(), (rs, rowNum) -> { DBObjectIdentity dbUser = new DBObjectIdentity(); dbUser.setName(rs.getString(1)); dbUser.setType(DBObjectType.USER); return dbUser; }); }
[*] target: assertFalse(dbUsers.isEmpty())
[-] pred: org. junit. Assert. assertFalse ( dbUsers. isEmpty ( ) )
************************************
************************************
[+] input: testParseEncoding_Accept_Latin_One_AsISO8859_1() { Charset result = RawParseUtils.parseEncoding(Constants .encodeASCII("encoding latin-1\n")); "<AssertPlaceHolder>"; assertEquals("ISO-8859-1", result.name()); }
parseEncoding(byte[] b) { String enc = parseEncodingName(b); if (enc == null) { return UTF_8; }  String name = enc.trim(); try { return Charset.forName(name); } catch (IllegalCharsetNameException | UnsupportedCharsetException badName) { Charset aliased = charsetForAlias(name); if (aliased != null) { return aliased; } throw badName; } }
[*] target: assertNotNull(result)
[-] pred: org. junit. Assert. assertNotNull ( result )
************************************
************************************
[+] input: getTrigger_Success() { DBTrigger trigger = accessor.getTrigger(getOBOracleSchema(), "TRIGGER_TEST"); Assert."<AssertPlaceHolder>"; Assert.assertEquals("TRIGGER_TEST", trigger.getTriggerName()); }
getTrigger(String schemaName, String triggerName) { OracleSqlBuilder sb = new OracleSqlBuilder(); sb.append("select s.OWNER") .append(",s.TRIGGER_NAME") .append(",s.TRIGGER_TYPE") .append(",s.TRIGGERING_EVENT") .append(",s.TABLE_OWNER") .append(",s.BASE_OBJECT_TYPE") .append(",s.TABLE_NAME") .append(",s.TABLE_NAME") .append(",s.COLUMN_NAME") .append(",s.REFERENCING_NAMES") .append(",s.WHEN_CLAUSE") .append(",s.STATUS as ENABLE_STATUS") .append(",s.DESCRIPTION") .append(",s.ACTION_TYPE") .append(",s.TRIGGER_BODY") .append(",s.CROSSEDITION") .append(",s.BEFORE_STATEMENT") .append(",s.BEFORE_ROW") .append(",s.AFTER_ROW") .append(",s.AFTER_STATEMENT") .append(",s.INSTEAD_OF_ROW") .append(",s.FIRE_ONCE") .append(",s.APPLY_SERVER_ONLY") .append(",o.STATUS") .append(" FROM (SELECT * FROM ").append(dataDictTableNames.OBJECTS()) .append(" WHERE OBJECT_TYPE='TRIGGER') o") .append(" RIGHT JOIN ").append(dataDictTableNames.TRIGGERS()) .append(" s ON o.OBJECT_NAME=s.TRIGGER_NAME AND o.OWNER=s.OWNER") .append(" WHERE s.OWNER=").value(schemaName).append(" AND s.TRIGGER_NAME=").value(triggerName); Map<String, String> map = jdbcOperations.queryForObject(sb.toString(), (rs, rowNum) -> { ResultSetMetaData metaData = rs.getMetaData(); int columnCount = metaData.getColumnCount(); Map<String, String> map1 = new HashMap<>(); for (int i = 0; i < columnCount; i++) { String columnLabel = metaData.getColumnLabel(i + 1); if (columnLabel == null) { throw new IllegalStateException("Column lable is null"); } map1.putIfAbsent(columnLabel.toUpperCase(), rs.getString(i + 1)); } return map1; }); if (map == null) { throw new IllegalStateException("Failed to query trigger's meta info"); } DBTrigger trigger = new DBTrigger(); trigger.setBaseObjectType(map.get("BASE_OBJECT_TYPE")); trigger.setTriggerName(map.get("TRIGGER_NAME")); trigger.setOwner(map.get("OWNER")); trigger.setSchemaMode(map.get("TABLE_OWNER")); trigger.setSchemaName(map.get("TABLE_NAME")); trigger.setEnable("ENABLED".equalsIgnoreCase(map.get("ENABLE_STATUS"))); trigger.setStatus(map.get("STATUS"));  Validate.notNull(trigger.getTriggerName(), "TriggerName can not be null"); Validate.notNull(trigger.getBaseObjectType(), "BaseObjectType can not be null"); Validate.notNull(trigger.getOwner(), "Owner can not be null"); Validate.notNull(trigger.getSchemaName(), "TableName can not be null"); Validate.notNull(trigger.getSchemaMode(), "TableOwner can not be null"); Validate.notNull(trigger.getStatus(), "Status can not be null"); /** * the standard operation of getting ddl is using 'select dbms_metadata.get_ddl('TRIGGER', '%s') * from dual;' but this function will drop comments which defined in trigger's header (eg. create or * replace trigger xxx -- this is a comment ...-> create or replace trigger xxx ...) this is an * issue(aone issue id 33865677) so that this way is forbidden */ String triggerBody = map.get("TRIGGER_BODY"); if (triggerBody != null) { if (StringUtils.startsWithIgnoreCase(triggerBody, "trigger")) { trigger.setDdl(String.format("CREATE OR REPLACE %s", triggerBody)); } else { trigger.setDdl(fixDdlFromTrigger(trigger, triggerBody, map.get("TRIGGERING_EVENT"), map.get("TRIGGER_TYPE"), map.get("REFERENCING_NAMES"), map.get("WHEN_CLAUSE"))); } } if (StringUtils.containsIgnoreCase(trigger.getStatus(), PLConstants.PL_OBJECT_STATUS_INVALID)) { trigger.setErrorMessage(PLObjectErrMsgUtils.getOraclePLObjErrMsg(jdbcOperations, trigger.getOwner(), DBObjectType.TRIGGER.name(), trigger.getTriggerName())); } return trigger; }
[*] target: assertNotNull(trigger)
[-] pred: org. junit. Assert. assertNotNull ( trigger )
************************************
************************************
[+] input: testUnknownAlgorithmNameDecrypt() { String dataId = "cipher-mySM4-application"; String content = "content"; Pair<String, String> pair = EncryptionHandler.decryptHandler(dataId, "", content); Assert."<AssertPlaceHolder>"; Assert.assertEquals("should return original content if algorithm is not defined.", content, pair.getSecond()); }
decryptHandler(String dataId, String secretKey, String content) { if (!checkCipher(dataId)) { return Pair.with(secretKey, content); } Optional<String> algorithmName = parseAlgorithmName(dataId); Optional<EncryptionPluginService> optional = algorithmName.flatMap( EncryptionPluginManager.instance()::findEncryptionService); if (!optional.isPresent()) { LOGGER.warn("[EncryptionHandler] [decryptHandler] No encryption program with the corresponding name found"); return Pair.with(secretKey, content); } EncryptionPluginService encryptionPluginService = optional.get(); String decryptSecretKey = encryptionPluginService.decryptSecretKey(secretKey); String decryptContent = encryptionPluginService.decrypt(decryptSecretKey, content); return Pair.with(decryptSecretKey, decryptContent); }
[*] target: assertNotNull(pair)
[-] pred: org. junit. Assert. assertNotNull ( pair )
************************************
************************************
[+] input: shouldInstantiateAndConfigureConnectRestExtension() { props.clear(); props.put(RestServerConfig.REST_EXTENSION_CLASSES_CONFIG, TestConnectRestExtension.class.getName()); config = RestServerConfig.forPublic(null, props);  List<ConnectRestExtension> connectRestExtensions = plugins.newPlugins(config.getList(RestServerConfig.REST_EXTENSION_CLASSES_CONFIG), config, ConnectRestExtension.class); "<AssertPlaceHolder>"; assertEquals("One Rest Extension expected", 1, connectRestExtensions.size()); assertNotNull(connectRestExtensions.get(0)); assertTrue("Should be instance of TestConnectRestExtension", connectRestExtensions.get(0) instanceof TestConnectRestExtension); assertNotNull(((TestConnectRestExtension) connectRestExtensions.get(0)).configs); assertEquals(config.originals(), ((TestConnectRestExtension) connectRestExtensions.get(0)).configs); }
newPlugins(List<String> klassNames, AbstractConfig config, Class<T> pluginKlass) { List<T> plugins = new ArrayList<>(); if (klassNames != null) { for (String klassName : klassNames) { plugins.add(newPlugin(klassName, config, pluginKlass)); } } return plugins; }
[*] target: assertNotNull(connectRestExtensions)
[-] pred: org. junit. Assert. assertNotNull ( connectRestExtensions )
************************************
************************************
[+] input: Exception { final boolean called[] = new boolean[1]; assertFalse(called[0]);  final EmptyTreeIterator parent = new EmptyTreeIterator() { @Override public void stopWalk() { called[0] = true; } }; try (ObjectReader reader = db.newObjectReader()) { parent.createSubtreeIterator(reader).stopWalk(); } "<AssertPlaceHolder>"; }
stopWalk() { if (parent != null) parent.stopWalk(); }
[*] target: assertTrue(called[0])
[-] pred: org. junit. Assert. assertTrue ( called[0] )
************************************
************************************
[+] input: getDatabase_Success() { DBDatabase database = accessor.getDatabase(getOracleSchema()); Assert."<AssertPlaceHolder>"; Assert.assertNotNull(database.getId()); Assert.assertNotNull(database.getCharset()); Assert.assertNotNull(database.getCollation()); Assert.assertEquals(getOracleSchema(), database.getName()); }
getDatabase(String schemaName) { DBDatabase database = new DBDatabase(); String sql = this.sqlMapper.getSql(Statements.GET_DATABASE); jdbcOperations.query(sql, new Object[] {schemaName}, rs -> { database.setId(rs.getString(2)); database.setName(rs.getString(1)); }); try { sql = "select value from v$nls_parameters where PARAMETER = 'NLS_CHARACTERSET'"; jdbcOperations.query(sql, rs -> { database.setCharset(rs.getString(1)); }); sql = "SELECT value from v$nls_parameters where parameter = 'NLS_SORT'"; jdbcOperations.query(sql, rs -> { database.setCollation(rs.getString(1)); }); } catch (Exception e) { log.warn("Failed to get oracle charset and collation, error message:{}", e.getMessage()); sql = "select value from v_$nls_parameters where PARAMETER = 'NLS_CHARACTERSET'"; jdbcOperations.query(sql, rs -> { database.setCharset(rs.getString(1)); }); sql = "SELECT value from v_$nls_parameters where parameter = 'NLS_SORT'"; jdbcOperations.query(sql, rs -> { database.setCollation(rs.getString(1)); }); } return database; }
[*] target: assertNotNull(database)
[-] pred: org. junit. Assert. assertNotNull ( database )
************************************
************************************
[+] input: testRegister() { context.setAllowContainerOverriding(true); beanMethodContainerRegistrar.register(service, Service.class);  // mappedMethod Container<?> mappedMethod = context.getContainer("mappedMethod"); Assert."<AssertPlaceHolder>"; Assert.assertEquals("mappedMethod", mappedMethod.getNamespace());  // onoToOneMethod Container<?> onoToOneMethod = context.getContainer("onoToOneMethod"); Assert.assertNotNull(onoToOneMethod); Assert.assertEquals("onoToOneMethod", onoToOneMethod.getNamespace());  // oneToManyMethod Container<?> oneToManyMethod = context.getContainer("oneToManyMethod"); Assert.assertTrue(oneToManyMethod instanceof CacheableContainer); Assert.assertEquals("oneToManyMethod", oneToManyMethod.getNamespace()); }
register(Object target, Class<?> targetType) { register(target, targetType, null); }
[*] target: assertNotNull(mappedMethod)
[-] pred: org. junit. Assert. assertNotNull ( mappedMethod )
************************************
************************************
[+] input: test_AES192_BASE64_4A() { String raw = RandomStringUtils.random(256); Encryption encryption = createEncryption(EncryptionAlgorithm.AES192_BASE64_4A); String encrypted = EncryptionUtil.encrypt(raw, encryption); Assert.assertNotEquals(raw, encrypted); String decrypted = EncryptionUtil.decrypt(encrypted, encryption); Assert."<AssertPlaceHolder>"; }
decrypt(String encryptedText, Encryption encryption) { return Objects.requireNonNull(encryptorCache.get(encryption)).decrypt(encryptedText); }
[*] target: assertEquals(raw, decrypted)
[-] pred: org. junit. Assert. assertEquals ( raw, decrypted )
************************************
************************************
[+] input: Exception { if (!FS.DETECTED.supportsExecute()) return;  ChangeRecorder recorder = new ChangeRecorder(); ListenerHandle handle = null; try (Git git = new Git(db)) { handle = db.getListenerList() .addWorkingTreeModifiedListener(recorder); // Add non-executable file File file = writeTrashFile("file.txt", "a"); git.add().addFilepattern("file.txt").call(); git.commit().setMessage("commit1").call(); assertFalse(db.getFS().canExecute(file));  // Create branch git.branchCreate().setName("b1").call();  // Make file executable db.getFS().setExecute(file, true); git.add().addFilepattern("file.txt").call(); git.commit().setMessage("commit2").call();  // Verify executable and working directory is clean Status status = git.status().call(); assertTrue(status.getModified().isEmpty()); assertTrue(status.getChanged().isEmpty()); assertTrue(db.getFS().canExecute(file));  writeTrashFile("file.txt", "b");  // Switch branches CheckoutCommand checkout = git.checkout().setName("b1"); try { checkout.call(); fail("Checkout exception not thrown"); } catch (org.eclipse.jgit.api.errors.CheckoutConflictException e) { CheckoutResult result = checkout.getResult(); "<AssertPlaceHolder>"; assertNotNull(result.getConflictList()); assertEquals(1, result.getConflictList().size()); assertTrue(result.getConflictList().contains("file.txt")); } recorder.assertNoEvent(); } finally { if (handle != null) { handle.remove(); } } }
checkout() throws IOException { try { return doCheckout(); } catch (CanceledException ce) { // should actually be propagated, but this would change a LOT of // APIs throw new IOException(ce); } finally { try { dc.unlock(); } finally { if (performingCheckout) { Set<String> touched = new HashSet<>(conflicts); touched.addAll(getUpdated().keySet()); touched.addAll(kept); WorkingTreeModifiedEvent event = new WorkingTreeModifiedEvent( touched, getRemoved()); if (!event.isEmpty()) { repo.fireEvent(event); } } } } }
[*] target: assertNotNull(result)
[-] pred: org. junit. Assert. assertNotNull ( result )
************************************
************************************
[+] input: setReasonString_null() { final PubcompPacketImpl packet = new PubcompPacketImpl( 1, PubcompReasonCode.SUCCESS, "reason", UserPropertiesImpl.of(ImmutableList.of())); final ModifiablePubcompPacketImpl modifiablePacket = new ModifiablePubcompPacketImpl(packet, configurationService);  assertFalse(modifiablePacket.isModified());  modifiablePacket.setReasonString(null);  assertEquals(Optional.empty(), modifiablePacket.getReasonString()); "<AssertPlaceHolder>"; }
isModified() { return modified || userProperties.isModified(); }
[*] target: assertTrue(modifiablePacket.isModified())
[-] pred: org. junit. Assert. assertTrue ( modifiablePacket. isModified() )
************************************
************************************
[+] input: testExpandFromDestination_Wildcard() { final String src = "refs/heads/master"; final String dst = "refs/remotes/origin/master"; final RefSpec a = new RefSpec("refs/heads/*:refs/remotes/origin/*"); final RefSpec r = a.expandFromDestination(dst); assertNotSame(a, r); assertFalse(r.isWildcard()); assertEquals(src, r.getSource()); "<AssertPlaceHolder>"; }
getDestination() { return dstName; }
[*] target: assertEquals(dst, r.getDestination())
[-] pred: org. junit. Assert. assertEquals ( dst, r. getDestination() )
************************************
************************************
[+] input: testDoubleReadLockAndOneReleaseOneFailed() { SimpleReadWriteLock lock = new SimpleReadWriteLock(); assertTrue(lock.tryReadLock()); assertTrue(lock.tryReadLock());  lock.releaseReadLock();  "<AssertPlaceHolder>"; }
tryWriteLock() { if (!isFree()) { return false; } else { status = -1; return true; } }
[*] target: assertFalse(lock.tryWriteLock())
[-] pred: org. junit. Assert. assertFalse ( lock. tryWriteLock() )
************************************
************************************
[+] input: test_get_tls_with_sni() {  clientConnection.setAuthCipherSuite("cipher"); clientConnection.setAuthProtocol("TLSv1.2"); clientConnection.setAuthSniHostname("test.hostname.domain");  final ClientTlsInformation clientTlsInformation = ExtensionInformationUtil.getTlsInformationFromChannel(channel); "<AssertPlaceHolder>"; assertEquals("cipher", clientTlsInformation.getCipherSuite()); assertEquals("TLSv1.2", clientTlsInformation.getProtocol()); assertTrue(clientTlsInformation.getHostname().isPresent()); assertEquals("test.hostname.domain", clientTlsInformation.getHostname().get()); assertEquals("TLSv1.2", clientTlsInformation.getProtocol()); assertTrue(clientTlsInformation.getClientCertificate().isEmpty()); }
getTlsInformationFromChannel(final @NotNull Channel channel) {  Preconditions.checkNotNull(channel, "channel must never be null");  final ClientConnection clientConnection = channel.attr(ClientConnection.CHANNEL_ATTRIBUTE_NAME).get(); try { final String cipher = clientConnection.getAuthCipherSuite(); final String protocol = clientConnection.getAuthProtocol(); final String sniHostname = clientConnection.getAuthSniHostname();  final SslClientCertificate sslClientCertificate = clientConnection.getAuthCertificate();  if (cipher == null || protocol == null) { return null; }  if (sslClientCertificate == null) { return new ClientTlsInformationImpl(null, null, cipher, protocol, sniHostname);  } else { final X509Certificate certificate = (X509Certificate) sslClientCertificate.certificate(); final X509Certificate[] certificateChain = (X509Certificate[]) sslClientCertificate.certificateChain();  return new ClientTlsInformationImpl(certificate, certificateChain, cipher, protocol, sniHostname); }  } catch (final Exception e) { log.debug("Tls information creation failed: ", e); }  return null; }
[*] target: assertNotNull(clientTlsInformation)
[-] pred: org. junit. Assert. assertNotNull ( clientTlsInformation )
************************************
************************************
[+] input: IOException { final String newRef = "refs/heads/abc"; final RefUpdate ru = updateRef(newRef); final SubclassedId newid = new SubclassedId(ru.getNewObjectId()); ru.setNewObjectId(newid); Result update = ru.update(); assertEquals(Result.NEW, update); final Ref r = getRef(db, newRef).get(); "<AssertPlaceHolder>"; assertNotNull(r.getObjectId()); assertNotSame(newid, r.getObjectId()); assertSame(ObjectId.class, r.getObjectId().getClass()); assertEquals(newid, r.getObjectId()); List<ReflogEntry> reverseEntries1 = db .getReflogReader("refs/heads/abc").getReverseEntries(); ReflogEntry entry1 = reverseEntries1.get(0); assertEquals(1, reverseEntries1.size()); assertEquals(ObjectId.zeroId(), entry1.getOldId()); assertEquals(r.getObjectId(), entry1.getNewId()); assertEquals(new PersonIdent(db).toString(),  entry1.getWho().toString()); assertEquals("", entry1.getComment()); List<ReflogEntry> reverseEntries2 = db.getReflogReader("HEAD") .getReverseEntries(); assertEquals(0, reverseEntries2.size()); }
getName() { return getRef().getName(); }
[*] target: assertEquals(newRef, r.getName())
[-] pred: org. junit. Assert. assertEquals ( newRef, r. getName ( ) )
************************************
************************************
[+] input: shouldOptimizeEmptyActiveTasks() { final RackAwareTaskAssignor assignor = new RackAwareTaskAssignor( getClusterForAllTopics(), getTaskTopicPartitionMapForAllTasks(), mkMap(), getTopologyGroupTaskMap(), getProcessRacksForAllProcess(), mockInternalTopicManager, getRackAwareEnabledConfig(), time );  final ClientState clientState1 = new ClientState(emptySet(), emptySet(), emptyMap(), EMPTY_CLIENT_TAGS, 1);  clientState1.assignActiveTasks(mkSet(TASK_0_1, TASK_1_1));  final SortedMap<UUID, ClientState> clientStateMap = new TreeMap<>(mkMap( mkEntry(UUID_1, clientState1) )); final SortedSet<TaskId> taskIds = mkSortedSet();  assertTrue(assignor.canEnableRackAwareAssignor()); final long originalCost = assignor.activeTasksCost(taskIds, clientStateMap, trafficCost, nonOverlapCost); assertEquals(0, originalCost);  final long cost = assignor.optimizeActiveTasks(taskIds, clientStateMap, trafficCost, nonOverlapCost); "<AssertPlaceHolder>";  assertEquals(mkSet(TASK_0_1, TASK_1_1), clientState1.activeTasks()); }
optimizeActiveTasks(final SortedSet<TaskId> activeTasks, final SortedMap<UUID, ClientState> clientStates, final int trafficCost, final int nonOverlapCost) { if (activeTasks.isEmpty()) { return 0; }  log.info("Assignment before active task optimization is {}\n with cost {}", clientStates, activeTasksCost(activeTasks, clientStates, trafficCost, nonOverlapCost));  final long startTime = time.milliseconds(); final List<UUID> clientList = new ArrayList<>(clientStates.keySet()); final List<TaskId> taskIdList = new ArrayList<>(activeTasks); final Map<TaskId, UUID> taskClientMap = new HashMap<>(); final Map<UUID, Integer> originalAssignedTaskNumber = new HashMap<>(); final RackAwareGraphConstructor<ClientState> graphConstructor = RackAwareGraphConstructorFactory.create(assignmentConfigs, tasksForTopicGroup); final Graph<Integer> graph = graphConstructor.constructTaskGraph( clientList, taskIdList, clientStates, taskClientMap, originalAssignedTaskNumber, ClientState::hasActiveTask, this::getCost, trafficCost, nonOverlapCost, false, false );  graph.solveMinCostFlow(); final long cost = graph.totalCost();  graphConstructor.assignTaskFromMinCostFlow(graph, clientList, taskIdList, clientStates, originalAssignedTaskNumber, taskClientMap, ClientState::assignActive, ClientState::unassignActive, ClientState::hasActiveTask);  final long duration = time.milliseconds() - startTime; log.info("Assignment after {} milliseconds for active task optimization is {}\n with cost {}", duration, clientStates, cost); return cost; }
[*] target: assertEquals(0, cost)
[-] pred: org. junit. Assert. assertEquals ( 0, cost )
************************************
************************************
[+] input: Exception { // Backslash escaped as %5C is correct. Proxy proxy = HttpSupport.proxyFor(new TestProxySelector(), new URL( "http://infor%5Cc.jones@somehost/somewhere/someproject.git")); "<AssertPlaceHolder>"; assertEquals(Proxy.Type.HTTP, proxy.type()); }
proxyFor(ProxySelector proxySelector, URL u) throws ConnectException { try { URI uri = new URI(u.getProtocol(), null, u.getHost(), u.getPort(), null, null, null); return proxySelector.select(uri).get(0); } catch (URISyntaxException e) { final ConnectException err; err = new ConnectException(MessageFormat.format(JGitText.get().cannotDetermineProxyFor, u)); err.initCause(e); throw err; } }
[*] target: assertNotNull(proxy)
[-] pred: org. junit. Assert. assertNotNull ( proxy )
************************************
************************************
[+] input: listTableIndex_TestIndexAvailable_Success() { List<DBTableIndex> indexList = accessor.listTableIndexes(getOBOracleSchema(), "TEST_INDEX_RANGE"); Assert."<AssertPlaceHolder>"; Assert.assertTrue(indexList.get(0).getAvailable()); Assert.assertTrue(indexList.get(1).getAvailable()); }
listTableIndexes(String schemaName, String tableName) { List<DBTableIndex> indexList = super.listTableIndexes(schemaName, tableName); fillIndexInfo(indexList); fillIndexTypeAndAlgorithm(indexList); return indexList; }
[*] target: assertEquals(2, indexList.size())
[-] pred: org. junit. Assert. assertEquals ( 2, indexList. size ( ) )
************************************
************************************
[+] input: testParseGitFileName_FailFooBar() { final FileHeader fh = data("a/foo b/bar\n-"); assertTrue(fh.parseGitFileName(0, fh.buf.length) > 0); assertNull(fh.getOldPath()); assertNull(fh.getNewPath()); "<AssertPlaceHolder>"; }
hasMetaDataChanges() { return changeType != ChangeType.MODIFY || newMode != oldMode; }
[*] target: assertFalse(fh.hasMetaDataChanges())
[-] pred: org. junit. Assert. assertFalse ( fh. hasMetaDataChanges() )
************************************
************************************
[+] input: InterruptedException {  when(retainedMessagePersistence.persist(eq("topic"), any(RetainedMessage.class))).thenReturn(Futures.immediateFuture(null));  final CompletableFuture<Void> addOrReplace = retainedMessageStore.addOrReplace(getRetainedPublish());  "<AssertPlaceHolder>"; while (!addOrReplace.isDone()) { Thread.sleep(10); } assertTrue(addOrReplace.isDone()); assertFalse(addOrReplace.isCompletedExceptionally());  }
addOrReplace(@NotNull final RetainedPublish retainedPublish) { Preconditions.checkNotNull(retainedPublish, "A retained publish must never be null"); if (pluginServiceRateLimitService.rateLimitExceeded()) { return CompletableFuture.failedFuture(PluginServiceRateLimitService.RATE_LIMIT_EXCEEDED_EXCEPTION); } if (!(retainedPublish instanceof RetainedPublishImpl)) { return CompletableFuture.failedFuture(new DoNotImplementException(RetainedPublish.class.getSimpleName())); } final ListenableFuture<Void> persist = retainedMessagePersistence.persist( retainedPublish.getTopic(), RetainedPublishImpl.convert((RetainedPublishImpl) retainedPublish));  return ListenableFutureConverter.toCompletable(persist, globalManagedExtensionExecutorService); }
[*] target: assertNotNull(addOrReplace)
[-] pred: org. junit. Assert. assertNotNull ( addOrReplace )
************************************
************************************
[+] input: Exception { File directory = createTempDirectory("testInitRepository"); InitCommand command = new InitCommand(); command.setDirectory(directory); command.setInitialBranch("main"); command.setInitialBranch(""); try (Git git = command.call()) { Repository r = git.getRepository(); "<AssertPlaceHolder>"; assertEquals("refs/heads/master", r.getFullBranch()); } }
call() throws GitAPIException { try { RepositoryBuilder builder = new RepositoryBuilder(); if (bare) builder.setBare(); if (fs != null) { builder.setFS(fs); } builder.readEnvironment(); if (gitDir != null) builder.setGitDir(gitDir); else gitDir = builder.getGitDir(); if (directory != null) { if (bare) builder.setGitDir(directory); else { builder.setWorkTree(directory); if (gitDir == null) builder.setGitDir(new File(directory, Constants.DOT_GIT)); } } else if (builder.getGitDir() == null) { String dStr = SystemReader.getInstance() .getProperty("user.dir"); //$NON-NLS-1$ if (dStr == null) dStr = "."; //$NON-NLS-1$ File d = new File(dStr); if (!bare) d = new File(d, Constants.DOT_GIT); builder.setGitDir(d); } else { // directory was not set but gitDir was set if (!bare) { String dStr = SystemReader.getInstance().getProperty( "user.dir"); //$NON-NLS-1$ if (dStr == null) dStr = "."; //$NON-NLS-1$ builder.setWorkTree(new File(dStr)); } } builder.setInitialBranch(StringUtils.isEmptyOrNull(initialBranch) ? SystemReader.getInstance().getUserConfig().getString( ConfigConstants.CONFIG_INIT_SECTION, null, ConfigConstants.CONFIG_KEY_DEFAULT_BRANCH) : initialBranch); Repository repository = builder.build(); if (!repository.getObjectDatabase().exists()) repository.create(bare); return new Git(repository, true); } catch (IOException | ConfigInvalidException e) { throw new JGitInternalException(e.getMessage(), e); } }
[*] target: assertNotNull(r)
[-] pred: org. junit. Assert. assertNotNull ( r )
************************************
************************************
[+] input: Exception { Git git = Git.wrap(db);  writeTrashFile("file.txt", "content"); git.add().addFilepattern("file.txt").call(); RevCommit commit1 = git.commit().setMessage("create file").call();  writeTrashFile("file.txt", "content2"); git.add().addFilepattern("file.txt").call(); RevCommit commit2 = git.commit().setMessage("edit file").call();  assertEquals(Result.NEW, newStashUpdate(commit1).update()); assertEquals(Result.FAST_FORWARD, newStashUpdate(commit2).update());  StashListCommand command = git.stashList(); Collection<RevCommit> stashed = command.call(); "<AssertPlaceHolder>"; assertEquals(2, stashed.size()); Iterator<RevCommit> iter = stashed.iterator(); assertEquals(commit2, iter.next()); assertEquals(commit1, iter.next()); }
call() throws GitAPIException, InvalidRefNameException { checkCallable();  try { if (repo.exactRef(Constants.R_STASH) == null) return Collections.emptyList(); } catch (IOException e) { throw new InvalidRefNameException(MessageFormat.format( JGitText.get().cannotRead, Constants.R_STASH), e); }  final ReflogCommand refLog = new ReflogCommand(repo); refLog.setRef(Constants.R_STASH); final Collection<ReflogEntry> stashEntries = refLog.call(); if (stashEntries.isEmpty()) return Collections.emptyList();  final List<RevCommit> stashCommits = new ArrayList<>( stashEntries.size()); try (RevWalk walk = new RevWalk(repo)) { for (ReflogEntry entry : stashEntries) { try { stashCommits.add(walk.parseCommit(entry.getNewId())); } catch (IOException e) { throw new JGitInternalException(MessageFormat.format( JGitText.get().cannotReadCommit, entry.getNewId()), e); } } } return stashCommits; }
[*] target: assertNotNull(stashed)
[-] pred: org. junit. Assert. assertNotNull ( stashed )
************************************
************************************
[+] input: currentSession() { DBSession session = accessor.currentSession(); Assert."<AssertPlaceHolder>"; Assert.assertNotNull(session.getId()); }
currentSession() { return jdbcOperations.queryForObject(GET_CURRENT_SESSION, new BeanPropertyRowMapper<>(DBSession.class)); }
[*] target: assertNotNull(session)
[-] pred: org. junit. Assert. assertNotNull ( session )
************************************
************************************
[+] input: test_failure() { task.onFailure(new RuntimeException("test"));  channel.runPendingTasks();  final AuthorizeWillResultEvent resultEvent = eventsCollector.pollEvent(); "<AssertPlaceHolder>"; assertTrue(resultEvent.getResult().isAuthorizerPresent()); assertEquals(AckReasonCode.NOT_AUTHORIZED, resultEvent.getResult().getAckReasonCode()); }
onFailure(@NotNull final Throwable t) { Exceptions.rethrowError("Exception at PublishAuthorization", t); final PublishAuthorizerResult result = new PublishAuthorizerResult(AckReasonCode.NOT_AUTHORIZED, getReasonString(connect), true, DisconnectReasonCode.NOT_AUTHORIZED); ctx.pipeline().fireUserEventTriggered(new PluginAuthorizerServiceImpl.AuthorizeWillResultEvent(connect, result)); }
[*] target: assertNotNull(resultEvent)
[-] pred: org. junit. Assert. assertNotNull ( resultEvent )
************************************
************************************
[+] input: Exception { RevCommit commit2a = git.commit().setAmend(true) .setMessage("Deleted file").call(); Collection<ReflogEntry> reflog = git.reflog().call(); "<AssertPlaceHolder>"; assertEquals(4, reflog.size()); ReflogEntry[] reflogs = reflog.toArray(new ReflogEntry[0]); assertEquals(reflogs[3].getComment(), "commit (initial): Initial commit"); assertEquals(reflogs[3].getNewId(), commit1.getId()); assertEquals(reflogs[3].getOldId(), ObjectId.zeroId()); assertEquals(reflogs[2].getComment(), "checkout: moving from master to b1"); assertEquals(reflogs[2].getNewId(), commit1.getId()); assertEquals(reflogs[2].getOldId(), commit1.getId()); assertEquals(reflogs[1].getComment(), "commit: Removed file"); assertEquals(reflogs[1].getNewId(), commit2.getId()); assertEquals(reflogs[1].getOldId(), commit1.getId()); assertEquals(reflogs[0].getComment(), "commit (amend): Deleted file"); assertEquals(reflogs[0].getNewId(), commit2a.getId()); assertEquals(reflogs[0].getOldId(), commit2.getId()); }
call() throws GitAPIException, InvalidRefNameException { checkCallable();  try { ReflogReader reader = repo.getReflogReader(ref); if (reader == null) throw new RefNotFoundException(MessageFormat.format( JGitText.get().refNotResolved, ref)); return reader.getReverseEntries(); } catch (IOException e) { throw new InvalidRefNameException(MessageFormat.format( JGitText.get().cannotRead, ref), e); } }
[*] target: assertNotNull(reflog)
[-] pred: org. junit. Assert. assertNotNull ( reflog )
************************************
************************************
[+] input: testFromBytesLenError() { try { IVertexId.from(new byte[] {}); } catch (Exception e) { Assert."<AssertPlaceHolder>"; return; } Assert.assertTrue(false); }
from(byte[] bytes) { if (bytes.length != Long.BYTES * 2) { throw new RuntimeException("vertex id must be 16 bytes"); } return new VertexId(bytes); }
[*] target: assertTrue(true)
[-] pred: org. junit. Assert. assertTrue ( true )
************************************
************************************
[+] input: testRemoveNotLastSubmittedRecord() { Map<String, Object> partition1Offset = newOffset(); Map<String, Object> partition2Offset = newOffset();  SubmittedRecord recordToRemove = submittedRecords.submit(PARTITION1, partition1Offset); SubmittedRecord lastSubmittedRecord = submittedRecords.submit(PARTITION2, partition2Offset);  CommittableOffsets committableOffsets = submittedRecords.committableOffsets(); assertMetadata(committableOffsets, 0, 2, 2, 1, PARTITION1, PARTITION2); assertNoEmptyDeques();  assertTrue("First attempt to remove record from submitted queue should succeed", recordToRemove.drop());  committableOffsets = submittedRecords.committableOffsets(); // Even if SubmittedRecords::remove is broken, we haven't ack'd anything yet, so there should be no committable offsets assertEquals(Collections.emptyMap(), committableOffsets.offsets()); assertMetadata(committableOffsets, 0, 1, 1, 1, PARTITION2); assertNoEmptyDeques(); // The only record for this partition has been removed; we shouldn't be tracking a deque for it anymore assertRemovedDeques(PARTITION1);  recordToRemove.ack(); committableOffsets = submittedRecords.committableOffsets(); // Even though the record has somehow been acknowledged, it should not be counted when collecting committable offsets assertEquals(Collections.emptyMap(), committableOffsets.offsets()); assertMetadata(committableOffsets, 0, 1, 1, 1, PARTITION2); assertNoEmptyDeques();  lastSubmittedRecord.ack(); committableOffsets = submittedRecords.committableOffsets(); // Now that the last-submitted record has been ack'd, we should be able to commit its offset assertEquals(Collections.singletonMap(PARTITION2, partition2Offset), committableOffsets.offsets()); assertMetadata(committableOffsets, 1, 0, 0, 0, (Map<String, Object>) null); assertFalse(committableOffsets.hasPending());  // Everything has been ack'd and consumed; make sure that it's been cleaned up to avoid memory leaks assertNoRemainingDeques(); committableOffsets = submittedRecords.committableOffsets(); "<AssertPlaceHolder>"; }
isEmpty() { return numCommittableMessages == 0 && numUncommittableMessages == 0 && offsets.isEmpty(); }
[*] target: assertTrue(committableOffsets.isEmpty())
[-] pred: org. junit. Assert. assertTrue ( committableOffsets. isEmpty ( ) )
************************************
************************************
[+] input: Exception { ComponentName cn = new ComponentName(getContext(), TEST_ACTIVITY); initCursor(ITEM_TYPE_APPLICATION, ""); assertTrue(mLoaderCursor.moveToNext());  WorkspaceItemInfo info = Executors.MODEL_EXECUTOR.submit(() -> mLoaderCursor.getAppShortcutInfo( new Intent().setComponent(cn), false  /* allowMissingTarget */, true)) .get(); "<AssertPlaceHolder>"; assertTrue(PackageManagerHelper.isLauncherAppTarget(info.getIntent())); }
getAppShortcutInfo( Intent intent, boolean allowMissingTarget, boolean useLowResIcon) { return getAppShortcutInfo(intent, allowMissingTarget, useLowResIcon, true); }
[*] target: assertNotNull(info)
[-] pred: org. junit. Assert. assertNotNull ( info )
************************************
************************************
[+] input: IOException { Table table = load();  table.updateProperties().set(SNAPSHOT_ID_INHERITANCE_ENABLED, "true").commit();  ManifestFile newManifest = writeManifest( "manifest-file-1.avro", manifestEntry(ManifestEntry.Status.ADDED, null, FILE_A));  table.newFastAppend().appendManifest(newManifest).commit(); long appendId = table.currentSnapshot().snapshotId();  Assert.assertEquals(1, table.currentSnapshot().allManifests(table.io()).size());  table.rewriteManifests().clusterBy(file -> "").commit();  List<ManifestFile> manifests = table.currentSnapshot().allManifests(table.io()); Assert."<AssertPlaceHolder>";  validateManifestEntries( manifests.get(0), ids(appendId), files(FILE_A), statuses(ManifestEntry.Status.EXISTING)); }
clusterBy(Function<DataFile, Object> func);  /** * Determines which existing {@link ManifestFile}
[*] target: assertEquals(1, manifests.size())
[-] pred: org. junit. Assert. assertEquals ( 1, manifests. size ( ) )
************************************
************************************
[+] input: testOffer_NotificationNotEmpty_Success() { Assert.assertTrue(queue.offer(Arrays.asList(getMessage()))); List<MessageEntity> messages = messageRepository.findAll();  Assert."<AssertPlaceHolder>"; }
size() { return messageRepository.findAll().size(); }
[*] target: assertEquals(1, messages.size())
[-] pred: org. junit. Assert. assertEquals ( 1, messages. size ( ) )
************************************
************************************
[+] input: testGetAllWorkflowDefsLatestVersions() { WorkflowDef def = new WorkflowDef(); def.setName("test1"); def.setVersion(1); def.setDescription("description"); def.setCreatedBy("unit_test"); def.setCreateTime(1L); def.setOwnerApp("ownerApp"); def.setUpdatedBy("unit_test2"); def.setUpdateTime(2L); metadataDAO.createWorkflowDef(def);  def.setName("test2"); metadataDAO.createWorkflowDef(def); def.setVersion(2); metadataDAO.createWorkflowDef(def);  def.setName("test3"); def.setVersion(1); metadataDAO.createWorkflowDef(def); def.setVersion(2); metadataDAO.createWorkflowDef(def); def.setVersion(3); metadataDAO.createWorkflowDef(def);  // Placed the values in a map because they might not be stored in order of defName. // To test, needed to confirm that the versions are correct for the definitions. Map<String, WorkflowDef> allMap = metadataDAO.getAllWorkflowDefsLatestVersions().stream() .collect(Collectors.toMap(WorkflowDef::getName, Function.identity()));  "<AssertPlaceHolder>"; assertEquals(3, allMap.size()); assertEquals(1, allMap.get("test1").getVersion()); assertEquals(2, allMap.get("test2").getVersion()); assertEquals(3, allMap.get("test3").getVersion()); }
getAllWorkflowDefsLatestVersions() { final String GET_ALL_WORKFLOW_DEF_LATEST_VERSIONS_QUERY = "SELECT json_data FROM meta_workflow_def wd WHERE wd.version = (SELECT MAX(version) FROM meta_workflow_def wd2 WHERE wd2.name = wd.name)"; return queryWithTransaction( GET_ALL_WORKFLOW_DEF_LATEST_VERSIONS_QUERY, q -> q.executeAndFetch(WorkflowDef.class)); }
[*] target: assertNotNull(allMap)
[-] pred: org. junit. Assert. assertNotNull ( allMap )
************************************
************************************
[+] input: test_CreateChannel_withChannelConfig() { Channel saved = notificationService.createChannel(PROJECT_ID, getChannel()); Assert."<AssertPlaceHolder>"; List<ChannelPropertyEntity> properties = channelPropertyRepository.findAllByChannelId(saved.getId()); Assert.assertEquals(2, properties.size()); }
createChannel(@NotNull Long projectId, @NotNull Channel channel) { PreConditions.notBlank(channel.getName(), "channel.name"); PreConditions.notNull(channel.getType(), "channel.type"); PreConditions.validNoDuplicated(ResourceType.ODC_NOTIFICATION_CHANNEL, "channel.name", channel.getName(), () -> existsChannel(projectId, channel.getName())); validator.validate(channel.getType(), channel.getChannelConfig());  if (StringUtils.isEmpty(channel.getChannelConfig().getTitleTemplate())) { channel.getChannelConfig().setTitleTemplate("${taskType}-${taskStatus}"); } ChannelEntity entity = channelMapper.toEntity(channel); entity.setCreatorId(authenticationFacade.currentUserId()); entity.setOrganizationId(authenticationFacade.currentOrganizationId()); entity.setProjectId(projectId);  return channelMapper.fromEntity(channelRepository.save(entity)); }
[*] target: assertNotNull(saved)
[-] pred: org. junit. Assert. assertNotNull ( saved )
************************************
************************************
[+] input: test_findByExpireTimeBefore() { long currentTime = System.currentTimeMillis(); PermissionEntity entity = createPermissionEntity("query", "ODC_DATABASE:1", new Date(currentTime - 90 * 1000L)); createPermissionEntity("change", "ODC_DATABASE:2", new Date(currentTime - 30 * 1000L)); createPermissionEntity("change", "ODC_DATABASE:3", TimeUtils.getMySQLMaxDatetime()); Assert.assertEquals(3, permissionRepository.findAllNoCareExpireTime().size()); List<PermissionEntity> entities = permissionRepository.findByExpireTimeBefore(new Date(currentTime - 60 * 1000L)); Assert."<AssertPlaceHolder>"; Assert.assertEquals(entity.getId(), entities.get(0).getId()); }
findByExpireTimeBefore(@Param("expireTime") Date expireTime);  @Modifying @Transactional @Query(value = "delete from iam_permission p where p.id in (:ids)", nativeQuery = true) int deleteByIds(@Param("ids") Collection<Long> ids);  @Modifying @Transactional @Query(value = "delete from iam_permission p where 1=1", nativeQuery = true) void deleteAll();  default List<PermissionEntity> batchCreate(List<PermissionEntity> entities) { String sql = InsertSqlTemplateBuilder.from("iam_permission") .field(PermissionEntity_.action) .field(PermissionEntity_.resourceIdentifier) .field(PermissionEntity_.type) .field(PermissionEntity_.creatorId) .field(PermissionEntity_.organizationId) .field("is_builtin") .field(PermissionEntity_.expireTime) .field(PermissionEntity_.authorizationType) .field(PermissionEntity_.ticketId) .field(PermissionEntity_.resourceType) .field(PermissionEntity_.resourceId) .build(); List<Function<PermissionEntity, Object>> getter = valueGetterBuilder() .add(PermissionEntity::getAction) .add(PermissionEntity::getResourceIdentifier) .add((PermissionEntity e) -> e.getType().name()) .add(PermissionEntity::getCreatorId) .add(PermissionEntity::getOrganizationId) .add(PermissionEntity::getBuiltIn) .add(PermissionEntity::getExpireTime) .add((PermissionEntity e) -> e.getAuthorizationType().name()) .add(PermissionEntity::getTicketId) .add((PermissionEntity e) -> e.getResourceType().name()) .add(PermissionEntity::getResourceId) .build();  return batchCreate(entities, sql, getter, PermissionEntity::setId); }
[*] target: assertEquals(1, entities.size())
[-] pred: org. junit. Assert. assertEquals ( 1, entities. size ( ) )
************************************
************************************
[+] input: fromHeadersShouldReturnNonNullResultOnValidSignatureAndSignatureAlgorithm() { InternalRequestSignature signature = InternalRequestSignature.fromHeaders(crypto, REQUEST_BODY, internalRequestHeaders(ENCODED_SIGNATURE, SIGNATURE_ALGORITHM)); assertNotNull(signature); "<AssertPlaceHolder>"; }
keyAlgorithm() { return mac.getAlgorithm(); }
[*] target: assertNotNull(signature.keyAlgorithm())
[-] pred: org. junit. Assert. assertNotNull ( signature. keyAlgorithm() )
************************************
************************************
[+] input: testValueOf3() { MediaType mediaType = MediaType.valueOf("application/x-www-form-urlencoded", "ISO-8859-1"); String type = "application/x-www-form-urlencoded"; String charset = "ISO-8859-1"; String excepted = "application/x-www-form-urlencoded;charset=ISO-8859-1"; assertEquals(type, mediaType.getType()); assertEquals(charset, mediaType.getCharset()); "<AssertPlaceHolder>"; }
toString() { return type + ";charset=" + charset; }
[*] target: assertEquals(excepted, mediaType.toString())
[-] pred: org. junit. Assert. assertEquals ( excepted, mediaType. toString ( ) )
************************************
************************************
[+] input: NacosException { rpcClient.rpcClientStatus.set(RpcClientStatus.RUNNING); rpcClient.currentConnection = connection; ErrorResponse errorResponse = new ErrorResponse(); errorResponse.setErrorCode(NacosException.UN_REGISTER); doReturn(errorResponse).when(connection).request(any(), anyLong()); Exception exception = null;  try { rpcClient.request(mock(Request.class), 10000); } catch (Exception e) { exception = e; }  assertEquals(RpcClientStatus.UNHEALTHY, rpcClient.rpcClientStatus.get()); verify(rpcClient).switchServerAsync(); Assert."<AssertPlaceHolder>"; }
switchServerAsync() { switchServerAsync(null, false); }
[*] target: assertNotNull(exception)
[-] pred: org. junit. Assert. assertNotNull ( exception )
************************************
************************************
[+] input: Exception { PowerMockito.whenNew(DefaultConnector.class).withAnyArguments().thenReturn(defaultConnector); Method methodGetObVersion = PowerMockito.method(ObConnectTemplate.class, "getObVersion"); PowerMockito.replace(methodGetObVersion).with((proxy, method, args) -> "2.4.0");  ObOperator operator = ObOperators.newMetaOperator(connectProperties.withCompatibilityMode(CompatibilityMode.MYSQL)); "<AssertPlaceHolder>"; assertNotNull(operator.cluster()); assertNotNull(operator.parameter()); }
newMetaOperator(ConnectProperties connectProperties) { ObConnectTemplate obConnectTemplate = new ObConnectTemplate(connectProperties); return ObOperator.builder() .clusterOperator(newClusterOperator(obConnectTemplate)) .parameterOperator(newParameterOperator(obConnectTemplate)) .build(); }
[*] target: assertNotNull(operator)
[-] pred: org. junit. Assert. assertNotNull ( operator )
************************************
************************************
[+] input: testGetFilename() { // Test case 1: null path String path1 = null; String result1 = StringUtils.getFilename(path1); Assert.assertNull(result1);  // Test case 2: path without separator String path2 = "myFile.txt"; String expectedResult2 = "myFile.txt"; String result2 = StringUtils.getFilename(path2); Assert.assertEquals(expectedResult2, result2);  // Test case 3: path with separator String path3 = "myPath/myFile.txt"; String expectedResult3 = "myFile.txt"; String result3 = StringUtils.getFilename(path3); Assert.assertEquals(expectedResult3, result3);  // Test case 4: path with multiple separators String path4 = "myPath/subPath/myFile.txt"; String expectedResult4 = "myFile.txt"; String result4 = StringUtils.getFilename(path4); Assert."<AssertPlaceHolder>"; }
getFilename(String path) { if (path == null) { return null; }  int separatorIndex = path.lastIndexOf(FOLDER_SEPARATOR); return (separatorIndex != -1 ? path.substring(separatorIndex + 1) : path); }
[*] target: assertEquals(expectedResult4, result4)
[-] pred: org. junit. Assert. assertEquals ( expectedResult4, result4 )
************************************
************************************
[+] input: testFailWorkflowWithOutputPayload() { WorkflowModel workflow = new WorkflowModel(); workflow.setOutput(new HashMap<>());  expectedException.expect(TerminateWorkflowException.class); externalPayloadStorageUtils.failWorkflow( workflow, ExternalPayloadStorage.PayloadType.TASK_OUTPUT, "error"); "<AssertPlaceHolder>"; assertTrue(workflow.getOutput().isEmpty()); assertEquals(WorkflowModel.Status.FAILED, workflow.getStatus()); }
failWorkflow(WorkflowModel workflow, PayloadType payloadType, String errorMsg) { LOGGER.error(errorMsg); if (payloadType == PayloadType.WORKFLOW_INPUT) { workflow.setInput(new HashMap<>()); } else { workflow.setOutput(new HashMap<>()); } throw new TerminateWorkflowException(errorMsg); }
[*] target: assertNotNull(workflow)
[-] pred: org. junit. Assert. assertNotNull ( workflow )
************************************
************************************
[+] input: IOException { File file = null; try { file = File.createTempFile("test_writeStringToFile", ".txt"); IoUtils.writeStringToFile(file, "123", "UTF-8"); List<String> actual = IoUtils.readLines(new FileReader(file)); Assert."<AssertPlaceHolder>"; Assert.assertEquals("123", actual.get(0)); } finally { if (null != file) { file.deleteOnExit(); } } }
readLines(Reader input) throws IOException { BufferedReader reader = toBufferedReader(input); List<String> list = new ArrayList<>(); while (true) { String line = reader.readLine(); if (null != line) { if (StringUtils.isNotEmpty(line)) { list.add(line.trim()); } } else { break; } } return list; }
[*] target: assertEquals(1, actual.size())
[-] pred: org. junit. Assert. assertEquals ( 1, actual. size ( ) )
************************************
************************************
[+] input: statelessTopologyShouldNotHavePersistentStore() { final TopologyWrapper topology = new TopologyWrapper(); final ProcessorTopology processorTopology = topology.getInternalBuilder("anyAppId").buildTopology(); assertFalse(processorTopology.hasPersistentLocalStore()); "<AssertPlaceHolder>"; }
hasPersistentGlobalStore() { for (final StateStore store : globalStateStores) { if (store.persistent()) { return true; } } return false; }
[*] target: assertFalse(processorTopology.hasPersistentGlobalStore())
[-] pred: org. junit. Assert. assertFalse ( processorTopology. hasPersistentGlobalStore() )
************************************
************************************
[+] input: testGetSelector() { Selector selector = serviceMetadata.getSelector();  Assert."<AssertPlaceHolder>"; boolean result = selector instanceof NoneSelector; Assert.assertTrue(result); }
getSelector() { return selector; }
[*] target: assertNotNull(selector)
[-] pred: org. junit. Assert. assertNotNull ( selector )
************************************
************************************
[+] input: Exception { String[] lines = { "command=fetch\n", "server-option=one\n", "server-option=two\n", PacketLineIn.delimiter(), PacketLineIn.end() };  TestV2Hook testHook = new TestV2Hook(); uploadPackSetup(TransferConfig.ProtocolVersion.V2.version(), (UploadPack up) -> { up.setProtocolV2Hook(testHook); }, lines);  FetchV2Request req = testHook.fetchRequest; "<AssertPlaceHolder>"; assertEquals(2, req.getServerOptions().size()); assertThat(req.getServerOptions(), hasItems("one", "two")); }
setProtocolV2Hook(@Nullable ProtocolV2Hook hook) { this.protocolV2Hook = hook != null ? hook : ProtocolV2Hook.DEFAULT; }
[*] target: assertNotNull(req)
[-] pred: org. junit. Assert. assertNotNull ( req )
************************************
************************************
[+] input: IOException { Map<Integer, String> index2Content = new HashMap<>(); Map<Integer, BinaryContentMetaData> index2MetaData = new HashMap<>();  BinaryDataManager dataManager = getDataManager(); for (int i = 0; i < 3; i++) { String content = getInputContent(); index2Content.putIfAbsent(i, content); index2MetaData.putIfAbsent(i, dataManager.write(getInputContentStream(content))); }  for (int i = 0; i < 3; i++) { BinaryContentMetaData metaData = index2MetaData.get(i); Assert.assertNotNull(metaData); InputStream inputStream = dataManager.read(metaData); String fromFile = String.join("", IOUtils.readLines(inputStream)); String fromMemory = index2Content.get(i); Assert."<AssertPlaceHolder>"; } }
read(@NonNull BinaryContentMetaData metaData) throws IOException;
[*] target: assertEquals(fromFile, fromMemory)
[-] pred: org. junit. Assert. assertEquals ( fromFile, fromMemory )
************************************
************************************
[+] input: Exception { config("Host orcz\n" + "\tConnectionAttempts 5\n"); final Host h = osc.lookup("orcz"); assertNotNull(h); "<AssertPlaceHolder>"; }
getConnectionAttempts() { return connectionAttempts; }
[*] target: assertEquals(5, h.getConnectionAttempts())
[-] pred: org. junit. Assert. assertEquals ( 5, h. getConnectionAttempts ( ) )
************************************
************************************
[+] input: Exception { PowerMockito.whenNew(DefaultConnector.class).withAnyArguments().thenReturn(defaultConnector); Method methodGetObVersion = PowerMockito.method(ObConnectTemplate.class, "getObVersion"); PowerMockito.replace(methodGetObVersion).with((proxy, method, args) -> "2.4.0");  ObAccessor accessor = ObAccessors.newObAccessor(connectProperties.withCompatibilityMode(CompatibilityMode.ORACLE)); "<AssertPlaceHolder>"; assertNotNull(accessor.session()); assertNotNull(accessor.variable()); assertNotNull(accessor.user()); assertNotNull(accessor.database()); }
newObAccessor(ConnectProperties connectProperties) { Validate.notNull(connectProperties, "The input connectProperties is null."); connectProperties.validate(); ObAccessor obAccessor = holder.get(connectProperties); if (obAccessor != null) { return obAccessor; }  ObConnectTemplate obConnectTemplate = new ObConnectTemplate(connectProperties); obAccessor = ObAccessor.builder() .infoAccessor(newInfoAccessor(obConnectTemplate)) .variableAccessor(newVariableAccessor(obConnectTemplate)) .parameterAccessor(newParameterAccessor(obConnectTemplate)) .userAccessor(newUserAccessor(obConnectTemplate)) .databaseAccessor(newDatabaseAccessor(obConnectTemplate)) .objectAccessor(newObjectAccessor(obConnectTemplate)) .sessionAccessor(newSessionAccessor(obConnectTemplate)) .sqlTuningAccessor(newSqlTuningAccessor(obConnectTemplate)) .build();  holder.put(connectProperties, obAccessor); return obAccessor; }
[*] target: assertNotNull(accessor)
[-] pred: org. junit. Assert. assertNotNull ( accessor )
************************************
************************************
[+] input: Exception { writeTrashFile("file.txt", "content2"); git.add().addFilepattern("file.txt").call(); writeTrashFile("file.txt", "content");  RevCommit stashed = Git.wrap(db).stashCreate().call(); "<AssertPlaceHolder>"; assertEquals("content", read(committedFile)); validateStashedCommit(stashed);  assertEquals(stashed.getParent(1).getTree(), stashed.getTree());  List<DiffEntry> workingDiffs = diffWorkingAgainstHead(stashed); assertEquals(1, workingDiffs.size()); assertEquals(DiffEntry.ChangeType.MODIFY, workingDiffs.get(0) .getChangeType()); assertEquals("file.txt", workingDiffs.get(0).getNewPath());  List<DiffEntry> indexDiffs = diffIndexAgainstHead(stashed); assertEquals(1, indexDiffs.size()); assertEquals(DiffEntry.ChangeType.MODIFY, indexDiffs.get(0) .getChangeType()); assertEquals("file.txt", indexDiffs.get(0).getNewPath());  assertEquals(workingDiffs.get(0).getOldId(), indexDiffs.get(0) .getOldId()); assertTrue(workingDiffs.get(0).getNewId() .equals(indexDiffs.get(0).getNewId())); }
call() throws GitAPIException { checkCallable();  List<String> deletedFiles = new ArrayList<>(); Ref head = getHead(); try (ObjectReader reader = repo.newObjectReader()) { RevCommit headCommit = parseCommit(reader, head.getObjectId()); DirCache cache = repo.lockDirCache(); ObjectId commitId; try (ObjectInserter inserter = repo.newObjectInserter(); TreeWalk treeWalk = new TreeWalk(repo, reader)) {  treeWalk.setRecursive(true); treeWalk.addTree(headCommit.getTree()); treeWalk.addTree(new DirCacheIterator(cache)); treeWalk.addTree(new FileTreeIterator(repo)); treeWalk.getTree(2, FileTreeIterator.class) .setDirCacheIterator(treeWalk, 1); treeWalk.setFilter(AndTreeFilter.create(new SkipWorkTreeFilter( 1), new IndexDiffFilter(1, 2)));  // Return null if no local changes to stash if (!treeWalk.next()) return null;  MutableObjectId id = new MutableObjectId(); List<PathEdit> wtEdits = new ArrayList<>(); List<String> wtDeletes = new ArrayList<>(); List<DirCacheEntry> untracked = new ArrayList<>(); boolean hasChanges = false; do { AbstractTreeIterator headIter = treeWalk.getTree(0, AbstractTreeIterator.class); DirCacheIterator indexIter = treeWalk.getTree(1, DirCacheIterator.class); WorkingTreeIterator wtIter = treeWalk.getTree(2, WorkingTreeIterator.class); if (indexIter != null && !indexIter.getDirCacheEntry().isMerged()) throw new UnmergedPathsException( new UnmergedPathException( indexIter.getDirCacheEntry())); if (wtIter != null) { if (indexIter == null && headIter == null && !includeUntracked) continue; hasChanges = true; if (indexIter != null && wtIter.idEqual(indexIter)) continue; if (headIter != null && wtIter.idEqual(headIter)) continue; treeWalk.getObjectId(id, 0); final DirCacheEntry entry = new DirCacheEntry( treeWalk.getRawPath()); entry.setLength(wtIter.getEntryLength()); entry.setLastModified( wtIter.getEntryLastModifiedInstant()); entry.setFileMode(wtIter.getEntryFileMode()); long contentLength = wtIter.getEntryContentLength(); try (InputStream in = wtIter.openEntryStream()) { entry.setObjectId(inserter.insert( Constants.OBJ_BLOB, contentLength, in)); }  if (indexIter == null && headIter == null) untracked.add(entry); else wtEdits.add(new PathEdit(entry) { @Override public void apply(DirCacheEntry ent) { ent.copyMetaData(entry); } }); } hasChanges = true; if (wtIter == null && headIter != null) wtDeletes.add(treeWalk.getPathString()); } while (treeWalk.next());  if (!hasChanges) return null;  String branch = Repository.shortenRefName(head.getTarget() .getName());  // Commit index changes CommitBuilder builder = createBuilder(); builder.setParentId(headCommit); builder.setTreeId(cache.writeTree(inserter)); builder.setMessage(MessageFormat.format(indexMessage, branch, headCommit.abbreviate(OBJECT_ID_ABBREV_STRING_LENGTH) .name(), headCommit.getShortMessage())); ObjectId indexCommit = inserter.insert(builder);  // Commit untracked changes ObjectId untrackedCommit = null; if (!untracked.isEmpty()) { DirCache untrackedDirCache = DirCache.newInCore(); DirCacheBuilder untrackedBuilder = untrackedDirCache .builder(); for (DirCacheEntry entry : untracked) untrackedBuilder.add(entry); untrackedBuilder.finish();  builder.setParentIds(new ObjectId[0]); builder.setTreeId(untrackedDirCache.writeTree(inserter)); builder.setMessage(MessageFormat.format(MSG_UNTRACKED, branch, headCommit .abbreviate(OBJECT_ID_ABBREV_STRING_LENGTH) .name(), headCommit.getShortMessage())); untrackedCommit = inserter.insert(builder); }  // Commit working tree changes if (!wtEdits.isEmpty() || !wtDeletes.isEmpty()) { DirCacheEditor editor = cache.editor(); for (PathEdit edit : wtEdits) editor.add(edit); for (String path : wtDeletes) editor.add(new DeletePath(path)); editor.finish(); } builder.setParentId(headCommit); builder.addParentId(indexCommit); if (untrackedCommit != null) builder.addParentId(untrackedCommit); builder.setMessage(MessageFormat.format( workingDirectoryMessage, branch, headCommit.abbreviate(OBJECT_ID_ABBREV_STRING_LENGTH) .name(), headCommit.getShortMessage())); builder.setTreeId(cache.writeTree(inserter)); commitId = inserter.insert(builder); inserter.flush();  updateStashRef(commitId, builder.getAuthor(), builder.getMessage());  // Remove untracked files if (includeUntracked) { for (DirCacheEntry entry : untracked) { String repoRelativePath = entry.getPathString(); File file = new File(repo.getWorkTree(), repoRelativePath); FileUtils.delete(file); deletedFiles.add(repoRelativePath); } }  } finally { cache.unlock(); }  // Hard reset to HEAD new ResetCommand(repo).setMode(ResetType.HARD).call();  // Return stashed commit return parseCommit(reader, commitId); } catch (IOException e) { throw new JGitInternalException(JGitText.get().stashFailed, e); } finally { if (!deletedFiles.isEmpty()) { repo.fireEvent( new WorkingTreeModifiedEvent(null, deletedFiles)); } } }
[*] target: assertNotNull(stashed)
[-] pred: org. junit. Assert. assertNotNull ( stashed )
************************************
************************************
[+] input: shouldGetAllStreamInstances() { final StreamsMetadata one = new StreamsMetadataImpl(hostOne, mkSet(globalTable, "table-one", "table-two", "merged-table"), mkSet(topic1P0, topic2P1, topic4P0), mkSet("table-one", "table-two", "merged-table"), mkSet(topic2P0, topic1P1)); final StreamsMetadata two = new StreamsMetadataImpl(hostTwo, mkSet(globalTable, "table-two", "table-one", "merged-table"), mkSet(topic2P0, topic1P1), mkSet("table-three"), mkSet(topic3P0)); final StreamsMetadata three = new StreamsMetadataImpl(hostThree, mkSet(globalTable, "table-three"), Collections.singleton(topic3P0), mkSet("table-one", "table-two", "merged-table"), mkSet(topic1P0, topic2P1, topic4P0));  final Collection<StreamsMetadata> actual = metadataState.getAllMetadata(); "<AssertPlaceHolder>"; assertTrue("expected " + actual + " to contain " + one, actual.contains(one)); assertTrue("expected " + actual + " to contain " + two, actual.contains(two)); assertTrue("expected " + actual + " to contain " + three, actual.contains(three)); }
getAllMetadata() { return Collections.unmodifiableList(allMetadata); }
[*] target: assertEquals(3, actual.size())
[-] pred: org. junit. Assert. assertEquals ( 3, actual. size ( ) )
************************************
************************************
[+] input: testPollBatch() { try { ClosableBlockingQueue<String> queue = new ClosableBlockingQueue<>();  assertNull(queue.pollBatch());  queue.add("a"); queue.add("b");  assertEquals(asList("a", "b"), queue.pollBatch()); assertNull(queue.pollBatch());  queue.add("c");  assertEquals(singletonList("c"), queue.pollBatch()); "<AssertPlaceHolder>";  assertTrue(queue.close());  try { queue.pollBatch(); fail("should cause an exception"); } catch (IllegalStateException ignored) { // expected } } catch (Exception e) { e.printStackTrace(); fail(e.getMessage()); } }
pollBatch() { lock.lock(); try { if (open) { if (elements.size() > 0) { ArrayList<E> result = new ArrayList<>(elements); elements.clear(); return result; } else { return null; } } else { throw new IllegalStateException("queue is closed"); } } finally { lock.unlock(); } }
[*] target: assertNull(queue.pollBatch())
[-] pred: org. junit. Assert. assertNull ( queue. pollBatch ( ) )
************************************
************************************
[+] input: GitAPIException { // create status StatusCommand command = git.status(); Status status = command.call(); Set<String> files = status.getUntracked(); assertFalse(files.isEmpty());  // run clean Set<String> cleanedFiles = git.clean().setCleanDirectories(true).call();  status = git.status().call(); files = status.getUntracked();  "<AssertPlaceHolder>"; assertTrue(cleanedFiles.contains("File2.txt")); assertTrue(cleanedFiles.contains("File3.txt")); assertTrue(!cleanedFiles.contains("sub-noclean/File1.txt")); assertTrue(cleanedFiles.contains("sub-noclean/File2.txt")); assertTrue(cleanedFiles.contains("sub-clean/")); }
call() throws NoWorkTreeException, GitAPIException { Set<String> files = new TreeSet<>(); try { StatusCommand command = new StatusCommand(repo); Status status = command.call();  Set<String> untrackedFiles = new TreeSet<>(status.getUntracked()); Set<String> untrackedDirs = new TreeSet<>( status.getUntrackedFolders());  FS fs = getRepository().getFS(); for (String p : status.getIgnoredNotInIndex()) { File f = new File(repo.getWorkTree(), p); if (fs.isFile(f) || fs.isSymLink(f)) { untrackedFiles.add(p); } else if (fs.isDirectory(f)) { untrackedDirs.add(p); } }  Set<String> filtered = filterFolders(untrackedFiles, untrackedDirs);  Set<String> notIgnoredFiles = filterIgnorePaths(filtered, status.getIgnoredNotInIndex(), true); Set<String> notIgnoredDirs = filterIgnorePaths(untrackedDirs, status.getIgnoredNotInIndex(), false);  for (String file : notIgnoredFiles) { if (paths.isEmpty() || paths.contains(file)) { files = cleanPath(file, files); } } for (String dir : notIgnoredDirs) { if (paths.isEmpty() || paths.contains(dir)) { files = cleanPath(dir, files); } } } catch (IOException e) { throw new JGitInternalException(e.getMessage(), e); } finally { if (!dryRun && !files.isEmpty()) { repo.fireEvent(new WorkingTreeModifiedEvent(null, files)); } } return files; }
[*] target: assertTrue(files.isEmpty())
[-] pred: org. junit. Assert. assertTrue ( files. isEmpty ( ) )
************************************
************************************
[+] input: shouldOptimizeActiveTasksWithMoreClientsWithMoreThanOneTask() { final Map<Subtopology, Set<TaskId>> tasksForTopicGroup = mkMap( mkEntry(new Subtopology(0, null), mkSet(TASK_0_0, TASK_0_1)), mkEntry(new Subtopology(1, null), mkSet(TASK_1_0)) ); final RackAwareTaskAssignor assignor = new RackAwareTaskAssignor( getClusterForAllTopics(), getTaskTopicPartitionMapForAllTasks(), mkMap(), tasksForTopicGroup, getProcessRacksForAllProcess(), mockInternalTopicManager, getRackAwareEnabledConfig(), time );  final ClientState clientState1 = new ClientState(emptySet(), emptySet(), emptyMap(), EMPTY_CLIENT_TAGS, 1); final ClientState clientState2 = new ClientState(emptySet(), emptySet(), emptyMap(), EMPTY_CLIENT_TAGS, 1); final ClientState clientState3 = new ClientState(emptySet(), emptySet(), emptyMap(), EMPTY_CLIENT_TAGS, 1);  clientState2.assignActiveTasks(mkSet(TASK_0_1, TASK_1_0)); clientState3.assignActive(TASK_0_0);  // task_0_0 has same rack as UUID_1 and UUID_2 // task_0_1 has same rack as UUID_2 and UUID_3 // task_1_0 has same rack as UUID_1 and UUID_3 // Optimal assignment is UUID_1: {}, UUID_2: {0_0, 0_1}, UUID_3: {1_0} which result in no cross rack traffic final SortedMap<UUID, ClientState> clientStateMap = new TreeMap<>(mkMap( mkEntry(UUID_1, clientState1), mkEntry(UUID_2, clientState2), mkEntry(UUID_3, clientState3) )); final SortedSet<TaskId> taskIds = mkSortedSet(TASK_0_0, TASK_0_1, TASK_1_0);  assertTrue(assignor.canEnableRackAwareAssignor()); final long originalCost = assignor.activeTasksCost(taskIds, clientStateMap, trafficCost, nonOverlapCost); int expected = stateful ? 20 : 2; assertEquals(expected, originalCost);  expected = stateful ? 2 : 0; final long cost = assignor.optimizeActiveTasks(taskIds, clientStateMap, trafficCost, nonOverlapCost); "<AssertPlaceHolder>";  // Because original assignment is not balanced (3 tasks but client 0 has no task), we maintain it assertEquals(mkSet(), clientState1.activeTasks()); assertEquals(mkSet(TASK_0_0, TASK_0_1), clientState2.activeTasks()); assertEquals(mkSet(TASK_1_0), clientState3.activeTasks()); }
optimizeActiveTasks(final SortedSet<TaskId> activeTasks, final SortedMap<UUID, ClientState> clientStates, final int trafficCost, final int nonOverlapCost) { if (activeTasks.isEmpty()) { return 0; }  log.info("Assignment before active task optimization is {}\n with cost {}", clientStates, activeTasksCost(activeTasks, clientStates, trafficCost, nonOverlapCost));  final long startTime = time.milliseconds(); final List<UUID> clientList = new ArrayList<>(clientStates.keySet()); final List<TaskId> taskIdList = new ArrayList<>(activeTasks); final Map<TaskId, UUID> taskClientMap = new HashMap<>(); final Map<UUID, Integer> originalAssignedTaskNumber = new HashMap<>(); final RackAwareGraphConstructor<ClientState> graphConstructor = RackAwareGraphConstructorFactory.create(assignmentConfigs, tasksForTopicGroup); final Graph<Integer> graph = graphConstructor.constructTaskGraph( clientList, taskIdList, clientStates, taskClientMap, originalAssignedTaskNumber, ClientState::hasActiveTask, this::getCost, trafficCost, nonOverlapCost, false, false );  graph.solveMinCostFlow(); final long cost = graph.totalCost();  graphConstructor.assignTaskFromMinCostFlow(graph, clientList, taskIdList, clientStates, originalAssignedTaskNumber, taskClientMap, ClientState::assignActive, ClientState::unassignActive, ClientState::hasActiveTask);  final long duration = time.milliseconds() - startTime; log.info("Assignment after {} milliseconds for active task optimization is {}\n with cost {}", duration, clientStates, cost); return cost; }
[*] target: assertEquals(expected, cost)
[-] pred: org. junit. Assert. assertEquals ( expected, cost )
************************************
************************************
[+] input: Exception { final String tagName = "foo"; remoteGit.commit().setMessage("commit").call(); Ref tagRef = remoteGit.tag().setName(tagName).call(); ObjectId originalId = tagRef.getObjectId();  String spec = "refs/heads/*:refs/remotes/origin/*"; git.fetch().setRemote("test").setRefSpecs(spec) .setTagOpt(TagOpt.AUTO_FOLLOW).call(); assertEquals(originalId, db.resolve(tagName));  remoteGit.commit().setMessage("commit 2").call(); remoteGit.tag().setName(tagName).setForceUpdate(true).call();  FetchResult result = git.fetch().setRemote("test").setRefSpecs(spec) .setTagOpt(TagOpt.AUTO_FOLLOW).call();  Collection<TrackingRefUpdate> refUpdates = result .getTrackingRefUpdates(); "<AssertPlaceHolder>"; TrackingRefUpdate update = refUpdates.iterator().next(); assertEquals("refs/heads/master", update.getRemoteName());  assertEquals(originalId, db.resolve(tagName)); }
call() throws GitAPIException, InvalidRemoteException, org.eclipse.jgit.api.errors.TransportException { checkCallable();  try (Transport transport = Transport.open(repo, remote)) { transport.setCheckFetchedObjects(checkFetchedObjects); transport.setRemoveDeletedRefs(isRemoveDeletedRefs()); transport.setDryRun(dryRun); if (tagOption != null) transport.setTagOpt(tagOption); transport.setFetchThin(thin); if (depth != null) { transport.setDepth(depth); } if (unshallow) { if (depth != null) { throw new IllegalStateException(JGitText.get().depthWithUnshallow); } transport.setDepth(Constants.INFINITE_DEPTH); } if (deepenSince != null) { transport.setDeepenSince(deepenSince); } transport.setDeepenNots(shallowExcludes); configure(transport); FetchResult result = transport.fetch(monitor, applyOptions(refSpecs), initialBranch); if (!repo.isBare()) { fetchSubmodules(result); }  return result; } catch (NoRemoteRepositoryException e) { throw new InvalidRemoteException(MessageFormat.format( JGitText.get().invalidRemote, remote), e); } catch (TransportException e) { throw new org.eclipse.jgit.api.errors.TransportException( e.getMessage(), e); } catch (URISyntaxException e) { throw new InvalidRemoteException(MessageFormat.format( JGitText.get().invalidRemote, remote), e); } catch (NotSupportedException e) { throw new JGitInternalException( JGitText.get().exceptionCaughtDuringExecutionOfFetchCommand, e); }  }
[*] target: assertEquals(1, refUpdates.size())
[-] pred: org. junit. Assert. assertEquals ( 1, refUpdates. size ( ) )
************************************
************************************
[+] input: Exception { final EmptyTreeIterator etp = new EmptyTreeIterator(); assertTrue(etp.first()); "<AssertPlaceHolder>"; }
eof() { return true; }
[*] target: assertTrue(etp.eof())
[-] pred: org. junit. Assert. assertTrue ( etp. eof() )
************************************
************************************
[+] input: testGetPropertySource() { PropertySource propertySource = getPropertySource(environment, MockPropertySource.MOCK_PROPERTIES_PROPERTY_SOURCE_NAME, PropertySource.class); assertNotNull(propertySource);  propertySource = getPropertySource(environment, MockPropertySource.MOCK_PROPERTIES_PROPERTY_SOURCE_NAME, EnumerablePropertySource.class); assertNotNull(propertySource);  propertySource = getPropertySource(environment, MockPropertySource.MOCK_PROPERTIES_PROPERTY_SOURCE_NAME, MapPropertySource.class); assertNotNull(propertySource);  propertySource = getPropertySource(environment, MockPropertySource.MOCK_PROPERTIES_PROPERTY_SOURCE_NAME, PropertiesPropertySource.class); assertNotNull(propertySource);  propertySource = getPropertySource(environment, MockPropertySource.MOCK_PROPERTIES_PROPERTY_SOURCE_NAME, MockPropertySource.class); assertNotNull(propertySource);  propertySource = getPropertySource(environment, MockPropertySource.MOCK_PROPERTIES_PROPERTY_SOURCE_NAME, ResourcePropertySource.class); assertNull(propertySource);  propertySource = getPropertySource(environment, "test", ResourcePropertySource.class); assertNull(propertySource);  propertySource = getPropertySource(environment, "test", MockPropertySource.class, MockPropertySource::new); "<AssertPlaceHolder>"; }
getPropertySource(ConfigurableEnvironment environment, String propertySourceName, Class<T> propertySourceType, Supplier<T> propertySourceSupplierIfAbsent) { MutablePropertySources propertySources = environment.getPropertySources(); PropertySource propertySource = propertySources.get(propertySourceName); T targetPropertySource = null; if (propertySource == null) { logger.debug("The '{}' PropertySource can't be found!", propertySourceName); if (propertySourceSupplierIfAbsent != null) { targetPropertySource = propertySourceSupplierIfAbsent.get(); if (targetPropertySource != null) { logger.debug("A new PropertySource[{}] will be created.", targetPropertySource); propertySources.addLast(targetPropertySource); } } } else if (propertySourceType.isInstance(propertySource)) { logger.debug("The '{}' PropertySource[type: {}] was found!", propertySourceName, propertySource.getClass().getName()); targetPropertySource = propertySourceType.cast(propertySource); } else { logger.warn("The '{}' PropertySource is not a {} instance, actual type : {}", propertySource.getClass().getName(), propertySourceType.getName()); } return targetPropertySource; }
[*] target: assertNotNull(propertySource)
[-] pred: org. junit. Assert. assertNotNull ( propertySource )
************************************
************************************
[+] input: Exception { final DirCache tree0 = db.readDirCache(); final DirCache tree1 = db.readDirCache(); final DirCache tree2 = db.readDirCache(); { final DirCacheBuilder b0 = tree0.builder(); final DirCacheBuilder b1 = tree1.builder(); final DirCacheBuilder b2 = tree2.builder();  b0.add(createEntry("gradle.properties", REGULAR_FILE)); b0.add(createEntry("gradle/nested_file.txt", REGULAR_FILE));  b1.add(createEntry("gradle.properties", REGULAR_FILE));  b2.add(createEntry("gradle", REGULAR_FILE)); b2.add(createEntry("gradle.properties", REGULAR_FILE));  b0.finish(); b1.finish(); b2.finish(); assertEquals(2, tree0.getEntryCount()); assertEquals(1, tree1.getEntryCount()); assertEquals(2, tree2.getEntryCount()); }  try (NameConflictTreeWalk tw = new NameConflictTreeWalk(db)) { tw.addTree(new DirCacheIterator(tree0)); tw.addTree(new DirCacheIterator(tree1)); tw.addTree(new DirCacheIterator(tree2));  assertModes("gradle", TREE, MISSING, REGULAR_FILE, tw); assertTrue(tw.isSubtree()); assertTrue(tw.isDirectoryFileConflict()); tw.enterSubtree(); assertModes("gradle/nested_file.txt", REGULAR_FILE, MISSING, MISSING, tw); assertFalse(tw.isSubtree()); // isDirectoryFileConflict is true, because the conflict is detected // on parent. assertTrue(tw.isDirectoryFileConflict()); assertModes("gradle.properties", REGULAR_FILE, REGULAR_FILE, REGULAR_FILE, tw); assertFalse(tw.isSubtree()); "<AssertPlaceHolder>"; } }
isDirectoryFileConflict() { return dfConflict != null; }
[*] target: assertFalse(tw.isDirectoryFileConflict())
[-] pred: org. junit. Assert. assertFalse ( tw. isDirectoryFileConflict() )
************************************
************************************
[+] input: testBitmapCounts_xorResolved() { TestPackBitmapIndex index = new TestPackBitmapIndex(bitmaps); index.getBitmap(xorOid);  assertEquals(2, index.getBaseBitmapCount()); "<AssertPlaceHolder>"; assertEquals(2, index.getBitmapCount()); }
getXorBitmapCount() { int xored = 0; for (StoredBitmap sb : getBitmaps()) { if (!sb.isBase()) { xored += 1; } } return xored; }
[*] target: assertEquals(0, index.getXorBitmapCount())
[-] pred: org. junit. Assert. assertEquals ( 0, index. getXorBitmapCount ( ) )
************************************
************************************
[+] input: shouldInstantiateAndConfigureDefaultHeaderConverter() { props.remove(WorkerConfig.HEADER_CONVERTER_CLASS_CONFIG); createConfig();  // Because it's not explicitly set on the supplied configuration, the logic to use the current classloader for the connector // will exit immediately, and so this method always returns null HeaderConverter headerConverter = plugins.newHeaderConverter(config, WorkerConfig.HEADER_CONVERTER_CLASS_CONFIG, ClassLoaderUsage.CURRENT_CLASSLOADER); assertNull(headerConverter); // But we should always find it (or the worker's default) when using the plugins classloader ... headerConverter = plugins.newHeaderConverter(config, WorkerConfig.HEADER_CONVERTER_CLASS_CONFIG, ClassLoaderUsage.PLUGINS); "<AssertPlaceHolder>"; assertInstanceOf(SimpleHeaderConverter.class, headerConverter); }
newHeaderConverter(AbstractConfig config, String classPropertyName, ClassLoaderUsage classLoaderUsage) { Class<? extends HeaderConverter> klass = null; switch (classLoaderUsage) { case CURRENT_CLASSLOADER: if (!config.originals().containsKey(classPropertyName)) { // This connector configuration does not define the header converter via the specified property name return null; } // Attempt to load first with the current classloader, and plugins as a fallback. // Note: we can't use config.getConfiguredInstance because we have to remove the property prefixes // before calling config(...) klass = pluginClassFromConfig(config, classPropertyName, HeaderConverter.class, scanResult.headerConverters()); break; case PLUGINS: // Attempt to load with the plugin class loader, which uses the current classloader as a fallback. // Note that there will always be at least a default header converter for the worker String converterClassOrAlias = config.getClass(classPropertyName).getName(); try { klass = pluginClass( delegatingLoader, converterClassOrAlias, HeaderConverter.class ); } catch (ClassNotFoundException e) { throw new ConnectException( "Failed to find any class that implements HeaderConverter and which name matches " + converterClassOrAlias + ", available header converters are: " + pluginNames(scanResult.headerConverters()) ); } } if (klass == null) { throw new ConnectException("Unable to initialize the HeaderConverter specified in '" + classPropertyName + "'"); }  String configPrefix = classPropertyName + "."; Map<String, Object> converterConfig = config.originalsWithPrefix(configPrefix); converterConfig.put(ConverterConfig.TYPE_CONFIG, ConverterType.HEADER.getName()); log.debug("Configuring the header converter with configuration keys:{}{}", System.lineSeparator(), converterConfig.keySet());  HeaderConverter plugin; try (LoaderSwap loaderSwap = withClassLoader(klass.getClassLoader())) { plugin = newPlugin(klass); plugin.configure(converterConfig); } return plugin; }
[*] target: assertNotNull(headerConverter)
[-] pred: org. junit. Assert. assertNotNull ( headerConverter )
************************************
************************************
[+] input: testS3URIWithBucketToAccessPointMapping() { String p1 = "s3://bucket/path/to/file?query=foo#bar"; Map<String, String> bucketToAccessPointMapping = ImmutableMap.of("bucket", "access-point"); S3URI uri1 = new S3URI(p1, bucketToAccessPointMapping);  assertEquals("access-point", uri1.bucket()); assertEquals("path/to/file", uri1.key()); "<AssertPlaceHolder>"; }
toString() { return location; }
[*] target: assertEquals(p1, uri1.toString())
[-] pred: org. junit. Assert. assertEquals ( p1, uri1. toString ( ) )
************************************
************************************
[+] input: test_queue_siz_not_modified() { clientSettings = new ModifiableClientSettingsImpl(65535, 1000L); assertEquals(1000L, clientSettings.getQueueSizeMaximum().longValue()); clientSettings.setClientQueueSizeMaximum(1000L); assertEquals(1000L, clientSettings.getQueueSizeMaximum().longValue()); "<AssertPlaceHolder>"; }
isModified() { return modified; }
[*] target: assertFalse(clientSettings.isModified())
[-] pred: org. junit. Assert. assertFalse ( clientSettings. isModified() )
************************************
************************************
[+] input: listTypes_Success() { List<DBPLObjectIdentity> types = accessor.listTypes(getOracleSchema()); Assert."<AssertPlaceHolder>"; Assert.assertEquals(2, types.size()); }
listTypes(String schemaName) { OracleSqlBuilder sb = new OracleSqlBuilder();  sb.append("select OBJECT_NAME as name, STATUS, OBJECT_TYPE as type, OWNER as schema_name from "); sb.append(dataDictTableNames.OBJECTS()); sb.append(" where OBJECT_TYPE='TYPE' and OWNER="); sb.value(schemaName); sb.append(" order by OBJECT_NAME asc");  List<DBPLObjectIdentity> types = jdbcOperations.query(sb.toString(), new BeanPropertyRowMapper<>(DBPLObjectIdentity.class));  return fillTypeErrorMessage(types, schemaName); }
[*] target: assertNotNull(types)
[-] pred: org. junit. Assert. assertNotNull ( types )
************************************
************************************
[+] input: testEntryFileMode() { for (FileMode m : new FileMode[] { FileMode.TREE, FileMode.REGULAR_FILE, FileMode.EXECUTABLE_FILE, FileMode.GITLINK, FileMode.SYMLINK }) { final FakeTreeIterator i = new FakeTreeIterator("a", m); assertEquals(m.getBits(), i.getEntryRawMode()); "<AssertPlaceHolder>"; } }
getEntryFileMode() { return FileMode.fromBits(mode); }
[*] target: assertSame(m, i.getEntryFileMode())
[-] pred: org. junit. Assert. assertSame ( m, i. getEntryFileMode() )
************************************
************************************
[+] input: test_undecided() { task.onSuccess(output);  channel.runPendingTasks();  final AuthorizeWillResultEvent resultEvent = eventsCollector.pollEvent(); "<AssertPlaceHolder>"; assertFalse(resultEvent.getResult().isAuthorizerPresent()); assertNull(resultEvent.getResult().getAckReasonCode()); assertNull(resultEvent.getResult().getReasonString()); }
onSuccess(@Nullable final PublishAuthorizerOutputImpl output) { if (output == null) { //this does not happen return; }  DisconnectReasonCode disconnectReasonCode = null; AckReasonCode reasonCode = null; String reasonString = null;  switch (output.getAuthorizationState()) { case DISCONNECT: disconnectReasonCode = output.getDisconnectReasonCode(); reasonCode = output.getAckReasonCode() != null ? output.getAckReasonCode() : AckReasonCode.NOT_AUTHORIZED; reasonString = output.getReasonString() != null ? output.getReasonString() : getReasonString(connect); break; case FAIL: reasonCode = output.getAckReasonCode() != null ? output.getAckReasonCode() : AckReasonCode.NOT_AUTHORIZED; reasonString = output.getReasonString() != null ? output.getReasonString() : getReasonString(connect); break; case UNDECIDED: if (!output.isAuthorizerPresent()) { //providers never returned an authorizer, same as continue break; } reasonCode = AckReasonCode.NOT_AUTHORIZED; reasonString = getReasonString(connect); break; case SUCCESS: reasonCode = AckReasonCode.SUCCESS; break; case CONTINUE: break; default: //no state left throw new IllegalStateException("Unknown type"); }  final PublishAuthorizerResult result = new PublishAuthorizerResult(reasonCode, reasonString, output.isAuthorizerPresent(), disconnectReasonCode); ctx.pipeline().fireUserEventTriggered(new PluginAuthorizerServiceImpl.AuthorizeWillResultEvent(connect, result)); }
[*] target: assertNotNull(resultEvent)
[-] pred: org. junit. Assert. assertNotNull ( resultEvent )
************************************
************************************
[+] input: Exception { try (Git git = new Git(db)) { writeTrashFile("file.txt", "content"); git.add().addFilepattern("file.txt").call(); RevCommit commit = git.commit().setMessage("create file").call();  SubmoduleAddCommand command = new SubmoduleAddCommand(db); String path = "sub"; command.setPath(path); String uri = db.getDirectory().toURI().toString(); command.setURI(uri); Repository repo = command.call(); assertNotNull(repo); addRepoToClose(repo);  try (SubmoduleWalk generator = SubmoduleWalk.forIndex(db)) { assertTrue(generator.next()); assertEquals(path, generator.getPath()); assertEquals(commit, generator.getObjectId()); assertEquals(uri, generator.getModulesUrl()); assertEquals(path, generator.getModulesPath()); assertEquals(uri, generator.getConfigUrl()); try (Repository subModRepo = generator.getRepository()) { assertNotNull(subModRepo); } } assertEquals(commit, repo.resolve(Constants.HEAD));  RevCommit submoduleCommit = git.commit().setMessage("submodule add") .setOnly(path).call(); "<AssertPlaceHolder>"; try (TreeWalk walk = new TreeWalk(db)) { walk.addTree(commit.getTree()); walk.addTree(submoduleCommit.getTree()); walk.setFilter(TreeFilter.ANY_DIFF); List<DiffEntry> diffs = DiffEntry.scan(walk); assertEquals(1, diffs.size()); DiffEntry subDiff = diffs.get(0); assertEquals(FileMode.MISSING, subDiff.getOldMode()); assertEquals(FileMode.GITLINK, subDiff.getNewMode()); assertEquals(ObjectId.zeroId(), subDiff.getOldId().toObjectId()); assertEquals(commit, subDiff.getNewId().toObjectId()); assertEquals(path, subDiff.getNewPath()); } } }
call() throws GitAPIException, AbortedByHookException, ConcurrentRefUpdateException, NoHeadException, NoMessageException, ServiceUnavailableException, UnmergedPathsException, WrongRepositoryStateException { checkCallable(); Collections.sort(only);  try (RevWalk rw = new RevWalk(repo)) { RepositoryState state = repo.getRepositoryState(); if (!state.canCommit()) throw new WrongRepositoryStateException(MessageFormat.format( JGitText.get().cannotCommitOnARepoWithState, state.name()));  if (!noVerify) { Hooks.preCommit(repo, hookOutRedirect.get(PreCommitHook.NAME), hookErrRedirect.get(PreCommitHook.NAME)) .call(); }  processOptions(state, rw);  if (all && !repo.isBare()) { try (Git git = new Git(repo)) { git.add().addFilepattern(".") //$NON-NLS-1$ .setUpdate(true).call(); } catch (NoFilepatternException e) { // should really not happen throw new JGitInternalException(e.getMessage(), e); } }  Ref head = repo.exactRef(Constants.HEAD); if (head == null) throw new NoHeadException( JGitText.get().commitOnRepoWithoutHEADCurrentlyNotSupported);  // determine the current HEAD and the commit it is referring to ObjectId headId = repo.resolve(Constants.HEAD + "^{commit}"); //$NON-NLS-1$ if (headId == null && amend) throw new WrongRepositoryStateException( JGitText.get().commitAmendOnInitialNotPossible);  if (headId != null) { if (amend) { RevCommit previousCommit = rw.parseCommit(headId); for (RevCommit p : previousCommit.getParents()) parents.add(p.getId()); if (author == null) author = previousCommit.getAuthorIdent(); } else { parents.add(0, headId); } } if (!noVerify) { message = Hooks .commitMsg(repo, hookOutRedirect.get(CommitMsgHook.NAME), hookErrRedirect.get(CommitMsgHook.NAME)) .setCommitMessage(message).call(); }  CommitConfig config = null; if (CleanupMode.DEFAULT.equals(cleanupMode)) { config = repo.getConfig().get(CommitConfig.KEY); cleanupMode = config.resolve(cleanupMode, cleanDefaultIsStrip); } char comments = (char) 0; if (CleanupMode.STRIP.equals(cleanupMode) || CleanupMode.SCISSORS.equals(cleanupMode)) { if (commentChar == null) { if (config == null) { config = repo.getConfig().get(CommitConfig.KEY); } if (config.isAutoCommentChar()) { // We're supposed to pick a character that isn't used, // but then cleaning up won't remove any lines. So don't // bother. comments = (char) 0; cleanupMode = CleanupMode.WHITESPACE; } else { comments = config.getCommentChar(); } } else { comments = commentChar.charValue(); } } message = CommitConfig.cleanText(message, cleanupMode, comments);  RevCommit revCommit; DirCache index = repo.lockDirCache(); try (ObjectInserter odi = repo.newObjectInserter()) { if (!only.isEmpty()) index = createTemporaryIndex(headId, index, rw);  // Write the index as tree to the object database. This may // fail for example when the index contains unmerged paths // (unresolved conflicts) ObjectId indexTreeId = index.writeTree(odi);  if (insertChangeId) insertChangeId(indexTreeId);  checkIfEmpty(rw, headId, indexTreeId);  // Create a Commit object, populate it and write it CommitBuilder commit = new CommitBuilder(); commit.setCommitter(committer); commit.setAuthor(author); commit.setMessage(message); commit.setParentIds(parents); commit.setTreeId(indexTreeId);  if (signCommit.booleanValue()) { sign(commit); }  ObjectId commitId = odi.insert(commit); odi.flush(); revCommit = rw.parseCommit(commitId);  updateRef(state, headId, revCommit, commitId); } finally { index.unlock(); } try { Hooks.postCommit(repo, hookOutRedirect.get(PostCommitHook.NAME), hookErrRedirect.get(PostCommitHook.NAME)).call(); } catch (Exception e) { log.error(MessageFormat.format( JGitText.get().postCommitHookFailed, e.getMessage()), e); } return revCommit; } catch (UnmergedPathException e) { throw new UnmergedPathsException(e); } catch (IOException e) { throw new JGitInternalException( JGitText.get().exceptionCaughtDuringExecutionOfCommitCommand, e); } }
[*] target: assertNotNull(submoduleCommit)
[-] pred: org. junit. Assert. assertNotNull ( submoduleCommit )
************************************
************************************
[+] input: JsonProcessingException { String json = "{"resultCode":200,"errorCode":0,"connectionId":"35643245_1.1.1.1_3306","success":true," + ""supportAbilityNegotiation":true}"; ServerCheckResponse response = mapper.readValue(json, ServerCheckResponse.class); assertEquals("35643245_1.1.1.1_3306", response.getConnectionId()); "<AssertPlaceHolder>"; }
isSupportAbilityNegotiation() { return supportAbilityNegotiation; }
[*] target: assertTrue(response.isSupportAbilityNegotiation())
[-] pred: org. junit. Assert. assertTrue ( response. isSupportAbilityNegotiation ( ) )
************************************
************************************
[+] input: shouldReturnTimestampedWindowStoreAsWindowStore() { final GlobalStateStoreProvider provider = new GlobalStateStoreProvider(stores); final List<ReadOnlyWindowStore<String, ValueAndTimestamp<String>>> stores = provider.stores("ts-w-store", QueryableStoreTypes.windowStore()); "<AssertPlaceHolder>"; for (final ReadOnlyWindowStore<String, ValueAndTimestamp<String>> store : stores) { assertThat(store, instanceOf(ReadOnlyWindowStore.class)); assertThat(store, not(instanceOf(TimestampedWindowStore.class))); } }
stores(final String storeName, final QueryableStoreType<T> queryableStoreType) { final StateStore store = globalStateStores.get(storeName); if (store == null || !queryableStoreType.accepts(store)) { return Collections.emptyList(); } if (!store.isOpen()) { throw new InvalidStateStoreException("the state store, " + storeName + ", is not open."); } if (store instanceof TimestampedKeyValueStore && queryableStoreType instanceof QueryableStoreTypes.KeyValueStoreType) { return (List<T>) Collections.singletonList(new ReadOnlyKeyValueStoreFacade((TimestampedKeyValueStore<Object, Object>) store)); } else if (store instanceof TimestampedWindowStore && queryableStoreType instanceof QueryableStoreTypes.WindowStoreType) { return (List<T>) Collections.singletonList(new ReadOnlyWindowStoreFacade((TimestampedWindowStore<Object, Object>) store)); } return (List<T>) Collections.singletonList(store); }
[*] target: assertEquals(1, stores.size())
[-] pred: org. junit. Assert. assertEquals ( 1, stores. size ( ) )
************************************
************************************
[+] input: setReasonString() { final PubcompPacketImpl packet = new PubcompPacketImpl( 1, PubcompReasonCode.SUCCESS, null, UserPropertiesImpl.of(ImmutableList.of())); final ModifiablePubcompPacketImpl modifiablePacket = new ModifiablePubcompPacketImpl(packet, configurationService);  assertFalse(modifiablePacket.isModified());  modifiablePacket.setReasonString("reason");  assertEquals(Optional.of("reason"), modifiablePacket.getReasonString()); "<AssertPlaceHolder>"; }
isModified() { return modified || userProperties.isModified(); }
[*] target: assertTrue(modifiablePacket.isModified())
[-] pred: org. junit. Assert. assertTrue ( modifiablePacket. isModified() )
************************************
************************************
[+] input: shouldOnlyIterateOverSegmentsInRangeWhenNullKeyFrom() { iterator = new SegmentIterator<>( Arrays.asList(segmentOne, segmentTwo).iterator(), hasNextCondition, null, Bytes.wrap("c".getBytes()), true);  assertTrue(iterator.hasNext()); assertEquals("a", new String(iterator.peekNextKey().get())); assertEquals(KeyValue.pair("a", "1"), toStringKeyValue(iterator.next()));  assertTrue(iterator.hasNext()); assertEquals("b", new String(iterator.peekNextKey().get())); assertEquals(KeyValue.pair("b", "2"), toStringKeyValue(iterator.next()));  assertTrue(iterator.hasNext()); assertEquals("c", new String(iterator.peekNextKey().get())); assertEquals(KeyValue.pair("c", "3"), toStringKeyValue(iterator.next()));  "<AssertPlaceHolder>"; }
hasNext() { boolean hasNext = false; while ((currentIterator == null || !(hasNext = hasNextConditionHasNext()) || !currentSegment.isOpen()) && segments.hasNext()) { close(); currentSegment = segments.next(); try { if (forward) { currentIterator = currentSegment.range(from, to); } else { currentIterator = currentSegment.reverseRange(from, to); } } catch (final InvalidStateStoreException e) { // segment may have been closed so we ignore it. } } return currentIterator != null && hasNext; }
[*] target: assertFalse(iterator.hasNext())
[-] pred: org. junit. Assert. assertFalse ( iterator. hasNext ( ) )
************************************
************************************
[+] input: metaPropertyInitialize() { String[] keys = new String[] { "JDBC_URL", "JDBC_USERNAME", "JDBC_PASSWORD" }; Map<String, String> backup = new HashMap<>(); for (String key : keys) { backup.put(key, System.clearProperty(key)); } try { MetaPropertyInitializer initializer = new MetaPropertyInitializer(); assertFalse(initializer.isPropertyReady()); System.setProperty("JDBC_USERNAME", "test"); assertFalse(initializer.isPropertyReady()); initializer.initialize("127.0.0.1:2881", "test", "user", "pswd"); "<AssertPlaceHolder>"; } finally { for (Entry<String, String> entry : backup.entrySet()) { if (entry.getValue() != null) { System.setProperty(entry.getKey(), entry.getValue()); } } } }
isPropertyReady() { String jdbcUrl = getProperty("JDBC_URL"); String jdbcUsername = getProperty("JDBC_USERNAME"); return !Strings.isNullOrEmpty(jdbcUrl) && !Strings.isNullOrEmpty(jdbcUsername); }
[*] target: assertTrue(initializer.isPropertyReady())
[-] pred: org. junit. Assert. assertTrue ( initializer. isPropertyReady ( ) )
************************************
************************************
[+] input: Exception { // Generate a PQ for random vectors var vectors = createRandomVectors(512, 64); var ravv = new ListRandomAccessVectorValues(vectors, 64); var bq = new BinaryQuantization(ravv.dimension());  // Compress the vectors var compressed = bq.encodeAll(ravv); var cv = new BQVectors(bq, compressed); assertEquals(64 * Float.BYTES, cv.getOriginalSize()); assertEquals(8, cv.getCompressedSize());  // Write compressed vectors File cvFile = File.createTempFile("bqtest", ".cv"); try (var out = new DataOutputStream(new FileOutputStream(cvFile))) { cv.write(out); } // Read compressed vectors try (var in = new SimpleMappedReader(cvFile.getAbsolutePath())) { var cv2 = BQVectors.load(in, 0); "<AssertPlaceHolder>"; } }
write(DataOutput out) throws IOException { write(out, OnDiskGraphIndex.CURRENT_VERSION); }
[*] target: assertEquals(cv, cv2)
[-] pred: org. junit. Assert. assertEquals ( cv, cv2 )
************************************
************************************
[+] input: testGetSubscribersFuzzy() { String serviceName = "test"; String namespaceId = "public"; boolean aggregation = Boolean.TRUE; try { List<Subscriber> clients = new ArrayList<Subscriber>(); Subscriber subscriber = new Subscriber("127.0.0.1:8080", "test", "app", "127.0.0.1", namespaceId, "testGroupName@@test_subscriber", 0); clients.add(subscriber); Mockito.when(this.aggregation.getFuzzySubscribers(Mockito.anyString(), Mockito.anyString())) .thenReturn(clients); List<Subscriber> list = subscribeManager.getSubscribers(serviceName, namespaceId, aggregation); Assert."<AssertPlaceHolder>"; Assert.assertEquals(1, list.size()); Assert.assertEquals("testGroupName@@test_subscriber", list.get(0).getServiceName()); } catch (Exception ignored) {  } }
getSubscribers(String serviceName, String namespaceId, boolean aggregation) { if (aggregation) { Collection<Subscriber> result = aggregationService.getFuzzySubscribers(namespaceId, serviceName); return CollectionUtils.isNotEmpty(result) ? result.stream().filter(distinctByKey(Subscriber::toString)) .collect(Collectors.toList()) : Collections.EMPTY_LIST; } else { return new LinkedList<>(localService.getFuzzySubscribers(namespaceId, serviceName)); } }
[*] target: assertNotNull(list)
[-] pred: org. junit. Assert. assertNotNull ( list )
************************************
************************************
[+] input: Exception { final SettableFuture<PublishStatus> future = SettableFuture.create(); final PUBLISH publish = new PUBLISHFactory.Mqtt3Builder() .withHivemqId("hivemqId") .withPayload(new byte[]{0}) .withTopic("topic") .withQoS(QoS.AT_LEAST_ONCE) .withOnwardQos(QoS.AT_LEAST_ONCE) .withMessageExpiryInterval(MESSAGE_EXPIRY_INTERVAL_NOT_SET) .withPublishId(1L) .withPersistence(publishPayloadPersistence) .build(); final PublishWithFuture publishWithFuture = new PublishWithFuture(publish, future, false, publishPayloadPersistence); final boolean messageDropped = handler.checkChannelNotWritable(ctx, publishWithFuture, promise); "<AssertPlaceHolder>"; assertEquals(false, future.isDone()); // will be set in the Ordered topic handler verify(promise, never()).setSuccess(); verify(counter, never()).inc(); verify(publishPayloadPersistence, never()).decrementReferenceCounter(1); }
checkChannelNotWritable(final ChannelHandlerContext ctx, final @NotNull Object msg, final @NotNull ChannelPromise promise) throws Exception { if (!ctx.channel().isWritable()) {  if (msg instanceof PUBLISH) { if (notWritableMessages.get() < notWritableQueueSize) { notWritableMessages.incrementAndGet(); promise.addListeners(decrementCounterListener); return false; }  final PUBLISH publish = (PUBLISH) msg; if ((publish).getQoS() == QoS.AT_MOST_ONCE) { if (msg instanceof PublishWithFuture) { final SettableFuture<PublishStatus> future = ((PublishWithFuture) msg).getFuture(); future.set(PublishStatus.CHANNEL_NOT_WRITABLE); } //Drop message final String clientId = ctx.channel().attr(ClientConnection.CHANNEL_ATTRIBUTE_NAME).get().getClientId(); log.trace("Dropped qos 0 message for client {} on topic {} because the channel was not writable", clientId, publish.getTopic()); messageDroppedService.notWritable(clientId, publish.getTopic(), publish.getQoS().getQosNumber()); promise.setSuccess(); return true; } } }  return false; }
[*] target: assertFalse(messageDropped)
[-] pred: org. junit. Assert. assertFalse ( messageDropped )
************************************
************************************
[+] input: Exception { init("ConflictOutOfBounds", true, true);  Result result = applyPatchAllowConflicts();  assertEquals(result.getErrors().size(), 1); PatchApplier.Result.Error error = result.getErrors().get(0); assertEquals("cannot apply hunk", error.msg); assertEquals("ConflictOutOfBounds", error.oldFileName); "<AssertPlaceHolder>"; verifyChange(result, "ConflictOutOfBounds", true, 1); }
isGitConflict() { return isGitConflict; }
[*] target: assertTrue(error.isGitConflict())
[-] pred: org. junit. Assert. assertTrue ( error. isGitConflict() )
************************************
************************************
[+] input: CloneNotSupportedException { Tcp original = new Tcp(); Tcp cloned = original.clone(); assertEquals(original.hashCode(), cloned.hashCode()); "<AssertPlaceHolder>"; }
equals(Object obj) { return obj instanceof Tcp; }
[*] target: assertTrue(original.equals(cloned))
[-] pred: org. junit. Assert. assertTrue ( original. equals ( cloned ) )
************************************
************************************
[+] input: findAllAnnotations() { Set<Annotation> annotations = finder.findAllAnnotations(Foo.class, Annotation.class); Assert."<AssertPlaceHolder>"; Assert.assertEquals(3, annotations.size()); }
findAllAnnotations(@NonNull AnnotatedElement element, Class<A> annotationType) { return Stream.of(element.getAnnotationsByType(annotationType)) .collect(Collectors.toSet()); }
[*] target: assertNotNull(annotations)
[-] pred: org. junit. Assert. assertNotNull ( annotations )
************************************
************************************
[+] input: Exception { config("Host orcz\n" + "\tHostName repo.or.cz\n" + "\n" + "Host *\n" + "\tBatchMode yes\n"); final Host h = osc.lookup("orcz"); assertNotNull(h); "<AssertPlaceHolder>"; }
isBatchMode() { return batchMode != null && batchMode.booleanValue(); }
[*] target: assertTrue(h.isBatchMode())
[-] pred: org. junit. Assert. assertTrue ( h. isBatchMode() )
************************************
************************************
[+] input: triggerWhenCreated() { List<ContainerLifecycleProcessor> processors = Arrays.asList( AlwaysNullContainerLifecycleProcessor.INSTANCE, DoNothingContainerLifecycleProcessor.INSTANCE ); Container<Object> container = Container.empty(); container = ConfigurationUtil.triggerWhenCreated(Container.EMPTY_CONTAINER_NAMESPACE, null, container, processors, log); Assert.assertNull(container);  container = ConfigurationUtil.triggerWhenCreated(Container.EMPTY_CONTAINER_NAMESPACE, null, null, processors, log); Assert."<AssertPlaceHolder>"; }
triggerWhenCreated( String namespace, ContainerDefinition definition, Container<Object> container, Collection<ContainerLifecycleProcessor> containerLifecycleProcessorList, Logger log) { for (ContainerLifecycleProcessor containerLifecycleProcessor : containerLifecycleProcessorList) { container = containerLifecycleProcessor.whenCreated(definition, container); if (Objects.isNull(container)) { log.warn( "not create container for [{}], because of container lifecycle processor [{}] return null", namespace, containerLifecycleProcessor.getClass().getSimpleName() ); break; } } return container; }
[*] target: assertNull(container)
[-] pred: org. junit. Assert. assertNull ( container )
************************************
************************************
[+] input: shouldRemoveCompactionFromOffsetTopicSettings() { Map<String, String> expectedTopicSettings = new HashMap<>(); expectedTopicSettings.put("foo", "foo value"); expectedTopicSettings.put("bar", "bar value"); expectedTopicSettings.put("baz.bim", "100"); Map<String, String> topicSettings = new HashMap<>(expectedTopicSettings); topicSettings.put("cleanup.policy", "something-else");  Map<String, String> settings = configs(); topicSettings.forEach((k, v) -> settings.put(DistributedConfig.OFFSET_STORAGE_PREFIX + k, v)); DistributedConfig config = new DistributedConfig(settings); Map<String, Object> actual = config.offsetStorageTopicSettings(); "<AssertPlaceHolder>"; assertNotEquals(topicSettings, actual); }
offsetStorageTopicSettings() { return topicSettings(OFFSET_STORAGE_PREFIX); }
[*] target: assertEquals(expectedTopicSettings, actual)
[-] pred: org. junit. Assert. assertEquals ( expectedTopicSettings, actual )
************************************
************************************
[+] input: JsonProcessingException { ServerNamingAbility expected = new ServerNamingAbility(); expected.setSupportJraft(true); String serializeJson = jacksonMapper.writeValueAsString(expected); ServerNamingAbility actual = jacksonMapper.readValue(serializeJson, ServerNamingAbility.class); assertEquals(expected, actual); actual = new ServerNamingAbility(); assertNotEquals(expected, actual); actual.setSupportJraft(true); "<AssertPlaceHolder>"; }
hashCode() { return Objects.hash(supportJraft); }
[*] target: assertEquals(expected.hashCode(), actual.hashCode())
[-] pred: org. junit. Assert. assertEquals ( expected. hashCode ( ), actual. hashCode() )
************************************
************************************
[+] input: Exception { final DirCache tree0 = db.readDirCache(); final DirCache tree1 = db.readDirCache(); { final DirCacheBuilder b0 = tree0.builder(); final DirCacheBuilder b1 = tree1.builder();  b0.add(createEntry("0", REGULAR_FILE)); b0.add(createEntry("a", REGULAR_FILE)); b1.add(createEntry("0", REGULAR_FILE)); b1.add(createEntry("a.b", REGULAR_FILE)); b1.add(createEntry("a/b", REGULAR_FILE)); b1.add(createEntry("a/c/e", REGULAR_FILE));  b0.finish(); b1.finish(); assertEquals(2, tree0.getEntryCount()); assertEquals(4, tree1.getEntryCount()); }  try (NameConflictTreeWalk tw = new NameConflictTreeWalk(db)) { tw.addTree(new DirCacheIterator(tree0)); tw.addTree(new DirCacheIterator(tree1));  assertModes("0", REGULAR_FILE, REGULAR_FILE, tw); assertFalse(tw.isDirectoryFileConflict()); assertModes("a", REGULAR_FILE, TREE, tw); assertTrue(tw.isSubtree()); assertTrue(tw.isDirectoryFileConflict()); tw.enterSubtree(); assertModes("a/b", MISSING, REGULAR_FILE, tw); assertTrue(tw.isDirectoryFileConflict()); assertModes("a/c", MISSING, TREE, tw); assertTrue(tw.isDirectoryFileConflict()); tw.enterSubtree(); assertModes("a/c/e", MISSING, REGULAR_FILE, tw); assertTrue(tw.isDirectoryFileConflict());  assertModes("a.b", MISSING, REGULAR_FILE, tw); "<AssertPlaceHolder>"; } }
isDirectoryFileConflict() { return dfConflict != null; }
[*] target: assertFalse(tw.isDirectoryFileConflict())
[-] pred: org. junit. Assert. assertFalse ( tw. isDirectoryFileConflict() )
************************************
************************************
[+] input: testGetChildren() { List<String> list = ZkHelper.getChildren(zooKeeper, "/hbase/table"); Assert."<AssertPlaceHolder>"; Assert.assertEquals(2, list.size()); }
getChildren(ZooKeeper zooKeeper, String path) { if(zooKeeper != null){ try{ return zooKeeper.getChildren(path,false); }catch (Exception e){ LOG.error("failed to get children, path :{}, {} ",path, ExceptionUtil.getErrorMessage(e)); return null; }  }else { return null; }  }
[*] target: assertNotNull(list)
[-] pred: org. junit. Assert. assertNotNull ( list )
************************************
************************************
[+] input: testAllClientId() { Collection<String> allClientIds = persistentIpPortClientManager.allClientId(); assertEquals(1, allClientIds.size()); "<AssertPlaceHolder>"; }
contains(String clientId) { return clients.containsKey(clientId); }
[*] target: assertTrue(allClientIds.contains(clientId))
[-] pred: org. junit. Assert. assertTrue ( allClientIds. contains ( clientId ) )
************************************
************************************
[+] input: delete_deleteBeginApprovalInstanceWithTopoExists_endNodeLeft() { FlowApprovalInstance begin = createApprovalInstance(true, false); FlowApprovalInstance end = createApprovalInstance(false, true); next(begin, end); begin.delete(); List<NodeInstanceEntity> begins = nodeRepository.findByInstanceIdAndInstanceTypeAndFlowableElementType( begin.getId(), FlowNodeType.APPROVAL_TASK, begin.getCoreFlowableElementType());  Assert."<AssertPlaceHolder>"; List<SequenceInstanceEntity> entities = sequenceRepository.findAll(); Assert.assertEquals(0, entities.size()); }
getCoreFlowableElementType() { return FlowableElementType.USER_TASK; }
[*] target: assertTrue(begins.isEmpty())
[-] pred: org. junit. Assert. assertTrue ( begins. isEmpty ( ) )
************************************
************************************
[+] input: testFailWorkflowWithInputPayload() { WorkflowModel workflow = new WorkflowModel(); workflow.setInput(new HashMap<>());  expectedException.expect(TerminateWorkflowException.class); externalPayloadStorageUtils.failWorkflow( workflow, ExternalPayloadStorage.PayloadType.TASK_INPUT, "error"); "<AssertPlaceHolder>"; assertTrue(workflow.getInput().isEmpty()); assertEquals(WorkflowModel.Status.FAILED, workflow.getStatus()); }
failWorkflow(WorkflowModel workflow, PayloadType payloadType, String errorMsg) { LOGGER.error(errorMsg); if (payloadType == PayloadType.WORKFLOW_INPUT) { workflow.setInput(new HashMap<>()); } else { workflow.setOutput(new HashMap<>()); } throw new TerminateWorkflowException(errorMsg); }
[*] target: assertNotNull(workflow)
[-] pred: org. junit. Assert. assertNotNull ( workflow )
************************************
************************************
[+] input: shouldOptimizeActiveTasksWithMoreClients() { final Map<Subtopology, Set<TaskId>> tasksForTopicGroup = mkMap( mkEntry(new Subtopology(0, null), mkSet(TASK_0_0)), mkEntry(new Subtopology(1, null), mkSet(TASK_1_0)) ); final RackAwareTaskAssignor assignor = new RackAwareTaskAssignor( getClusterForAllTopics(), getTaskTopicPartitionMapForAllTasks(), mkMap(), tasksForTopicGroup, getProcessRacksForAllProcess(), mockInternalTopicManager, getRackAwareEnabledConfig(), time );  final ClientState clientState1 = new ClientState(emptySet(), emptySet(), emptyMap(), EMPTY_CLIENT_TAGS, 1); final ClientState clientState2 = new ClientState(emptySet(), emptySet(), emptyMap(), EMPTY_CLIENT_TAGS, 1); final ClientState clientState3 = new ClientState(emptySet(), emptySet(), emptyMap(), EMPTY_CLIENT_TAGS, 1);  clientState2.assignActive(TASK_1_0); clientState3.assignActive(TASK_0_0);  // task_0_0 has same rack as UUID_1 and UUID_2 // task_1_0 has same rack as UUID_1 and UUID_3 // Optimal assignment is UUID_1: {}, UUID_2: {0_0}, UUID_3: {1_0} which result in no cross rack traffic // and keeps UUID_1 empty since it was originally empty final SortedMap<UUID, ClientState> clientStateMap = new TreeMap<>(mkMap( mkEntry(UUID_1, clientState1), mkEntry(UUID_2, clientState2), mkEntry(UUID_3, clientState3) )); final SortedSet<TaskId> taskIds = mkSortedSet(TASK_0_0, TASK_1_0);  assertTrue(assignor.canEnableRackAwareAssignor()); final long originalCost = assignor.activeTasksCost(taskIds, clientStateMap, trafficCost, nonOverlapCost); int expected = stateful ? 20 : 2; assertEquals(expected, originalCost);  expected = stateful ? 2 : 0; final long cost = assignor.optimizeActiveTasks(taskIds, clientStateMap, trafficCost, nonOverlapCost); "<AssertPlaceHolder>";  // UUID_1 remains empty assertEquals(mkSet(), clientState1.activeTasks()); assertEquals(mkSet(TASK_0_0), clientState2.activeTasks()); assertEquals(mkSet(TASK_1_0), clientState3.activeTasks()); }
optimizeActiveTasks(final SortedSet<TaskId> activeTasks, final SortedMap<UUID, ClientState> clientStates, final int trafficCost, final int nonOverlapCost) { if (activeTasks.isEmpty()) { return 0; }  log.info("Assignment before active task optimization is {}\n with cost {}", clientStates, activeTasksCost(activeTasks, clientStates, trafficCost, nonOverlapCost));  final long startTime = time.milliseconds(); final List<UUID> clientList = new ArrayList<>(clientStates.keySet()); final List<TaskId> taskIdList = new ArrayList<>(activeTasks); final Map<TaskId, UUID> taskClientMap = new HashMap<>(); final Map<UUID, Integer> originalAssignedTaskNumber = new HashMap<>(); final RackAwareGraphConstructor<ClientState> graphConstructor = RackAwareGraphConstructorFactory.create(assignmentConfigs, tasksForTopicGroup); final Graph<Integer> graph = graphConstructor.constructTaskGraph( clientList, taskIdList, clientStates, taskClientMap, originalAssignedTaskNumber, ClientState::hasActiveTask, this::getCost, trafficCost, nonOverlapCost, false, false );  graph.solveMinCostFlow(); final long cost = graph.totalCost();  graphConstructor.assignTaskFromMinCostFlow(graph, clientList, taskIdList, clientStates, originalAssignedTaskNumber, taskClientMap, ClientState::assignActive, ClientState::unassignActive, ClientState::hasActiveTask);  final long duration = time.milliseconds() - startTime; log.info("Assignment after {} milliseconds for active task optimization is {}\n with cost {}", duration, clientStates, cost); return cost; }
[*] target: assertEquals(expected, cost)
[-] pred: org. junit. Assert. assertEquals ( expected, cost )
************************************
************************************
[+] input: Exception { final Host h = osc.lookup("orcz"); assertNotNull(h); "<AssertPlaceHolder>"; }
getConnectionAttempts() { return connectionAttempts; }
[*] target: assertEquals(1, h.getConnectionAttempts())
[-] pred: org. junit. Assert. assertEquals ( 1, h. getConnectionAttempts ( ) )
************************************
************************************
[+] input: WriteProcessException { File testFile = new File(TestConstant.BASE_OUTPUT_PATH + "test.tsfile"); IDeviceID deviceID = Factory.DEFAULT_FACTORY.create("root.topic1"); try (TsFileWriter writer = new TsFileWriter(testFile)) { writer.registerTimeseries(deviceID, new MeasurementSchema("s", TSDataType.DOUBLE)); TSRecord record = new TSRecord(0, deviceID); record.addTuple(new DoubleDataPoint("s", 0.0)); writer.write(record); }  TsFileSequenceReader reader = new TsFileSequenceReader(testFile.getAbsolutePath()); BloomFilter bloomFilter = reader.readBloomFilter(); "<AssertPlaceHolder>"; assertTrue(bloomFilter.contains(deviceID.toString() + ".s")); assertFalse( bloomFilter.contains(Factory.DEFAULT_FACTORY.create("root.topic2").toString() + ".s")); }
readBloomFilter() throws IOException { readFileMetadata(); return tsFileMetaData.getBloomFilter(); }
[*] target: assertNotNull(bloomFilter)
[-] pred: org. junit. Assert. assertNotNull ( bloomFilter )
************************************
************************************
[+] input: Exception { git.tag().setAnnotated(false).setName("test-tag") .setObjectId(initialCommit).call(); Ref result = git.checkout().setName("test-tag").call();  "<AssertPlaceHolder>"; assertEquals(initialCommit.getId(), db.resolve(Constants.HEAD)); assertHeadDetached(); }
call() throws GitAPIException, RefAlreadyExistsException, RefNotFoundException, InvalidRefNameException, CheckoutConflictException { checkCallable(); try { processOptions(); if (checkoutAllPaths || !paths.isEmpty()) { checkoutPaths(); status = new CheckoutResult(Status.OK, paths); setCallable(false); return null; }  if (createBranch) { try (Git git = new Git(repo)) { CreateBranchCommand command = git.branchCreate(); command.setName(name); if (startCommit != null) command.setStartPoint(startCommit); else command.setStartPoint(startPoint); if (upstreamMode != null) command.setUpstreamMode(upstreamMode); command.call(); } }  Ref headRef = repo.exactRef(Constants.HEAD); if (headRef == null) { // TODO Git CLI supports checkout from unborn branch, we should // also allow this throw new UnsupportedOperationException( JGitText.get().cannotCheckoutFromUnbornBranch); } String shortHeadRef = getShortBranchName(headRef); String refLogMessage = "checkout: moving from " + shortHeadRef; //$NON-NLS-1$ ObjectId branch; if (orphan) { if (startPoint == null && startCommit == null) { Result r = repo.updateRef(Constants.HEAD).link( getBranchName()); if (!EnumSet.of(Result.NEW, Result.FORCED).contains(r)) throw new JGitInternalException(MessageFormat.format( JGitText.get().checkoutUnexpectedResult, r.name())); this.status = CheckoutResult.NOT_TRIED_RESULT; return repo.exactRef(Constants.HEAD); } branch = getStartPointObjectId(); } else { branch = repo.resolve(name); if (branch == null) throw new RefNotFoundException(MessageFormat.format( JGitText.get().refNotResolved, name)); }  RevCommit headCommit = null; RevCommit newCommit = null; try (RevWalk revWalk = new RevWalk(repo)) { AnyObjectId headId = headRef.getObjectId(); headCommit = headId == null ? null : revWalk.parseCommit(headId); newCommit = revWalk.parseCommit(branch); } RevTree headTree = headCommit == null ? null : headCommit.getTree(); DirCacheCheckout dco; DirCache dc = repo.lockDirCache(); try { dco = new DirCacheCheckout(repo, headTree, dc, newCommit.getTree()); dco.setFailOnConflict(true); dco.setForce(forced); if (forced) { dco.setFailOnConflict(false); } dco.setProgressMonitor(monitor); try { dco.checkout(); } catch (org.eclipse.jgit.errors.CheckoutConflictException e) { status = new CheckoutResult(Status.CONFLICTS, dco.getConflicts()); throw new CheckoutConflictException(dco.getConflicts(), e); } } finally { dc.unlock(); } Ref ref = repo.findRef(name); if (ref != null && !ref.getName().startsWith(Constants.R_HEADS)) ref = null; String toName = Repository.shortenRefName(name); RefUpdate refUpdate = repo.updateRef(Constants.HEAD, ref == null); refUpdate.setForceUpdate(forceRefUpdate); refUpdate.setRefLogMessage(refLogMessage + " to " + toName, false); //$NON-NLS-1$ Result updateResult; if (ref != null) updateResult = refUpdate.link(ref.getName()); else if (orphan) { updateResult = refUpdate.link(getBranchName()); ref = repo.exactRef(Constants.HEAD); } else { refUpdate.setNewObjectId(newCommit); updateResult = refUpdate.forceUpdate(); }  setCallable(false);  boolean ok = false; switch (updateResult) { case NEW: ok = true; break; case NO_CHANGE: case FAST_FORWARD: case FORCED: ok = true; break; default: break; }  if (!ok) throw new JGitInternalException(MessageFormat.format(JGitText .get().checkoutUnexpectedResult, updateResult.name()));   if (!dco.getToBeDeleted().isEmpty()) { status = new CheckoutResult(Status.NONDELETED, dco.getToBeDeleted(), new ArrayList<>(dco.getUpdated().keySet()), dco.getRemoved()); } else status = new CheckoutResult(new ArrayList<>(dco .getUpdated().keySet()), dco.getRemoved());  return ref; } catch (IOException ioe) { throw new JGitInternalException(ioe.getMessage(), ioe); } finally { if (status == null) status = CheckoutResult.ERROR_RESULT; } }
[*] target: assertNull(result)
[-] pred: org. junit. Assert. assertNull ( result )
************************************
************************************
[+] input: list_Filter() { List<CreateUserReq> requestList = new ArrayList<>(); for (int i = 0; i < 3; i++) { requestList.add(buildCreateUserReq("list_filter" + i)); } CreateUserReq customUserRequest = buildCreateUserReq("custom"); requestList.add(customUserRequest); List<User> createdUsers = userService.batchCreate(requestList); Assert.assertNotNull(createdUsers);  QueryUserParams queryParams = QueryUserParams.builder() .names(Arrays.asList("odc_user_name")) .accountNames(Arrays.asList(ACCOUNT_NAME_PREFIX + "list_filter")).build();  PaginatedData<User> listUsers = userService.list(queryParams, DEFAULT_PAGEABLE); Assert."<AssertPlaceHolder>"; Assert.assertEquals(createdUsers.size(), listUsers.getContents().size()); }
list(QueryUserParams queryUserParams, Pageable pageable) { if (Objects.nonNull(queryUserParams.getBasic()) && queryUserParams.getBasic()) { return listUserBasicsWithoutPermissionCheck(); } if (StringUtils.isNotEmpty(queryUserParams.getAuthorizedResource())) { // get related users for some specific resource, such as ODC_CONNECTION:10 or ODC_RESOURCE_GROUP:15 List<User> users = new ArrayList<>(); CustomPage customPage = CustomPage.empty(); ResourceContext resourceContext = ResourceContextUtil.parseFromResourceIdentifier(queryUserParams.getAuthorizedResource()); ResourceType resourceType = ResourceType.valueOf(resourceContext.getField()); PreConditions.notNull(resourceContext.getId(), "id"); String resourceId = resourceContext.getId().toString(); Map<User, Set<String>> userActionMap = permissionAccessor.permittedUserActions(resourceType, resourceId, permission -> true); Set<String> permittedUserIds = getAuthorizedUserIds(MoreObjects.firstNonNull(queryUserParams.getMinPrivilege(), "read")); if (!permittedUserIds.contains("*")) { userActionMap = userActionMap.entrySet().stream() .filter(entry -> permittedUserIds.contains(entry.getKey().getId().toString())) .collect(Collectors.toMap(Entry::getKey, Entry::getValue)); } acquireRolesAndRoleIds(userActionMap.keySet()); for (Map.Entry<User, Set<String>> entry : userActionMap.entrySet()) { User user = entry.getKey(); user.setAuthorizedActions(entry.getValue()); users.add(user); } return new PaginatedData<>(users, customPage); } return listUserWithQueryParams(queryUserParams, pageable, true); }
[*] target: assertNotNull(listUsers)
[-] pred: org. junit. Assert. assertNotNull ( listUsers )
************************************
************************************
[+] input: Exception { File target = dumpSchemaAndDataForLoad(DialectType.OB_ORACLE); assertOracleModeTableNotExists();  UploadFileResult actual = dataTransferService.getMetaInfo(target.getAbsolutePath()); UploadFileResult expect = new UploadFileResult(); expect.setFormat(DataFormat.SQL); expect.setFileType("ZIP"); expect.setFileName(target.getAbsolutePath()); expect.setContainsData(true); expect.setContainsSchema(true); Map<ObjectType, Set<String>> importFileNames = new HashMap<>(); importFileNames.putIfAbsent(ObjectType.TABLE, Collections.singleton(TEST_TABLE_NAME)); expect.setImportObjects(importFileNames);  Assert."<AssertPlaceHolder>"; }
getMetaInfo(@NonNull String fileName) throws IOException { File uploadFile = fileManager.findByName(TaskType.IMPORT, LocalFileManager.UPLOAD_BUCKET, fileName).orElseThrow( () -> new FileNotFoundException("File not found")); if (!uploadFile.exists() || !uploadFile.isFile()) { throw new IllegalArgumentException("Target is not a file or does not exist, " + fileName); }  // If the file is from third party like PL/SQL, this will convert it compatible with ob-loader. ThirdPartyOutputConverter.convert(uploadFile);  String uploadFileName = uploadFile.getName(); if (StringUtils.endsWithIgnoreCase(uploadFileName, ".zip")) { // 疑似 zip 压缩文件，需要进一步确认是否合法 try { ExportOutput dumperOutput = new ExportOutput(uploadFile); return UploadFileResult.ofExportOutput(fileName, dumperOutput); } catch (Exception e) { log.warn("Not a valid zip file, file={}", fileName, e); return UploadFileResult.ofFail(ErrorCodes.ImportInvalidFileType, new Object[] {uploadFileName}); } } else if (StringUtils.endsWithIgnoreCase(uploadFileName, ".csv")) { return UploadFileResult.ofCsv(fileName); } else if (StringUtils.endsWithIgnoreCase(uploadFileName, ".sql") || StringUtils.endsWithIgnoreCase(uploadFileName, ".txt")) { return UploadFileResult.ofSql(fileName); } return UploadFileResult.ofFail(ErrorCodes.ImportInvalidFileType, new Object[] {uploadFileName}); }
[*] target: assertEquals(expect, actual)
[-] pred: org. junit. Assert. assertEquals ( expect, actual )
************************************
************************************
[+] input: Exception { String str = "http://example.com/"; URIish u = new URIish(str); assertEquals("example.com", u.getHost()); assertEquals("/", u.getPath()); assertEquals(str, u.toString());  str = "http://example.com"; u = new URIish(str); assertEquals("example.com", u.getHost()); assertEquals("", u.getPath()); "<AssertPlaceHolder>"; }
toString() { return format(false, false); }
[*] target: assertEquals(str, u.toString())
[-] pred: org. junit. Assert. assertEquals ( str, u. toString ( ) )
************************************
************************************
[+] input: connectorConfig() { final String connName = "sink6"; final Map<String, String> expectedConfig = Collections.singletonMap("key", "value");  @SuppressWarnings("unchecked") ArgumentCaptor<Callback<Map<String, String>>> callback = ArgumentCaptor.forClass(Callback.class); doAnswer(invocation -> { callback.getValue().onCompletion(null, expectedConfig); return null; }).when(herder).connectorConfig(eq(connName), callback.capture());  Map<String, String> actualConfig = connectClusterState.connectorConfig(connName);  "<AssertPlaceHolder>"; assertNotSame( "Config should be copied in order to avoid mutation by REST extensions", expectedConfig, actualConfig ); }
connectorConfig(String connName) { FutureCallback<Map<String, String>> connectorConfigCallback = new FutureCallback<>(); herder.connectorConfig(connName, connectorConfigCallback); try { return new HashMap<>(connectorConfigCallback.get(herderRequestTimeoutMs, TimeUnit.MILLISECONDS)); } catch (InterruptedException | ExecutionException | TimeoutException e) { throw new ConnectException( String.format("Failed to retrieve configuration for connector '%s'", connName), e ); } }
[*] target: assertEquals(expectedConfig, actualConfig)
[-] pred: org. junit. Assert. assertEquals ( expectedConfig, actualConfig )
************************************
************************************
[+] input: Exception { commitGraph = CommitGraphLoader .open(JGitTestUtil.getTestResourceFile("commit-graph.v1")); "<AssertPlaceHolder>"; assertEquals(10, commitGraph.getCommitCnt()); verifyGraphObjectIndex();  assertCommitData("85b0176af27fa1640868f061f224d01e0b295f59", new int[] { 5, 6 }, 1670570408L, 3, 0); assertCommitData("d4f7c00aab3f0160168c9e5991abb6194a4e0d9e", new int[] {}, 1670569901L, 1, 1); assertCommitData("4d03aaf9c20c97d6ccdc05cb7f146b1deb6c01d5", new int[] { 5 }, 1670570119L, 3, 2); assertCommitData("a2f409b753880bf83b18bfb433dd340a6185e8be", new int[] { 7 }, 1670569935L, 3, 3); assertCommitData("431343847343979bbe31127ed905a24fed9a636c", new int[] { 3, 2, 8 }, 1670570644L, 4, 4); assertCommitData("c3f745ad8928ef56b5dbf33740fc8ede6b598290", new int[] { 1 }, 1670570106L, 2, 5); assertCommitData("95b12422c8ea4371e54cd58925eeed9d960ff1f0", new int[] { 1 }, 1670570163L, 2, 6); assertCommitData("de0ea882503cdd9c984c0a43238014569a123cac", new int[] { 1 }, 1670569921L, 2, 7); assertCommitData("102c9d6481559b1a113eb66bf55085903de6fb00", new int[] { 6 }, 1670570616L, 3, 8); assertCommitData("b5de2a84867f8ffc6321649dabf8c0680661ec03", new int[] { 7, 5 }, 1670570364L, 3, 9); }
open(File graphFile) throws FileNotFoundException, CommitGraphFormatException, IOException { try (SilentFileInputStream fd = new SilentFileInputStream(graphFile)) { try { return read(fd); } catch (CommitGraphFormatException fe) { throw fe; } catch (IOException ioe) { throw new IOException(MessageFormat.format( JGitText.get().unreadableCommitGraph, graphFile.getAbsolutePath()), ioe); } } }
[*] target: assertNotNull(commitGraph)
[-] pred: org. junit. Assert. assertNotNull ( commitGraph )
************************************
************************************
[+] input: testPending() { WorkflowDef def = new WorkflowDef(); def.setName("pending_count_test");  WorkflowModel workflow = createTestWorkflow(); workflow.setWorkflowDefinition(def);  List<String> workflowIds = generateWorkflows(workflow, 10); long count = getExecutionDAO().getPendingWorkflowCount(def.getName()); assertEquals(10, count);  for (int i = 0; i < 10; i++) { getExecutionDAO().removeFromPendingWorkflow(def.getName(), workflowIds.get(i)); }  count = getExecutionDAO().getPendingWorkflowCount(def.getName()); "<AssertPlaceHolder>"; }
getPendingWorkflowCount(String workflowName);
[*] target: assertEquals(0, count)
[-] pred: org. junit. Assert. assertEquals ( 0, count )
************************************
************************************
[+] input: test_disconnect() { output.authorizerPresent(); output.disconnectClient(); task.onSuccess(output);  final AuthorizeWillResultEvent resultEvent = eventsCollector.pollEvent(); "<AssertPlaceHolder>"; assertEquals(AckReasonCode.NOT_AUTHORIZED, resultEvent.getResult().getAckReasonCode()); assertTrue(resultEvent.getResult().isAuthorizerPresent()); }
onSuccess(@Nullable final PublishAuthorizerOutputImpl output) { if (output == null) { //this does not happen return; }  DisconnectReasonCode disconnectReasonCode = null; AckReasonCode reasonCode = null; String reasonString = null;  switch (output.getAuthorizationState()) { case DISCONNECT: disconnectReasonCode = output.getDisconnectReasonCode(); reasonCode = output.getAckReasonCode() != null ? output.getAckReasonCode() : AckReasonCode.NOT_AUTHORIZED; reasonString = output.getReasonString() != null ? output.getReasonString() : getReasonString(connect); break; case FAIL: reasonCode = output.getAckReasonCode() != null ? output.getAckReasonCode() : AckReasonCode.NOT_AUTHORIZED; reasonString = output.getReasonString() != null ? output.getReasonString() : getReasonString(connect); break; case UNDECIDED: if (!output.isAuthorizerPresent()) { //providers never returned an authorizer, same as continue break; } reasonCode = AckReasonCode.NOT_AUTHORIZED; reasonString = getReasonString(connect); break; case SUCCESS: reasonCode = AckReasonCode.SUCCESS; break; case CONTINUE: break; default: //no state left throw new IllegalStateException("Unknown type"); }  final PublishAuthorizerResult result = new PublishAuthorizerResult(reasonCode, reasonString, output.isAuthorizerPresent(), disconnectReasonCode); ctx.pipeline().fireUserEventTriggered(new PluginAuthorizerServiceImpl.AuthorizeWillResultEvent(connect, result)); }
[*] target: assertNotNull(resultEvent)
[-] pred: org. junit. Assert. assertNotNull ( resultEvent )
************************************
************************************
[+] input: shouldIterateBackwardOverAllSegmentsWhenNullKeyFromKeyTo() { iterator = new SegmentIterator<>( Arrays.asList(segmentTwo, segmentOne).iterator(), //store should pass the segments in the right order hasNextCondition, null, null, false);  assertTrue(iterator.hasNext()); assertEquals("d", new String(iterator.peekNextKey().get())); assertEquals(KeyValue.pair("d", "4"), toStringKeyValue(iterator.next()));  assertTrue(iterator.hasNext()); assertEquals("c", new String(iterator.peekNextKey().get())); assertEquals(KeyValue.pair("c", "3"), toStringKeyValue(iterator.next()));  assertTrue(iterator.hasNext()); assertEquals("b", new String(iterator.peekNextKey().get())); assertEquals(KeyValue.pair("b", "2"), toStringKeyValue(iterator.next()));  assertTrue(iterator.hasNext()); assertEquals("a", new String(iterator.peekNextKey().get())); assertEquals(KeyValue.pair("a", "1"), toStringKeyValue(iterator.next()));  "<AssertPlaceHolder>"; }
hasNext() { boolean hasNext = false; while ((currentIterator == null || !(hasNext = hasNextConditionHasNext()) || !currentSegment.isOpen()) && segments.hasNext()) { close(); currentSegment = segments.next(); try { if (forward) { currentIterator = currentSegment.range(from, to); } else { currentIterator = currentSegment.reverseRange(from, to); } } catch (final InvalidStateStoreException e) { // segment may have been closed so we ignore it. } } return currentIterator != null && hasNext; }
[*] target: assertFalse(iterator.hasNext())
[-] pred: org. junit. Assert. assertFalse ( iterator. hasNext ( ) )
************************************
************************************
[+] input: Exception { // Generate a PQ for random 2D vectors var vectors = createRandomVectors(512, 2); var ravv = new ListRandomAccessVectorValues(vectors, 2); var pq = ProductQuantization.compute(ravv, 1, 256, false);  // Compress the vectors var compressed = pq.encodeAll(ravv); var cv = new PQVectors(pq, compressed); assertEquals(2 * Float.BYTES, cv.getOriginalSize()); assertEquals(1, cv.getCompressedSize());  // Write compressed vectors File cvFile = File.createTempFile("pqtest", ".cv"); try (var out = new DataOutputStream(new FileOutputStream(cvFile))) { cv.write(out); } // Read compressed vectors try (var in = new SimpleMappedReader(cvFile.getAbsolutePath())) { var cv2 = PQVectors.load(in, 0); "<AssertPlaceHolder>"; } }
write(DataOutput out) throws IOException { write(out, OnDiskGraphIndex.CURRENT_VERSION); }
[*] target: assertEquals(cv, cv2)
[-] pred: org. junit. Assert. assertEquals ( cv, cv2 )
************************************
************************************
[+] input: testSetSelector() { LabelSelector labelSelector = new LabelSelector(); serviceMetadata.setSelector(labelSelector);  Selector selector = serviceMetadata.getSelector(); Assert."<AssertPlaceHolder>"; boolean result = selector instanceof LabelSelector; Assert.assertTrue(result); }
getSelector() { return selector; }
[*] target: assertNotNull(selector)
[-] pred: org. junit. Assert. assertNotNull ( selector )
************************************
************************************
[+] input: Exception { File directory = createTempDirectory("testRepository"); CloneCommand command = Git.cloneRepository(); command.setDirectory(directory); command.setURI(fileUri()); command.setCloneAllBranches(true); Git git2 = command.call(); addRepoToClose(git2.getRepository());   LsRemoteCommand lsRemoteCommand = git2.lsRemote(); Collection<Ref> refs = lsRemoteCommand.call(); "<AssertPlaceHolder>"; assertEquals(6, refs.size()); }
call() throws GitAPIException, InvalidRemoteException, org.eclipse.jgit.api.errors.TransportException { return execute().values(); }
[*] target: assertNotNull(refs)
[-] pred: org. junit. Assert. assertNotNull ( refs )
************************************
************************************
[+] input: Exception { setupReflog("logs/refs/heads/master", twoLineWithAppendInProgress); ReflogReader reader = new ReflogReaderImpl(db, "refs/heads/master"); List<ReflogEntry> reverseEntries = reader.getReverseEntries(); "<AssertPlaceHolder>"; ReflogEntry e = reverseEntries.get(0); assertEquals(ObjectId .fromString("c6734895958052a9dbc396cff4459dc1a25029ab"), e .getOldId()); assertEquals(ObjectId .fromString("54794942a18a237c57a80719afed44bb78172b10"), e .getNewId()); assertEquals("Same A U Thor", e.getWho().getName()); assertEquals("same.author@example.com", e.getWho().getEmailAddress()); assertEquals(60, e.getWho().getTimeZoneOffset()); assertEquals("2009-05-22T22:36:42", iso(e.getWho())); assertEquals( "rebase finished: refs/heads/rr/renamebranch5 onto c6e3b9fe2da0293f11eae202ec35fb343191a82d", e.getComment()); // while similar to testReadTwoLine, we can assume that if we get the last entry // right, everything else is too }
getReverseEntries() throws IOException;
[*] target: assertEquals(2, reverseEntries.size())
[-] pred: org. junit. Assert. assertEquals ( 2, reverseEntries. size ( ) )
************************************
************************************
[+] input: testGetAndSet() { ClientNamingAbility ability = new ClientNamingAbility(); assertFalse(ability.isSupportDeltaPush()); assertFalse(ability.isSupportRemoteMetric()); ability.setSupportDeltaPush(true); ability.setSupportRemoteMetric(true); assertTrue(ability.isSupportDeltaPush()); "<AssertPlaceHolder>"; }
isSupportRemoteMetric() { return supportRemoteMetric; }
[*] target: assertTrue(ability.isSupportRemoteMetric())
[-] pred: org. junit. Assert. assertTrue ( ability. isSupportRemoteMetric() )
************************************
************************************
[+] input: Exception { Git git = Git.wrap(db); List<RevCommit> commits = createCommits(git);  Iterator<RevCommit> log = git.log().all().setSkip(1).setMaxCount(1).call() .iterator(); "<AssertPlaceHolder>"; RevCommit commit = log.next(); assertTrue(commits.contains(commit)); assertEquals("commit#2", commit.getShortMessage()); assertFalse(log.hasNext()); }
call() throws GitAPIException, NoHeadException { checkCallable(); List<TreeFilter> filters = new ArrayList<>(); if (!pathFilters.isEmpty()) { filters.add(AndTreeFilter.create(PathFilterGroup.create(pathFilters), TreeFilter.ANY_DIFF)); } if (!excludeTreeFilters.isEmpty()) { for (TreeFilter f : excludeTreeFilters) { filters.add(AndTreeFilter.create(f, TreeFilter.ANY_DIFF)); } } if (!filters.isEmpty()) { if (filters.size() == 1) { filters.add(TreeFilter.ANY_DIFF); } walk.setTreeFilter(AndTreeFilter.create(filters));  } if (skip > -1 && maxCount > -1) walk.setRevFilter(AndRevFilter.create(SkipRevFilter.create(skip), MaxCountRevFilter.create(maxCount))); else if (skip > -1) walk.setRevFilter(SkipRevFilter.create(skip)); else if (maxCount > -1) walk.setRevFilter(MaxCountRevFilter.create(maxCount)); if (!startSpecified) { try { ObjectId headId = repo.resolve(Constants.HEAD); if (headId == null) throw new NoHeadException( JGitText.get().noHEADExistsAndNoExplicitStartingRevisionWasSpecified); add(headId); } catch (IOException e) { // all exceptions thrown by add() shouldn't occur and represent // severe low-level exception which are therefore wrapped throw new JGitInternalException( JGitText.get().anExceptionOccurredWhileTryingToAddTheIdOfHEAD, e); } }  if (this.revFilter != null) { walk.setRevFilter(this.revFilter); }  setCallable(false); return walk; }
[*] target: assertTrue(log.hasNext())
[-] pred: org. junit. Assert. assertTrue ( log. hasNext ( ) )
************************************
************************************
[+] input: testSwap() { final Edit e = new Edit(1, 2, 3, 4); e.swap(); assertEquals(3, e.getBeginA()); assertEquals(4, e.getEndA()); assertEquals(1, e.getBeginB()); "<AssertPlaceHolder>"; }
getEndB() { return endB; }
[*] target: assertEquals(2, e.getEndB())
[-] pred: org. junit. Assert. assertEquals ( 2, e. getEndB() )
************************************
************************************
[+] input: Exception { config("ConnectionAttempts 5\n\nHost orcz\nConnectionAttempts 3\n"); final Host h = osc.lookup("orcz"); assertNotNull(h); "<AssertPlaceHolder>"; }
getConnectionAttempts() { return connectionAttempts; }
[*] target: assertEquals(5, h.getConnectionAttempts())
[-] pred: org. junit. Assert. assertEquals ( 5, h. getConnectionAttempts ( ) )
************************************
************************************
[+] input: Exception { File file = writeTrashFile("file", "content"); git.add().addFilepattern("file").call(); git.commit().setMessage("x").call(); file.delete(); git.rm().addFilepattern("file").call(); recorder.assertNoEvent(); git.stashCreate().call(); recorder.assertEvent(new String[] { "file" }, ChangeRecorder.EMPTY); file.delete();  git.stashApply().setStashRef("stash@{0}").call();  "<AssertPlaceHolder>"; recorder.assertEvent(ChangeRecorder.EMPTY, new String[] { "file" }); }
call() throws GitAPIException, WrongRepositoryStateException, NoHeadException, StashApplyFailureException { checkCallable();  if (!ignoreRepositoryState && repo.getRepositoryState() != RepositoryState.SAFE) throw new WrongRepositoryStateException(MessageFormat.format( JGitText.get().stashApplyOnUnsafeRepository, repo.getRepositoryState()));  try (ObjectReader reader = repo.newObjectReader(); RevWalk revWalk = new RevWalk(reader)) {  ObjectId headCommit = repo.resolve(Constants.HEAD); if (headCommit == null) throw new NoHeadException(JGitText.get().stashApplyWithoutHead);  final ObjectId stashId = getStashId(); RevCommit stashCommit = revWalk.parseCommit(stashId); if (stashCommit.getParentCount() < 2 || stashCommit.getParentCount() > 3) throw new JGitInternalException(MessageFormat.format( JGitText.get().stashCommitIncorrectNumberOfParents, stashId.name(), Integer.valueOf(stashCommit.getParentCount())));  ObjectId headTree = repo.resolve(Constants.HEAD + "^{tree}"); //$NON-NLS-1$ ObjectId stashIndexCommit = revWalk.parseCommit(stashCommit .getParent(1)); ObjectId stashHeadCommit = stashCommit.getParent(0); ObjectId untrackedCommit = null; if (restoreUntracked && stashCommit.getParentCount() == 3) untrackedCommit = revWalk.parseCommit(stashCommit.getParent(2));  Merger merger = strategy.newMerger(repo); boolean mergeSucceeded; if (merger instanceof ResolveMerger) { ResolveMerger resolveMerger = (ResolveMerger) merger; resolveMerger .setCommitNames(new String[] { "stashed HEAD", "HEAD", //$NON-NLS-1$ //$NON-NLS-2$ "stash" }); //$NON-NLS-1$ resolveMerger.setBase(stashHeadCommit); resolveMerger .setWorkingTreeIterator(new FileTreeIterator(repo)); resolveMerger.setContentMergeStrategy(contentStrategy); mergeSucceeded = resolveMerger.merge(headCommit, stashCommit); List<String> modifiedByMerge = resolveMerger.getModifiedFiles(); if (!modifiedByMerge.isEmpty()) { repo.fireEvent(new WorkingTreeModifiedEvent(modifiedByMerge, null)); } } else { mergeSucceeded = merger.merge(headCommit, stashCommit); } if (mergeSucceeded) { DirCache dc = repo.lockDirCache(); DirCacheCheckout dco = new DirCacheCheckout(repo, headTree, dc, merger.getResultTreeId()); dco.setFailOnConflict(true); dco.checkout(); // Ignoring failed deletes.... if (restoreIndex) { Merger ixMerger = strategy.newMerger(repo, true); if (ixMerger instanceof ResolveMerger) { ResolveMerger resolveMerger = (ResolveMerger) ixMerger; resolveMerger.setCommitNames(new String[] { "stashed HEAD", //$NON-NLS-1$ "HEAD", "stashed index" }); //$NON-NLS-1$//$NON-NLS-2$ resolveMerger.setBase(stashHeadCommit); resolveMerger.setContentMergeStrategy(contentStrategy); } boolean ok = ixMerger.merge(headCommit, stashIndexCommit); if (ok) { resetIndex(revWalk .parseTree(ixMerger.getResultTreeId())); } else { throw new StashApplyFailureException( JGitText.get().stashApplyConflict); } }  if (untrackedCommit != null) { Merger untrackedMerger = strategy.newMerger(repo, true); if (untrackedMerger instanceof ResolveMerger) { ResolveMerger resolveMerger = (ResolveMerger) untrackedMerger; resolveMerger.setCommitNames(new String[] { "null", "HEAD", //$NON-NLS-1$//$NON-NLS-2$ "untracked files" }); //$NON-NLS-1$ // There is no common base for HEAD & untracked files // because the commit for untracked files has no parent. // If we use stashHeadCommit as common base (as in the // other merges) we potentially report conflicts for // files which are not even member of untracked files // commit. resolveMerger.setBase(null); resolveMerger.setContentMergeStrategy(contentStrategy); } boolean ok = untrackedMerger.merge(headCommit, untrackedCommit); if (ok) { try { RevTree untrackedTree = revWalk .parseTree(untrackedCommit); resetUntracked(untrackedTree); } catch (CheckoutConflictException e) { throw new StashApplyFailureException( JGitText.get().stashApplyConflict, e); } } else { throw new StashApplyFailureException( JGitText.get().stashApplyConflict); } } } else { throw new StashApplyFailureException( JGitText.get().stashApplyConflict); } return stashId;  } catch (JGitInternalException e) { throw e; } catch (IOException e) { throw new JGitInternalException(JGitText.get().stashApplyFailed, e); } }
[*] target: assertFalse(file.exists())
[-] pred: org. junit. Assert. assertFalse ( file. exists ( ) )
************************************
************************************
[+] input: shouldSortProcessorNodesCorrectly() { builder.addSource(null, "source1", null, null, null, "topic1"); builder.addSource(null, "source2", null, null, null, "topic2"); builder.addProcessor("processor1", new MockApiProcessorSupplier<>(), "source1"); builder.addProcessor("processor2", new MockApiProcessorSupplier<>(), "source1", "source2"); builder.addProcessor("processor3", new MockApiProcessorSupplier<>(), "processor2"); builder.addSink("sink1", "topic2", null, null, null, "processor1", "processor3");  assertEquals(1, builder.describe().subtopologies().size());  final Iterator<TopologyDescription.Node> iterator = ((SubtopologyDescription) builder.describe().subtopologies().iterator().next()).nodesInOrder();  "<AssertPlaceHolder>"; InternalTopologyBuilder.AbstractNode node = (InternalTopologyBuilder.AbstractNode) iterator.next(); assertEquals("source1", node.name); assertEquals(6, node.size);  assertTrue(iterator.hasNext()); node = (InternalTopologyBuilder.AbstractNode) iterator.next(); assertEquals("source2", node.name); assertEquals(4, node.size);  assertTrue(iterator.hasNext()); node = (InternalTopologyBuilder.AbstractNode) iterator.next(); assertEquals("processor2", node.name); assertEquals(3, node.size);  assertTrue(iterator.hasNext()); node = (InternalTopologyBuilder.AbstractNode) iterator.next(); assertEquals("processor1", node.name); assertEquals(2, node.size);  assertTrue(iterator.hasNext()); node = (InternalTopologyBuilder.AbstractNode) iterator.next(); assertEquals("processor3", node.name); assertEquals(2, node.size);  assertTrue(iterator.hasNext()); node = (InternalTopologyBuilder.AbstractNode) iterator.next(); assertEquals("sink1", node.name); assertEquals(1, node.size); }
nodesInOrder() { return nodes.iterator(); }
[*] target: assertTrue(iterator.hasNext())
[-] pred: org. junit. Assert. assertTrue ( iterator. hasNext ( ) )
************************************
************************************
[+] input: testRegisterOperatorProxyMethodFactory() { Crane4jTemplate.OpsForProxy ops = crane4jTemplate.opsForProxy(); AtomicBoolean processed = new AtomicBoolean(false); Assert.assertSame( ops, ops.registerOperatorProxyMethodFactory(new OperatorProxyMethodFactory() { @Override public int getSort() { return -1; } @Override public @Nullable MethodInvoker get( BeanOperations beanOperations, Method method, BeanOperationExecutor beanOperationExecutor) { processed.set(true); return null; } }) ); ops.createOperatorProxy(TestOperatorProxy.class); Assert."<AssertPlaceHolder>"; }
createOperatorProxy(@NonNull Class<T> operator) { return operatorProxyFactory.get(operator); }
[*] target: assertTrue(processed.get())
[-] pred: org. junit. Assert. assertTrue ( processed. get ( ) )
************************************
************************************
[+] input: test_wrong_client_id_length() {  final ChannelFuture cf = mock(ChannelFuture.class);  when(channel.writeAndFlush(any())).thenReturn(cf);  final ByteBuf buf = Unpooled.buffer();  buf.writeBytes(new byte[]{0, 4}); buf.writeBytes("MQTT".getBytes(UTF_8)); buf.writeByte(4); buf.writeByte(0b0000_0010); //keepAlive buf.writeShort(14); //payload length buf.writeShort(1000);  final CONNECT connectPacket = decoder.decode(clientConnection, buf, fixedHeader);  "<AssertPlaceHolder>"; assertFalse(channel.isActive()); }
decode( final @NotNull ClientConnection clientConnection, final @NotNull ByteBuf buf, final byte header) {   if (!validateHeader(header)) { disconnectByInvalidFixedHeader(clientConnection); return null; }  final ByteBuf connectHeader = decodeFixedVariableHeaderConnect(clientConnection, buf); if (connectHeader == null) { return null; }  if (!validateProtocolName(connectHeader, clientConnection, PROTOCOL_NAME)) { return null; }  //We don't need to validate the protocol version byte since we already know it's valid, otherwise //we wouldn't be in this protocol-version dependant decoder connectHeader.readByte();  final byte connectFlagsByte = connectHeader.readByte();  if (!validateConnectFlagByte(connectFlagsByte, clientConnection)) { return null; }  final boolean isCleanSessionFlag = isBitSet(connectFlagsByte, 1); final boolean isWillFlag = isBitSet(connectFlagsByte, 2); final boolean isWillRetain = isBitSet(connectFlagsByte, 5); final boolean isPasswordFlag = isBitSet(connectFlagsByte, 6); final boolean isUsernameFlag = isBitSet(connectFlagsByte, 7);  final int willQoS = (connectFlagsByte & 0b0001_1000) >> 3;  if (!validateWill(isWillFlag, isWillRetain, willQoS, clientConnection)) { return null; }  if (!validateUsernamePassword(isUsernameFlag, isPasswordFlag)) { mqttConnacker.connackError(clientConnection.getChannel(), "A client (IP: {}) connected with an invalid username/password combination. The password flag was set but the username flag was not set. Disconnecting client.", "Sent a CONNECT with invalid username/password combination", Mqtt5ConnAckReasonCode.PROTOCOL_ERROR, ReasonStrings.CONNACK_PROTOCOL_ERROR_INVALID_USER_PASS_COMB_MQTT3); return null; }  final int keepAlive = connectHeader.readUnsignedShort();  final int utf8StringLength;  if (buf.readableBytes() < 2 || (buf.readableBytes() < (utf8StringLength = buf.readUnsignedShort()) && utf8StringLength > 0)) { mqttConnacker.connackError(clientConnection.getChannel(), "A client (IP: {}) sent a CONNECT message with an incorrect client id length. Disconnecting client.", "Sent CONNECT with incorrect client id length", Mqtt5ConnAckReasonCode.MALFORMED_PACKET, ReasonStrings.CONNACK_CLIENT_IDENTIFIER_NOT_VALID); return null; }  final String clientId;  if (validateUTF8 && utf8StringLength > 0) { clientId = Strings.getValidatedPrefixedString(buf, utf8StringLength, true); if (clientId == null) { mqttConnacker.connackError(clientConnection.getChannel(), "The client id of the client (IP: {}) is not well formed. This is not allowed. Disconnecting client.", "Sent CONNECT with malformed client id", Mqtt5ConnAckReasonCode.MALFORMED_PACKET, ReasonStrings.CONNACK_CLIENT_IDENTIFIER_NOT_VALID); return null; } } else { if (utf8StringLength == 0) { if (!isCleanSessionFlag) { mqttConnacker.connackError(clientConnection.getChannel(), "A client (IP: {}) connected with a persistent session and NO clientID. Using an empty client ID is only allowed when using a cleanSession. Disconnecting client.", "Sent CONNECT with a persistent session and NO clientID", Mqtt5ConnAckReasonCode.CLIENT_IDENTIFIER_NOT_VALID, ReasonStrings.CONNACK_CLIENT_IDENTIFIER_NOT_VALID); return null; } if (!allowAssignedClientId) { mqttConnacker.connackError(clientConnection.getChannel(), "The client id of the client (IP: {}) is empty. This is not allowed. Disconnecting client.", "Sent CONNECT with empty client id", Mqtt5ConnAckReasonCode.CLIENT_IDENTIFIER_NOT_VALID, ReasonStrings.CONNACK_CLIENT_IDENTIFIER_NOT_VALID); return null; }  clientId = clientIds.generateNext(); clientConnection.setClientIdAssigned(true); } else { clientId = Strings.getPrefixedString(buf, utf8StringLength); } }  clientConnection.setClientId(clientId);  final MqttWillPublish willPublish;  if (isWillFlag) { willPublish = readMqtt3WillPublish(clientConnection, buf, willQoS, isWillRetain, hiveMQId); //channel already closed. if (willPublish == null) { return null; } } else { willPublish = null; }  final String userName;  if (isUsernameFlag) { userName = Strings.getPrefixedString(buf); if (userName == null) { mqttConnacker.connackError(clientConnection.getChannel(), "A client (IP: {}) sent a CONNECT with an incorrect username length. Disconnecting client.", "Sent a CONNECT with an incorrect username length", Mqtt5ConnAckReasonCode.MALFORMED_PACKET, ReasonStrings.CONNACK_MALFORMED_PACKET_USERNAME); return null; } clientConnection.setAuthUsername(userName); } else { userName = null; }  final byte[] password;  if (isPasswordFlag) { password = Bytes.getPrefixedBytes(buf); if (password == null) { mqttConnacker.connackError(clientConnection.getChannel(), "A client (IP: {}) sent a CONNECT with an incorrect password length. Disconnecting client.", "Sent a CONNECT with an incorrect password length", Mqtt5ConnAckReasonCode.MALFORMED_PACKET, ReasonStrings.CONNACK_MALFORMED_PACKET_PASSWORD); return null; } clientConnection.setAuthPassword(password); } else { password = null; }  clientConnection.setConnectKeepAlive(keepAlive); clientConnection.setCleanStart(isCleanSessionFlag);  final long sessionExpiryInterval = isCleanSessionFlag ? 0 : maxSessionExpiryInterval; clientConnection.setClientSessionExpiryInterval(sessionExpiryInterval);  return new CONNECT.Mqtt3Builder().withProtocolVersion(ProtocolVersion.MQTTv3_1_1) .withClientIdentifier(clientId) .withUsername(userName) .withPassword(password) .withCleanStart(isCleanSessionFlag) .withSessionExpiryInterval(sessionExpiryInterval) .withKeepAlive(keepAlive) .withWillPublish(willPublish).build(); }
[*] target: assertNull(connectPacket)
[-] pred: org. junit. Assert. assertNull ( connectPacket )
************************************
************************************
[+] input: hasPermission() { Permission permission = new Permission(); permission.setAction("rw"); permission.setResource(Resource.EMPTY_RESOURCE); NacosUser nacosUser = new NacosUser(); nacosUser.setUserName("nacos"); boolean res = nacosRoleService.hasPermission(nacosUser, permission); Assert.assertFalse(res);  Permission permission2 = new Permission(); permission2.setAction("rw"); Resource resource = new Resource("public", "group", AuthConstants.UPDATE_PASSWORD_ENTRY_POINT, "rw", null); permission2.setResource(resource); boolean res2 = nacosRoleService.hasPermission(nacosUser, permission2); Assert."<AssertPlaceHolder>"; }
hasPermission(NacosUser nacosUser, Permission permission) { //update password if (AuthConstants.UPDATE_PASSWORD_ENTRY_POINT.equals(permission.getResource().getName())) { return true; }  List<RoleInfo> roleInfoList = getRoles(nacosUser.getUserName()); if (CollectionUtils.isEmpty(roleInfoList)) { return false; }  // Global admin pass: for (RoleInfo roleInfo : roleInfoList) { if (AuthConstants.GLOBAL_ADMIN_ROLE.equals(roleInfo.getRole())) { nacosUser.setGlobalAdmin(true); return true; } }  // Old global admin can pass resource 'console/': if (permission.getResource().getName().startsWith(AuthConstants.CONSOLE_RESOURCE_NAME_PREFIX)) { return false; }  // For other roles, use a pattern match to decide if pass or not. for (RoleInfo roleInfo : roleInfoList) { List<PermissionInfo> permissionInfoList = getPermissions(roleInfo.getRole()); if (CollectionUtils.isEmpty(permissionInfoList)) { continue; } for (PermissionInfo permissionInfo : permissionInfoList) { String permissionResource = permissionInfo.getResource().replaceAll("\\*", ".*"); String permissionAction = permissionInfo.getAction(); if (permissionAction.contains(permission.getAction()) && Pattern.matches(permissionResource, joinResource(permission.getResource()))) { return true; } } } return false; }
[*] target: assertTrue(res2)
[-] pred: org. junit. Assert. assertTrue ( res2 )
************************************
************************************
[+] input: shouldCreateTaskStateDirectory() { final TaskId taskId = new TaskId(0, 0); final File taskDirectory = directory.getOrCreateDirectoryForTask(taskId); "<AssertPlaceHolder>"; assertTrue(taskDirectory.isDirectory()); }
getOrCreateDirectoryForTask(final TaskId taskId) { final File taskParentDir = getTaskDirectoryParentName(taskId); final File taskDir = new File(taskParentDir, StateManagerUtil.toTaskDirString(taskId)); if (hasPersistentStores) { if (!taskDir.exists()) { synchronized (taskDirCreationLock) { // to avoid a race condition, we need to check again if the directory does not exist: // otherwise, two threads might pass the outer `if` (and enter the `then` block), // one blocks on `synchronized` while the other creates the directory, // and the blocking one fails when trying to create it after it's unblocked if (!taskParentDir.exists() && !taskParentDir.mkdir()) { throw new ProcessorStateException( String.format("Parent [%s] of task directory [%s] doesn't exist and couldn't be created", taskParentDir.getPath(), taskDir.getPath())); } if (!taskDir.exists() && !taskDir.mkdir()) { throw new ProcessorStateException( String.format("task directory [%s] doesn't exist and couldn't be created", taskDir.getPath())); } } } else if (!taskDir.isDirectory()) { throw new ProcessorStateException( String.format("state directory [%s] can't be created as there is an existing file with the same name", taskDir.getPath())); } } return taskDir; }
[*] target: assertTrue(taskDirectory.exists())
[-] pred: org. junit. Assert. assertTrue ( taskDirectory. exists ( ) )
************************************
************************************
[+] input: shouldCleanupSegmentsThatHaveExpired() { final LogicalKeyValueSegment segment1 = segments.getOrCreateSegmentIfLive(0, context, 0); final LogicalKeyValueSegment segment2 = segments.getOrCreateSegmentIfLive(2, context, SEGMENT_INTERVAL * 2L); final LogicalKeyValueSegment segment3 = segments.getOrCreateSegmentIfLive(3, context, SEGMENT_INTERVAL * 3L); final LogicalKeyValueSegment segment4 = segments.getOrCreateSegmentIfLive(7, context, SEGMENT_INTERVAL * 7L);  segments.cleanupExpiredSegments(SEGMENT_INTERVAL * 7L);  final List<LogicalKeyValueSegment> allSegments = segments.allSegments(true); "<AssertPlaceHolder>"; assertEquals(segment3, allSegments.get(0)); assertEquals(segment4, allSegments.get(1)); }
cleanupExpiredSegments(final long streamTime) { super.cleanupExpiredSegments(streamTime); }
[*] target: assertEquals(2, allSegments.size())
[-] pred: org. junit. Assert. assertEquals ( 2, allSegments. size ( ) )
************************************
************************************
[+] input: Exception { CancelledTestMonitor m = new CancelledTestMonitor(); try (CancellableDigestOutputStream out = new CancellableDigestOutputStream( m, NullOutputStream.INSTANCE)) { byte[] KB = new byte[1024]; int triggerCancelWriteCnt = BYTES_TO_WRITE_BEFORE_CANCEL_CHECK / KB.length; for (int i = 0; i < triggerCancelWriteCnt + 1; i++) { out.write(KB); } assertTrue(out.length() > BYTES_TO_WRITE_BEFORE_CANCEL_CHECK); m.setCancelled(true);  for (int i = 0; i < triggerCancelWriteCnt - 1; i++) { out.write(KB); }  long lastLength = out.length(); assertThrows(InterruptedIOException.class, () -> { out.write(1); }); assertEquals(lastLength, out.length());  assertThrows(InterruptedIOException.class, () -> { out.write(new byte[1]); }); "<AssertPlaceHolder>"; } }
length() { return count; }
[*] target: assertEquals(lastLength, out.length())
[-] pred: org. junit. Assert. assertEquals ( lastLength, out. length() )
************************************
************************************
[+] input: Exception { File directory = createTempDirectory("testInitRepository"); InitCommand command = new InitCommand(); command.setDirectory(directory); command.setInitialBranch("main"); command.setInitialBranch(null); try (Git git = command.call()) { Repository r = git.getRepository(); "<AssertPlaceHolder>"; assertEquals("refs/heads/master", r.getFullBranch()); } }
call() throws GitAPIException { try { RepositoryBuilder builder = new RepositoryBuilder(); if (bare) builder.setBare(); if (fs != null) { builder.setFS(fs); } builder.readEnvironment(); if (gitDir != null) builder.setGitDir(gitDir); else gitDir = builder.getGitDir(); if (directory != null) { if (bare) builder.setGitDir(directory); else { builder.setWorkTree(directory); if (gitDir == null) builder.setGitDir(new File(directory, Constants.DOT_GIT)); } } else if (builder.getGitDir() == null) { String dStr = SystemReader.getInstance() .getProperty("user.dir"); //$NON-NLS-1$ if (dStr == null) dStr = "."; //$NON-NLS-1$ File d = new File(dStr); if (!bare) d = new File(d, Constants.DOT_GIT); builder.setGitDir(d); } else { // directory was not set but gitDir was set if (!bare) { String dStr = SystemReader.getInstance().getProperty( "user.dir"); //$NON-NLS-1$ if (dStr == null) dStr = "."; //$NON-NLS-1$ builder.setWorkTree(new File(dStr)); } } builder.setInitialBranch(StringUtils.isEmptyOrNull(initialBranch) ? SystemReader.getInstance().getUserConfig().getString( ConfigConstants.CONFIG_INIT_SECTION, null, ConfigConstants.CONFIG_KEY_DEFAULT_BRANCH) : initialBranch); Repository repository = builder.build(); if (!repository.getObjectDatabase().exists()) repository.create(bare); return new Git(repository, true); } catch (IOException | ConfigInvalidException e) { throw new JGitInternalException(e.getMessage(), e); } }
[*] target: assertNotNull(r)
[-] pred: org. junit. Assert. assertNotNull ( r )
************************************
************************************
[+] input: shouldRestore() { // should be empty initially assertFalse(windowStore.all().hasNext());  final StateSerdes<Integer, String> serdes = new StateSerdes<>("", Serdes.Integer(), Serdes.String());  final List<KeyValue<byte[], byte[]>> restorableEntries = new LinkedList<>();  restorableEntries .add(new KeyValue<>(toStoreKeyBinary(1, 0L, 0, serdes).get(), serdes.rawValue("one"))); restorableEntries.add(new KeyValue<>(toStoreKeyBinary(2, WINDOW_SIZE, 0, serdes).get(), serdes.rawValue("two"))); restorableEntries.add(new KeyValue<>(toStoreKeyBinary(3, 2 * WINDOW_SIZE, 0, serdes).get(), serdes.rawValue("three")));  context.restore(STORE_NAME, restorableEntries); try (final KeyValueIterator<Windowed<Integer>, String> iterator = windowStore .fetchAll(0L, 2 * WINDOW_SIZE)) {  assertEquals(windowedPair(1, "one", 0L), iterator.next()); assertEquals(windowedPair(2, "two", WINDOW_SIZE), iterator.next()); assertEquals(windowedPair(3, "three", 2 * WINDOW_SIZE), iterator.next()); "<AssertPlaceHolder>"; } }
hasNext() { if (next != null) { return true; } if (recordIterator == null || (!recordIterator.hasNext() && !segmentIterator.hasNext())) { return false; }  next = getNext(); if (next == null) { return false; }  if (allKeys || !retainDuplicates) { return true; }  final Bytes key = getKey(next.key); if (isKeyWithinRange(key)) { return true; } else { next = null; return hasNext(); } }
[*] target: assertFalse(iterator.hasNext())
[-] pred: org. junit. Assert. assertFalse ( iterator. hasNext() )
************************************
************************************
[+] input: Exception { writeTrashFile("file.txt", "content2"); git.add().addFilepattern("file.txt").call(); writeTrashFile("file.txt", "content3");  RevCommit stashed = Git.wrap(db).stashCreate().call(); "<AssertPlaceHolder>"; assertEquals("content", read(committedFile)); validateStashedCommit(stashed);  assertFalse(stashed.getTree().equals(stashed.getParent(1).getTree()));  List<DiffEntry> workingDiffs = diffWorkingAgainstHead(stashed); assertEquals(1, workingDiffs.size()); assertEquals(DiffEntry.ChangeType.MODIFY, workingDiffs.get(0) .getChangeType()); assertEquals("file.txt", workingDiffs.get(0).getNewPath());  List<DiffEntry> indexDiffs = diffIndexAgainstHead(stashed); assertEquals(1, indexDiffs.size()); assertEquals(DiffEntry.ChangeType.MODIFY, indexDiffs.get(0) .getChangeType()); assertEquals("file.txt", indexDiffs.get(0).getNewPath());  assertEquals(workingDiffs.get(0).getOldId(), indexDiffs.get(0) .getOldId()); assertFalse(workingDiffs.get(0).getNewId() .equals(indexDiffs.get(0).getNewId())); }
call() throws GitAPIException { checkCallable();  List<String> deletedFiles = new ArrayList<>(); Ref head = getHead(); try (ObjectReader reader = repo.newObjectReader()) { RevCommit headCommit = parseCommit(reader, head.getObjectId()); DirCache cache = repo.lockDirCache(); ObjectId commitId; try (ObjectInserter inserter = repo.newObjectInserter(); TreeWalk treeWalk = new TreeWalk(repo, reader)) {  treeWalk.setRecursive(true); treeWalk.addTree(headCommit.getTree()); treeWalk.addTree(new DirCacheIterator(cache)); treeWalk.addTree(new FileTreeIterator(repo)); treeWalk.getTree(2, FileTreeIterator.class) .setDirCacheIterator(treeWalk, 1); treeWalk.setFilter(AndTreeFilter.create(new SkipWorkTreeFilter( 1), new IndexDiffFilter(1, 2)));  // Return null if no local changes to stash if (!treeWalk.next()) return null;  MutableObjectId id = new MutableObjectId(); List<PathEdit> wtEdits = new ArrayList<>(); List<String> wtDeletes = new ArrayList<>(); List<DirCacheEntry> untracked = new ArrayList<>(); boolean hasChanges = false; do { AbstractTreeIterator headIter = treeWalk.getTree(0, AbstractTreeIterator.class); DirCacheIterator indexIter = treeWalk.getTree(1, DirCacheIterator.class); WorkingTreeIterator wtIter = treeWalk.getTree(2, WorkingTreeIterator.class); if (indexIter != null && !indexIter.getDirCacheEntry().isMerged()) throw new UnmergedPathsException( new UnmergedPathException( indexIter.getDirCacheEntry())); if (wtIter != null) { if (indexIter == null && headIter == null && !includeUntracked) continue; hasChanges = true; if (indexIter != null && wtIter.idEqual(indexIter)) continue; if (headIter != null && wtIter.idEqual(headIter)) continue; treeWalk.getObjectId(id, 0); final DirCacheEntry entry = new DirCacheEntry( treeWalk.getRawPath()); entry.setLength(wtIter.getEntryLength()); entry.setLastModified( wtIter.getEntryLastModifiedInstant()); entry.setFileMode(wtIter.getEntryFileMode()); long contentLength = wtIter.getEntryContentLength(); try (InputStream in = wtIter.openEntryStream()) { entry.setObjectId(inserter.insert( Constants.OBJ_BLOB, contentLength, in)); }  if (indexIter == null && headIter == null) untracked.add(entry); else wtEdits.add(new PathEdit(entry) { @Override public void apply(DirCacheEntry ent) { ent.copyMetaData(entry); } }); } hasChanges = true; if (wtIter == null && headIter != null) wtDeletes.add(treeWalk.getPathString()); } while (treeWalk.next());  if (!hasChanges) return null;  String branch = Repository.shortenRefName(head.getTarget() .getName());  // Commit index changes CommitBuilder builder = createBuilder(); builder.setParentId(headCommit); builder.setTreeId(cache.writeTree(inserter)); builder.setMessage(MessageFormat.format(indexMessage, branch, headCommit.abbreviate(OBJECT_ID_ABBREV_STRING_LENGTH) .name(), headCommit.getShortMessage())); ObjectId indexCommit = inserter.insert(builder);  // Commit untracked changes ObjectId untrackedCommit = null; if (!untracked.isEmpty()) { DirCache untrackedDirCache = DirCache.newInCore(); DirCacheBuilder untrackedBuilder = untrackedDirCache .builder(); for (DirCacheEntry entry : untracked) untrackedBuilder.add(entry); untrackedBuilder.finish();  builder.setParentIds(new ObjectId[0]); builder.setTreeId(untrackedDirCache.writeTree(inserter)); builder.setMessage(MessageFormat.format(MSG_UNTRACKED, branch, headCommit .abbreviate(OBJECT_ID_ABBREV_STRING_LENGTH) .name(), headCommit.getShortMessage())); untrackedCommit = inserter.insert(builder); }  // Commit working tree changes if (!wtEdits.isEmpty() || !wtDeletes.isEmpty()) { DirCacheEditor editor = cache.editor(); for (PathEdit edit : wtEdits) editor.add(edit); for (String path : wtDeletes) editor.add(new DeletePath(path)); editor.finish(); } builder.setParentId(headCommit); builder.addParentId(indexCommit); if (untrackedCommit != null) builder.addParentId(untrackedCommit); builder.setMessage(MessageFormat.format( workingDirectoryMessage, branch, headCommit.abbreviate(OBJECT_ID_ABBREV_STRING_LENGTH) .name(), headCommit.getShortMessage())); builder.setTreeId(cache.writeTree(inserter)); commitId = inserter.insert(builder); inserter.flush();  updateStashRef(commitId, builder.getAuthor(), builder.getMessage());  // Remove untracked files if (includeUntracked) { for (DirCacheEntry entry : untracked) { String repoRelativePath = entry.getPathString(); File file = new File(repo.getWorkTree(), repoRelativePath); FileUtils.delete(file); deletedFiles.add(repoRelativePath); } }  } finally { cache.unlock(); }  // Hard reset to HEAD new ResetCommand(repo).setMode(ResetType.HARD).call();  // Return stashed commit return parseCommit(reader, commitId); } catch (IOException e) { throw new JGitInternalException(JGitText.get().stashFailed, e); } finally { if (!deletedFiles.isEmpty()) { repo.fireEvent( new WorkingTreeModifiedEvent(null, deletedFiles)); } } }
[*] target: assertNotNull(stashed)
[-] pred: org. junit. Assert. assertNotNull ( stashed )
************************************
************************************
[+] input: InterruptedException { redisson.getKeys().flushall(); String lockId = "abcd-1234"; boolean isLocked = redisLock.acquireLock(lockId, 1000, 1000, TimeUnit.MILLISECONDS); "<AssertPlaceHolder>";  Thread.sleep(2000);  RLock lock = redisson.getLock(lockId); assertFalse(lock.isLocked()); }
acquireLock(String lockId, long timeToTry, long leaseTime, TimeUnit unit) { RLock lock = redisson.getLock(parseLockId(lockId)); try { return lock.tryLock(timeToTry, leaseTime, unit); } catch (Exception e) { return handleAcquireLockFailure(lockId, e); } }
[*] target: assertTrue(isLocked)
[-] pred: org. junit. Assert. assertTrue ( isLocked )
************************************
************************************
[+] input: IOException { setObjectSizeIndexMinBytes(100); insertBlobWithSize(200); insertBlobWithSize(230); insertBlobWithSize(100); try (DfsReader ctx = db.getObjectDatabase().newReader()) { CounterPackLoadListener listener = new CounterPackLoadListener(); ctx.addPackLoadListener(listener); ObjectId oid = ObjectId .fromString("aa48de2aa61d9dffa8a05439dc115fe82f10f129"); boolean has = ctx.has(oid); "<AssertPlaceHolder>"; // Open 3 indices trying to find the pack assertEquals(Integer.valueOf(3), listener.callsPerExt.get(PackExt.INDEX)); } }
has(AnyObjectId objectId) throws IOException { if (last != null && !skipGarbagePack(last) && last.hasObject(this, objectId)) return true; PackList packList = db.getPackList(); if (hasImpl(packList, objectId)) { return true; } else if (packList.dirty()) { stats.scanPacks++; return hasImpl(db.scanPacks(packList), objectId); } return false; }
[*] target: assertFalse(has)
[-] pred: org. junit. Assert. assertFalse ( has )
************************************
************************************
[+] input: testEmptyValueNoLF() { String msg = buildMessage("subject\n\nbody of commit\n" + "\n" + "Signed-off-by:"); List<FooterLine> footers = FooterLine.fromMessage(msg); FooterLine f;  assertNotNull(footers); assertEquals(1, footers.size());  f = footers.get(0); assertEquals("Signed-off-by", f.getKey()); assertEquals("", f.getValue()); "<AssertPlaceHolder>"; }
getEmailAddress() { final int lt = RawParseUtils.nextLF(buffer, valStart, '<'); if (valEnd <= lt) { final int at = RawParseUtils.nextLF(buffer, valStart, '@'); if (valStart < at && at < valEnd) return getValue(); return null; } final int gt = RawParseUtils.nextLF(buffer, lt, '>'); if (valEnd < gt) return null; return RawParseUtils.decode(enc, buffer, lt, gt - 1); }
[*] target: assertNull(f.getEmailAddress())
[-] pred: org. junit. Assert. assertNull ( f. getEmailAddress() )
************************************
************************************
[+] input: testUnknownAlgorithmNameEnc() { String dataId = "cipher-mySM4-application"; String content = "content"; Pair<String, String> pair = EncryptionHandler.encryptHandler(dataId, content); Assert."<AssertPlaceHolder>"; Assert.assertEquals("should return original content if algorithm is not defined.", content, pair.getSecond()); }
encryptHandler(String dataId, String content) { if (!checkCipher(dataId)) { return Pair.with("", content); } Optional<String> algorithmName = parseAlgorithmName(dataId); Optional<EncryptionPluginService> optional = algorithmName.flatMap( EncryptionPluginManager.instance()::findEncryptionService); if (!optional.isPresent()) { LOGGER.warn("[EncryptionHandler] [encryptHandler] No encryption program with the corresponding name found"); return Pair.with("", content); } EncryptionPluginService encryptionPluginService = optional.get(); String secretKey = encryptionPluginService.generateSecretKey(); String encryptContent = encryptionPluginService.encrypt(secretKey, content); return Pair.with(encryptionPluginService.encryptSecretKey(secretKey), encryptContent); }
[*] target: assertNotNull(pair)
[-] pred: org. junit. Assert. assertNotNull ( pair )
************************************
************************************
[+] input: testDoRegister() { distroClientComponentRegistry.doRegister();  DistroDataStorage dataStorage = componentHolder.findDataStorage(DistroClientDataProcessor.TYPE); Assert."<AssertPlaceHolder>";  DistroDataProcessor dataProcessor = componentHolder.findDataProcessor(DistroClientDataProcessor.TYPE); Assert.assertNotNull(dataProcessor);  DistroFailedTaskHandler failedTaskHandler = componentHolder .findFailedTaskHandler(DistroClientDataProcessor.TYPE); Assert.assertNotNull(failedTaskHandler);  DistroTransportAgent transportAgent = componentHolder.findTransportAgent(DistroClientDataProcessor.TYPE); Assert.assertNotNull(transportAgent);  }
doRegister() { DistroClientDataProcessor dataProcessor = new DistroClientDataProcessor(clientManager, distroProtocol); DistroTransportAgent transportAgent = new DistroClientTransportAgent(clusterRpcClientProxy, serverMemberManager); DistroClientTaskFailedHandler taskFailedHandler = new DistroClientTaskFailedHandler(taskEngineHolder); componentHolder.registerDataStorage(DistroClientDataProcessor.TYPE, dataProcessor); componentHolder.registerDataProcessor(dataProcessor); componentHolder.registerTransportAgent(DistroClientDataProcessor.TYPE, transportAgent); componentHolder.registerFailedTaskHandler(DistroClientDataProcessor.TYPE, taskFailedHandler); }
[*] target: assertNotNull(dataStorage)
[-] pred: org. junit. Assert. assertNotNull ( dataStorage )
************************************
************************************
[+] input: testParseGitFileName_Empty() { final FileHeader fh = data(""); assertEquals(-1, fh.parseGitFileName(0, fh.buf.length)); assertNotNull(fh.getHunks()); assertTrue(fh.getHunks().isEmpty()); "<AssertPlaceHolder>"; }
hasMetaDataChanges() { return changeType != ChangeType.MODIFY || newMode != oldMode; }
[*] target: assertFalse(fh.hasMetaDataChanges())
[-] pred: org. junit. Assert. assertFalse ( fh. hasMetaDataChanges() )
************************************
************************************
[+] input: Exception { ConfigInfoWrapper configInfoWrapper1 = createNewConfig(1); ConfigInfoWrapper configInfoWrapper2 = createNewConfig(2); long timestamp = System.currentTimeMillis(); configInfoWrapper1.setLastModified(timestamp); configInfoWrapper2.setLastModified(timestamp); Page<ConfigInfoWrapper> page = new Page<>(); page.setTotalCount(2); page.setPagesAvailable(2); page.setPageNumber(1); List<ConfigInfoWrapper> list = Arrays.asList(configInfoWrapper1, configInfoWrapper2); page.setPageItems(list);  Mockito.when(configInfoPersistService.findConfigMaxId()).thenReturn(2L); Mockito.when(configInfoPersistService.findAllConfigInfoFragment(0, PropertyUtil.getAllDumpPageSize(), true)) .thenReturn(page);  // For config 1, assign a latter time, to make sure that it would be updated. // For config 2, assign an earlier time, to make sure that it is not be updated. String md51 = MD5Utils.md5Hex(configInfoWrapper1.getContent(), "UTF-8"); String md52 = MD5Utils.md5Hex(configInfoWrapper2.getContent(), "UTF-8"); long latterTimestamp = timestamp + 999; long earlierTimestamp = timestamp - 999; String encryptedDataKey = "testEncryptedDataKey"; ConfigCacheService.dumpWithMd5(configInfoWrapper1.getDataId(), configInfoWrapper1.getGroup(), configInfoWrapper1.getTenant(), configInfoWrapper1.getContent(), md51, latterTimestamp, "json", encryptedDataKey); ConfigCacheService.dumpWithMd5(configInfoWrapper2.getDataId(), configInfoWrapper2.getGroup(), configInfoWrapper2.getTenant(), configInfoWrapper2.getContent(), md52, earlierTimestamp, "json", encryptedDataKey);  DumpAllTask dumpAllTask = new DumpAllTask(true);  boolean process = dumpAllProcessor.process(dumpAllTask); Assert."<AssertPlaceHolder>";  //Check cache CacheItem contentCache1 = ConfigCacheService.getContentCache( GroupKey2.getKey(configInfoWrapper1.getDataId(), configInfoWrapper1.getGroup(), configInfoWrapper1.getTenant())); Assert.assertEquals(md51, contentCache1.getConfigCache().getMd5Utf8()); // check if config1 is updated Assert.assertTrue(timestamp < contentCache1.getConfigCache().getLastModifiedTs()); //check disk String contentFromDisk1 = ConfigDiskServiceFactory.getInstance() .getContent(configInfoWrapper1.getDataId(), configInfoWrapper1.getGroup(), configInfoWrapper1.getTenant()); Assert.assertEquals(configInfoWrapper1.getContent(), contentFromDisk1);  //Check cache CacheItem contentCache2 = ConfigCacheService.getContentCache( GroupKey2.getKey(configInfoWrapper2.getDataId(), configInfoWrapper2.getGroup(), configInfoWrapper2.getTenant())); Assert.assertEquals(MD5Utils.md5Hex(configInfoWrapper2.getContent(), "UTF-8"), contentCache2.getConfigCache().getMd5Utf8()); // check if config2 is updated Assert.assertEquals(timestamp, contentCache2.getConfigCache().getLastModifiedTs()); //check disk String contentFromDisk2 = ConfigDiskServiceFactory.getInstance() .getContent(configInfoWrapper2.getDataId(), configInfoWrapper2.getGroup(), configInfoWrapper2.getTenant()); Assert.assertEquals(configInfoWrapper2.getContent(), contentFromDisk2); }
process(NacosTask task) { if (!(task instanceof DumpAllTask)) { DEFAULT_LOG.error("[all-dump-error] ,invalid task type,DumpAllProcessor should process DumpAllTask type."); return false; } DumpAllTask dumpAllTask = (DumpAllTask) task;  long currentMaxId = configInfoPersistService.findConfigMaxId(); long lastMaxId = 0; ThreadPoolExecutor executorService = null; if (dumpAllTask.isStartUp()) { executorService = new ThreadPoolExecutor(Runtime.getRuntime().availableProcessors(), Runtime.getRuntime().availableProcessors(), 60L, TimeUnit.SECONDS, new LinkedBlockingQueue<>(PropertyUtil.getAllDumpPageSize() * 2), r -> new Thread(r, "dump all executor"), new ThreadPoolExecutor.CallerRunsPolicy()); } else { executorService = new ThreadPoolExecutor(1, 1, 60L, TimeUnit.SECONDS, new SynchronousQueue<>(), r -> new Thread(r, "dump all executor"), new ThreadPoolExecutor.CallerRunsPolicy()); }  DEFAULT_LOG.info("start dump all config-info...");  while (lastMaxId < currentMaxId) {  long start = System.currentTimeMillis();  Page<ConfigInfoWrapper> page = configInfoPersistService.findAllConfigInfoFragment(lastMaxId, PropertyUtil.getAllDumpPageSize(), dumpAllTask.isStartUp()); long dbTimeStamp = System.currentTimeMillis(); if (page == null || page.getPageItems() == null || page.getPageItems().isEmpty()) { break; }  for (ConfigInfoWrapper cf : page.getPageItems()) { lastMaxId = Math.max(cf.getId(), lastMaxId); //if not start up, page query will not return content, check md5 and lastModified first ,if changed ,get single content info to dump. if (!dumpAllTask.isStartUp()) { final String groupKey = GroupKey2.getKey(cf.getDataId(), cf.getGroup(), cf.getTenant()); boolean newLastModified = cf.getLastModified() > ConfigCacheService.getLastModifiedTs(groupKey); //check md5 & update local disk cache. String localContentMd5 = ConfigCacheService.getContentMd5(groupKey); boolean md5Update = !localContentMd5.equals(cf.getMd5()); if (newLastModified || md5Update) { LogUtil.DUMP_LOG.info("[dump-all] find change config {}, {}, md5={}", groupKey, cf.getLastModified(), cf.getMd5()); cf = configInfoPersistService.findConfigInfo(cf.getDataId(), cf.getGroup(), cf.getTenant()); } else { continue; } }  if (cf == null) { continue; } if (cf.getDataId().equals(AggrWhitelist.AGGRIDS_METADATA)) { AggrWhitelist.load(cf.getContent()); }  if (cf.getDataId().equals(ClientIpWhiteList.CLIENT_IP_WHITELIST_METADATA)) { ClientIpWhiteList.load(cf.getContent()); }  if (cf.getDataId().equals(SwitchService.SWITCH_META_DATA_ID)) { SwitchService.load(cf.getContent()); }  final String content = cf.getContent(); final String dataId = cf.getDataId(); final String group = cf.getGroup(); final String tenant = cf.getTenant(); final long lastModified = cf.getLastModified(); final String type = cf.getType(); final String encryptedDataKey = cf.getEncryptedDataKey();  executorService.execute(() -> { final String md5Utf8 = MD5Utils.md5Hex(content, ENCODE_UTF8); boolean result = ConfigCacheService.dumpWithMd5(dataId, group, tenant, content, md5Utf8, lastModified, type, encryptedDataKey); if (result) { LogUtil.DUMP_LOG.info("[dump-all-ok] {}, {}, length={},md5UTF8={}", GroupKey2.getKey(dataId, group), lastModified, content.length(), md5Utf8); } else { LogUtil.DUMP_LOG.info("[dump-all-error] {}", GroupKey2.getKey(dataId, group)); }  });  }  long diskStamp = System.currentTimeMillis(); DEFAULT_LOG.info("[all-dump] submit all task for {} / {}, dbTime={},diskTime={}", lastMaxId, currentMaxId, (dbTimeStamp - start), (diskStamp - dbTimeStamp)); }  //wait all task are finished and then shutdown executor. try { int unfinishedTaskCount = 0; while ((unfinishedTaskCount = executorService.getQueue().size() + executorService.getActiveCount()) > 0) { DEFAULT_LOG.info("[all-dump] wait {} dump tasks to be finished", unfinishedTaskCount); Thread.sleep(1000L); } executorService.shutdown();  } catch (Exception e) { DEFAULT_LOG.error("[all-dump] wait  dump tasks to be finished error", e); } DEFAULT_LOG.info("success to  dump all config-info。"); return true; }
[*] target: assertTrue(process)
[-] pred: org. junit. Assert. assertTrue ( process )
************************************
************************************
[+] input: listTableConstraint_TestForeignKey_Success() { List<DBTableConstraint> constraintListList = accessor.listTableConstraints(getOracleSchema(), "TEST_FK_CHILD"); Assert."<AssertPlaceHolder>"; Assert.assertEquals(DBConstraintType.FOREIGN_KEY, constraintListList.get(0).getType()); Assert.assertEquals("TEST_FK_PARENT", constraintListList.get(0).getReferenceTableName()); Assert.assertEquals("TEST_FK_CHILD", constraintListList.get(0).getTableName()); Assert.assertEquals(getOracleSchema(), constraintListList.get(0).getSchemaName()); }
listTableConstraints(String schemaName, String tableName) { String sql = this.sqlMapper.getSql(Statements.LIST_TABLE_CONSTRAINTS); Map<String, DBTableConstraint> name2Constraint = new LinkedHashMap<>(); jdbcOperations.query(sql, new Object[] {schemaName, tableName}, (rs, num) -> { String constraintName = rs.getString(OracleConstants.CONS_NAME); if (!name2Constraint.containsKey(constraintName)) { int currentPosition = name2Constraint.size(); name2Constraint.put(constraintName, createConstraintByResultSet(rs, currentPosition + 1)); } else { name2Constraint.get(constraintName).getColumnNames() .add(rs.getString("COLUMN_NAME")); name2Constraint.get(constraintName).getReferenceColumnNames() .add(rs.getString(OracleConstants.CONS_R_COLUMN_NAME)); } return constraintName; });  filterConstraintColumns(new ArrayList<>(name2Constraint.values())); return new ArrayList<>(name2Constraint.values()); }
[*] target: assertEquals(1, constraintListList.size())
[-] pred: org. junit. Assert. assertEquals ( 1, constraintListList. size ( ) )
************************************
************************************
[+] input: getAllAnnotations() { Set<Annotation> annotations = finder.getAllAnnotations(Foo.class, Annotation.class); Assert."<AssertPlaceHolder>"; Assert.assertEquals(3, annotations.size()); }
getAllAnnotations(@NonNull AnnotatedElement element, Class<A> annotationType) { return Stream.of(element.getDeclaredAnnotationsByType(annotationType)) .collect(Collectors.toSet()); }
[*] target: assertNotNull(annotations)
[-] pred: org. junit. Assert. assertNotNull ( annotations )
************************************
************************************
[+] input: shouldNotCommitBatchRepeatedly() { context.commitTransaction(); assertTrue(context.shouldCommitBatch()); "<AssertPlaceHolder>"; }
shouldCommitBatch() { checkBatchRequestsConsistency(); boolean result = batchCommitRequested; batchCommitRequested = false; return result; }
[*] target: assertFalse(context.shouldCommitBatch())
[-] pred: org. junit. Assert. assertFalse ( context. shouldCommitBatch ( ) )
************************************
************************************
[+] input: createOKHttpClient() { OkHttpClient okHttpClient = WebUtils.okHttpClientWithTimeout(Duration.ofMinutes(10)); Assert."<AssertPlaceHolder>"; int timeout = okHttpClient.callTimeoutMillis(); Assert.assertEquals(10 * 60 * 1000, timeout); }
okHttpClientWithTimeout(Duration timeout) { log.info("Creating OkHttpClient with timeout {}", timeout); OkHttpClient client = new OkHttpClient.Builder() .callTimeout(timeout) .readTimeout(timeout) .connectTimeout(timeout) .build(); log.info("OkHttpClient created"); return client; }
[*] target: assertNotNull(okHttpClient)
[-] pred: org. junit. Assert. assertNotNull ( okHttpClient )
************************************
************************************
[+] input: testTaskOps() { List<TaskModel> tasks = new LinkedList<>(); String workflowId = UUID.randomUUID().toString();  for (int i = 0; i < 3; i++) { TaskModel task = new TaskModel(); task.setScheduledTime(1L); task.setSeq(1); task.setTaskId(workflowId + "_t" + i); task.setReferenceTaskName("testTaskOps" + i); task.setRetryCount(0); task.setWorkflowInstanceId(workflowId); task.setTaskDefName("testTaskOps" + i); task.setStatus(TaskModel.Status.IN_PROGRESS); tasks.add(task); }  for (int i = 0; i < 3; i++) { TaskModel task = new TaskModel(); task.setScheduledTime(1L); task.setSeq(1); task.setTaskId("x" + workflowId + "_t" + i); task.setReferenceTaskName("testTaskOps" + i); task.setRetryCount(0); task.setWorkflowInstanceId("x" + workflowId); task.setTaskDefName("testTaskOps" + i); task.setStatus(TaskModel.Status.IN_PROGRESS); getExecutionDAO().createTasks(Collections.singletonList(task)); }  List<TaskModel> created = getExecutionDAO().createTasks(tasks); assertEquals(tasks.size(), created.size());  List<TaskModel> pending = getExecutionDAO().getPendingTasksForTaskType(tasks.get(0).getTaskDefName()); assertNotNull(pending); assertEquals(2, pending.size()); // Pending list can come in any order.  finding the one we are looking for and then // comparing TaskModel matching = pending.stream() .filter(task -> task.getTaskId().equals(tasks.get(0).getTaskId())) .findAny() .get(); assertTrue(EqualsBuilder.reflectionEquals(matching, tasks.get(0)));  for (int i = 0; i < 3; i++) { TaskModel found = getExecutionDAO().getTask(workflowId + "_t" + i); assertNotNull(found); found.addOutput("updated", true); found.setStatus(TaskModel.Status.COMPLETED); getExecutionDAO().updateTask(found); }  List<String> taskIds = tasks.stream().map(TaskModel::getTaskId).collect(Collectors.toList()); List<TaskModel> found = getExecutionDAO().getTasks(taskIds); assertEquals(taskIds.size(), found.size()); found.forEach( task -> { assertTrue(task.getOutputData().containsKey("updated")); assertEquals(true, task.getOutputData().get("updated")); boolean removed = getExecutionDAO().removeTask(task.getTaskId()); assertTrue(removed); });  found = getExecutionDAO().getTasks(taskIds); "<AssertPlaceHolder>"; }
getTasks(List<String> taskIds);
[*] target: assertTrue(found.isEmpty())
[-] pred: org. junit. Assert. assertTrue ( found. isEmpty ( ) )
************************************
************************************
[+] input: testChangesInfo() { ApiCollection apiCollection1 = new ApiCollection(0, "coll1", Context.now(), new HashSet<>(), "akto.io", 1, false, true); ApiCollection apiCollection2 = new ApiCollection(1, "coll2", Context.now(), new HashSet<>(), "app.akto.io", 2, false, true); ApiCollection apiCollection3 = new ApiCollection(2, "coll3", Context.now(), new HashSet<>(), null, 3, false, true); ApiCollectionsDao.instance.insertMany(Arrays.asList(apiCollection1, apiCollection2, apiCollection3));  SingleTypeInfo sti1 = generateSti("/api/books", 0, false); SingleTypeInfo sti1h = generateSti("/api/books", 0,true); SingleTypeInfo sti2 = generateSti("api/books/INTEGER", 0, false); SingleTypeInfo sti2h = generateSti("api/books/INTEGER", 0, true); SingleTypeInfo sti3 = generateSti("/api/cars", 1, false); SingleTypeInfo sti3h = generateSti("/api/cars", 1, true); SingleTypeInfo sti4 = generateSti("/api/toys", 2, false); SingleTypeInfo sti5 = generateSti("/api/bus",2, false);  SingleTypeInfoDao.instance.insertMany(Arrays.asList(sti1, sti2, sti3, sti4, sti5, sti1h, sti2h, sti3h));  InitializerListener.ChangesInfo changesInfo = InitializerListener.getChangesInfo(Context.now(), Context.now(), null, null, false); "<AssertPlaceHolder>"; List<String> newEndpointsLast7Days = changesInfo.newEndpointsLast7Days; Map<String, String> newSensitiveParams = changesInfo.newSensitiveParams;  assertEquals(5,newEndpointsLast7Days.size());  assertTrue(newEndpointsLast7Days.contains("GET akto.io/api/books")); assertTrue(newEndpointsLast7Days.contains("GET akto.io/api/books/INTEGER")); assertTrue(newEndpointsLast7Days.contains("GET app.akto.io/api/cars")); assertTrue(newEndpointsLast7Days.contains("GET /api/toys")); assertTrue(newEndpointsLast7Days.contains("GET /api/bus"));  assertTrue(newSensitiveParams.containsKey("GET akto.io/api/books: EMAIL")); assertTrue(newSensitiveParams.containsKey("GET akto.io/api/books/INTEGER: EMAIL")); assertTrue(newSensitiveParams.containsKey("GET app.akto.io/api/cars: EMAIL")); assertTrue(newSensitiveParams.containsKey("GET /api/toys: EMAIL")); assertTrue(newSensitiveParams.containsKey("GET /api/bus: EMAIL")); }
getChangesInfo(int newEndpointsFrequency, int newSensitiveParamsFrequency, List<String> newEndpointCollections, List<String> newSensitiveEndpointCollections, boolean includeCollectionIds) { ChangesInfo ret = new ChangesInfo(); try { int now = Context.now(); List<BasicDBObject> newEndpointsSmallerDuration = new InventoryAction().fetchRecentEndpoints(now - newSensitiveParamsFrequency, now); List<BasicDBObject> newEndpointsBiggerDuration = new InventoryAction().fetchRecentEndpoints(now - newEndpointsFrequency, now);  Map<Integer, ApiCollection> apiCollectionMap = ApiCollectionsDao.instance.generateApiCollectionMap();  int newParamInNewEndpoint = 0;  for (BasicDBObject singleTypeInfo : newEndpointsSmallerDuration) { newParamInNewEndpoint += (int) singleTypeInfo.getOrDefault("countTs", 0); singleTypeInfo = (BasicDBObject) (singleTypeInfo.getOrDefault("_id", new BasicDBObject())); UrlResult urlResult = extractUrlFromBasicDbObject(singleTypeInfo, apiCollectionMap, newEndpointCollections, includeCollectionIds); if (urlResult == null) { continue; } ret.newEndpointsLast7Days.add(urlResult.urlString); ret.newEndpointsLast7DaysObject.add(urlResult.urlObject); }  for (BasicDBObject singleTypeInfo : newEndpointsBiggerDuration) { singleTypeInfo = (BasicDBObject) (singleTypeInfo.getOrDefault("_id", new BasicDBObject())); UrlResult urlResult = extractUrlFromBasicDbObject(singleTypeInfo, apiCollectionMap, null, includeCollectionIds); if (urlResult == null) { continue; } ret.newEndpointsLast31Days.add(urlResult.urlString); ret.newEndpointsLast31DaysObject.add(urlResult.urlObject); }  List<SingleTypeInfo> sensitiveParamsList = new InventoryAction().fetchSensitiveParams(); ret.totalSensitiveParams = sensitiveParamsList.size(); ret.recentSentiiveParams = 0; int delta = newSensitiveParamsFrequency; Map<Pair<String, String>, Set<String>> endpointToSubTypes = new HashMap<>(); Map<Pair<String, String>, ApiCollection> endpointToApiCollection = new HashMap<>(); for (SingleTypeInfo sti : sensitiveParamsList) { ApiCollection apiCollection = apiCollectionMap.get(sti.getApiCollectionId()); String url = sti.getUrl(); boolean skipAddingIntoMap = false; if (apiCollection != null && apiCollection.getHostName() != null) { String hostName = apiCollection.getHostName(); url = url.startsWith("/") ? hostName + url : hostName + "/" + url; }  if (newSensitiveEndpointCollections != null) {//case of filtering by collection for sensitive endpoints skipAddingIntoMap = true; if (apiCollection != null) { skipAddingIntoMap = !newSensitiveEndpointCollections.contains(apiCollection.getDisplayName()); } } if (skipAddingIntoMap) { continue; }  String encoded = Base64.getEncoder().encodeToString((sti.getUrl() + " " + sti.getMethod()).getBytes()); String link = "/dashboard/observe/inventory/" + sti.getApiCollectionId() + "/" + encoded; Pair<String, String> key = new Pair<>(sti.getMethod() + " " + url, link); String value = sti.getSubType().getName(); if (sti.getTimestamp() >= now - delta) { ret.recentSentiiveParams++; Set<String> subTypes = endpointToSubTypes.get(key); if (subTypes == null) { subTypes = new HashSet<>(); endpointToSubTypes.put(key, subTypes); } endpointToApiCollection.put(key, apiCollection); subTypes.add(value); } }  for (Pair<String, String> key : endpointToSubTypes.keySet()) { String subTypes = StringUtils.join(endpointToSubTypes.get(key), ","); String methodPlusUrl = key.getFirst(); ret.newSensitiveParams.put(methodPlusUrl + ": " + subTypes, key.getSecond());  BasicDBObject basicDBObject = new BasicDBObject(); String[] methodPlusUrlList = methodPlusUrl.split(" "); if (methodPlusUrlList.length != 2) continue; basicDBObject.put("url", methodPlusUrlList[1]); basicDBObject.put("method", methodPlusUrlList[0]); basicDBObject.put("subTypes", subTypes); basicDBObject.put("link", key.getSecond()); ApiCollection collection = endpointToApiCollection.get(key); basicDBObject.put(SingleTypeInfo._API_COLLECTION_ID, collection != null ? collection.getId() : null); basicDBObject.put(SingleTypeInfo.COLLECTION_NAME, collection != null ? collection.getDisplayName() : null); ret.newSensitiveParamsObject.add(basicDBObject); }  List<SingleTypeInfo> allNewParameters = new InventoryAction().fetchAllNewParams(now - newEndpointsFrequency, now); int totalNewParameters = allNewParameters.size(); ret.newParamsInExistingEndpoints = Math.max(0, totalNewParameters - newParamInNewEndpoint); return ret; } catch (Exception e) { loggerMaker.errorAndAddToDb(e, String.format("get new endpoints %s", e.toString()), LogDb.DASHBOARD); } return ret; }
[*] target: assertNotNull(changesInfo)
[-] pred: org. junit. Assert. assertNotNull ( changesInfo )
************************************
************************************
[+] input: shouldReturnTimestampedKeyValueStore() { final GlobalStateStoreProvider provider = new GlobalStateStoreProvider(stores); final List<ReadOnlyKeyValueStore<String, ValueAndTimestamp<String>>> stores = provider.stores("ts-kv-store", QueryableStoreTypes.timestampedKeyValueStore()); "<AssertPlaceHolder>"; for (final ReadOnlyKeyValueStore<String, ValueAndTimestamp<String>> store : stores) { assertThat(store, instanceOf(ReadOnlyKeyValueStore.class)); assertThat(store, instanceOf(TimestampedKeyValueStore.class)); } }
stores(final String storeName, final QueryableStoreType<T> queryableStoreType) { final StateStore store = globalStateStores.get(storeName); if (store == null || !queryableStoreType.accepts(store)) { return Collections.emptyList(); } if (!store.isOpen()) { throw new InvalidStateStoreException("the state store, " + storeName + ", is not open."); } if (store instanceof TimestampedKeyValueStore && queryableStoreType instanceof QueryableStoreTypes.KeyValueStoreType) { return (List<T>) Collections.singletonList(new ReadOnlyKeyValueStoreFacade((TimestampedKeyValueStore<Object, Object>) store)); } else if (store instanceof TimestampedWindowStore && queryableStoreType instanceof QueryableStoreTypes.WindowStoreType) { return (List<T>) Collections.singletonList(new ReadOnlyWindowStoreFacade((TimestampedWindowStore<Object, Object>) store)); } return (List<T>) Collections.singletonList(store); }
[*] target: assertEquals(1, stores.size())
[-] pred: org. junit. Assert. assertEquals ( 1, stores. size ( ) )
************************************
************************************
[+] input: IOException { String line = getSqlFromFile("sql/split/comment-processor-oracle-test.sql"); SqlCommentProcessor processor = new SqlCommentProcessor(DialectType.OB_ORACLE, false, false, false); StringBuffer builder = new StringBuffer(); List<OffsetString> actual = processor.split(builder, line); List<OffsetString> expected = getSqls("sql/split/comment-processor-oracle-verify.yml"); Assert."<AssertPlaceHolder>"; for (int i = 0; i < expected.size(); i++) { Assert.assertEquals(expected.get(i), actual.get(i)); } }
split(StringBuffer buffer, String sqlScript) { if (StringUtils.isBlank(sqlScript)) { return new ArrayList<>(); } try { List<OffsetString> offsetStrings = new ArrayList<>();  List<List<OrderChar>> lines = splitLine(sqlScript); Holder<Integer> bufferOrder = new Holder<>(0); for (List<OrderChar> item : lines) { if (Objects.nonNull(this.dialectType) && this.dialectType.isMysql()) { addLineMysql(offsetStrings, buffer, bufferOrder, item); } else if (Objects.nonNull(this.dialectType) && this.dialectType.isOracle()) { addLineOracle(offsetStrings, buffer, bufferOrder, item); } else if (Objects.nonNull(this.dialectType) && this.dialectType.isDoris()) { addLineMysql(offsetStrings, buffer, bufferOrder, item); } else { throw new IllegalArgumentException("dialect type is illegal"); } } return offsetStrings; } finally { mlComment = false; inString = '\0'; inNormalSql = false; } }
[*] target: assertEquals(expected.size(), actual.size())
[-] pred: org. junit. Assert. assertEquals ( expected. size ( ), actual. size ( ) )
************************************
************************************
[+] input: setReasonString() { final PubrelPacketImpl packet = new PubrelPacketImpl( 1, PubrelReasonCode.SUCCESS, null, UserPropertiesImpl.of(ImmutableList.of())); final ModifiablePubrelPacketImpl modifiablePacket = new ModifiablePubrelPacketImpl(packet, configurationService);  assertFalse(modifiablePacket.isModified());  modifiablePacket.setReasonString("reason");  assertEquals(Optional.of("reason"), modifiablePacket.getReasonString()); "<AssertPlaceHolder>"; }
isModified() { return modified || userProperties.isModified(); }
[*] target: assertTrue(modifiablePacket.isModified())
[-] pred: org. junit. Assert. assertTrue ( modifiablePacket. isModified() )
************************************
************************************
[+] input: test_wrong_client_id_length() {  final ChannelFuture cf = mock(ChannelFuture.class);  when(channel.writeAndFlush(any())).thenReturn(cf);  final ByteBuf buf = Unpooled.buffer();  buf.writeBytes(new byte[]{0, 6}); buf.writeBytes("MQIsdp".getBytes(UTF_8)); buf.writeByte(4); buf.writeByte(0b0000_0010); //keepAlive buf.writeShort(14); //payload length buf.writeShort(1000);  final CONNECT connectPacket = decoder.decode(clientConnection, buf, fixedHeader);  "<AssertPlaceHolder>"; assertFalse(channel.isActive()); }
decode( final @NotNull ClientConnection clientConnection, final @NotNull ByteBuf buf, final byte header) {  if (buf.readableBytes() < 12) { disconnectByInvalidHeader(clientConnection); return null; }  final ByteBuf connectHeader = buf.readSlice(12);  if (!validateProtocolName(connectHeader, clientConnection, PROTOCOL_NAME)) { return null; }  //We don't need to validate the protocol version byte since we already know it's valid, otherwise //we wouldn't be in this protocol-version dependant decoder connectHeader.readByte();  final byte connectFlagsByte = connectHeader.readByte();  final boolean isCleanSessionFlag = isBitSet(connectFlagsByte, 1); final boolean isWillFlag = isBitSet(connectFlagsByte, 2); final boolean isWillRetain = isBitSet(connectFlagsByte, 5); final boolean isPasswordFlag = isBitSet(connectFlagsByte, 6); final boolean isUsernameFlag = isBitSet(connectFlagsByte, 7);  final int willQoS = (connectFlagsByte & 0b0001_1000) >> 3;  if (!validateWill(isWillFlag, isWillRetain, willQoS, clientConnection)) { return null; }  if (!validateUsernamePassword(isUsernameFlag, isPasswordFlag)) { mqttConnacker.connackError(clientConnection.getChannel(), "A client (IP: {}) connected with an invalid username/password combination. The password flag was set but the username flag was not set. Disconnecting client.", "Sent a CONNECT with invalid username/password combination", Mqtt5ConnAckReasonCode.PROTOCOL_ERROR, ReasonStrings.CONNACK_PROTOCOL_ERROR_INVALID_USER_PASS_COMB_MQTT3); return null; }  final int keepAlive = connectHeader.readUnsignedShort();  final int utf8StringLength;  if (buf.readableBytes() < 2 || (buf.readableBytes() < (utf8StringLength = buf.readUnsignedShort()) && utf8StringLength > 0)) { mqttConnacker.connackError(clientConnection.getChannel(), "A client (IP: {}) sent a CONNECT message with an incorrect client id length. Disconnecting client.", "Sent CONNECT with incorrect client id length", Mqtt5ConnAckReasonCode.MALFORMED_PACKET, ReasonStrings.CONNACK_CLIENT_IDENTIFIER_NOT_VALID); return null; }  if (utf8StringLength == 0) { mqttConnacker.connackError(clientConnection.getChannel(), "A client (IP: {}) connected without clientID. This is not allowed. Disconnecting client.", "Sent CONNECT without clientID", Mqtt5ConnAckReasonCode.CLIENT_IDENTIFIER_NOT_VALID, ReasonStrings.CONNACK_CLIENT_IDENTIFIER_NOT_VALID); return null; }  final String clientId;  if (validateUTF8) { clientId = Strings.getValidatedPrefixedString(buf, utf8StringLength, true); if (clientId == null) { mqttConnacker.connackError(clientConnection.getChannel(), "The client id of the client (IP: {}) is not well formed. This is not allowed. Disconnecting client.", "Sent CONNECT with malformed client id", Mqtt5ConnAckReasonCode.MALFORMED_PACKET, ReasonStrings.CONNACK_CLIENT_IDENTIFIER_NOT_VALID); buf.clear(); return null; } } else { clientId = Strings.getPrefixedString(buf, utf8StringLength); } clientConnection.setClientId(clientId);  final MqttWillPublish willPublish;  if (isWillFlag) { willPublish = readMqtt3WillPublish(clientConnection, buf, willQoS, isWillRetain, hiveMQId); if (willPublish == null) { return null; } } else { willPublish = null; }  final String userName; if (isUsernameFlag) { userName = Strings.getPrefixedString(buf); if (userName == null) { mqttConnacker.connackError(clientConnection.getChannel(), "A client (IP: {}) sent a CONNECT with an incorrect username length. Disconnecting client.", "Sent a CONNECT with an incorrect username length", Mqtt5ConnAckReasonCode.MALFORMED_PACKET, ReasonStrings.CONNACK_MALFORMED_PACKET_USERNAME); buf.clear(); return null; } clientConnection.setAuthUsername(userName); } else { userName = null; }  final byte[] password; if (isPasswordFlag) { password = Bytes.getPrefixedBytes(buf); clientConnection.setAuthPassword(password); } else { password = null; }  clientConnection.setConnectKeepAlive(keepAlive); clientConnection.setCleanStart(isCleanSessionFlag);  final long sessionExpiryInterval = isCleanSessionFlag ? 0 : maxSessionExpiryInterval; clientConnection.setClientSessionExpiryInterval(sessionExpiryInterval);  return new CONNECT.Mqtt3Builder().withProtocolVersion(ProtocolVersion.MQTTv3_1) .withClientIdentifier(clientId) .withUsername(userName) .withPassword(password) .withCleanStart(isCleanSessionFlag) .withSessionExpiryInterval(sessionExpiryInterval) .withKeepAlive(keepAlive) .withWillPublish(willPublish).build(); }
[*] target: assertNull(connectPacket)
[-] pred: org. junit. Assert. assertNull ( connectPacket )
************************************
************************************
[+] input: Exception { String map = "{"requestId":"1375128656908832001","workflowId":"fc147e1d-5408-4d41-b066-53cb2e551d0e"," + ""inner":{"num":42,"status":"READY"}}"; jsonUtils.expand(map);  Object jsonObject = jsonUtils.expand(map); "<AssertPlaceHolder>"; assertTrue(jsonObject instanceof LinkedHashMap); assertTrue(((LinkedHashMap<?, ?>) jsonObject).get("requestId") instanceof String); assertTrue(((LinkedHashMap<?, ?>) jsonObject).get("workflowId") instanceof String); assertTrue(((LinkedHashMap<?, ?>) jsonObject).get("inner") instanceof LinkedHashMap); assertTrue( ((LinkedHashMap<?, ?>) ((LinkedHashMap<?, ?>) jsonObject).get("inner")).get("num") instanceof Integer); assertTrue( ((LinkedHashMap<?, ?>) ((LinkedHashMap<?, ?>) jsonObject).get("inner")) .get("status") instanceof String); }
expand(Object input) { if (input instanceof List) { expandList((List<Object>) input); return input; } else if (input instanceof Map) { expandMap((Map<String, Object>) input); return input; } else if (input instanceof String) { return getJson((String) input); } else { return input; } }
[*] target: assertNotNull(jsonObject)
[-] pred: org. junit. Assert. assertNotNull ( jsonObject )
************************************
************************************
[+] input: test_undecided_authorizers_present() { output.authorizerPresent(); task.onSuccess(output);  channel.runPendingTasks();  final AuthorizeWillResultEvent resultEvent = eventsCollector.pollEvent(); "<AssertPlaceHolder>"; assertTrue(resultEvent.getResult().isAuthorizerPresent()); assertEquals(AckReasonCode.NOT_AUTHORIZED, resultEvent.getResult().getAckReasonCode()); }
onSuccess(@Nullable final PublishAuthorizerOutputImpl output) { if (output == null) { //this does not happen return; }  DisconnectReasonCode disconnectReasonCode = null; AckReasonCode reasonCode = null; String reasonString = null;  switch (output.getAuthorizationState()) { case DISCONNECT: disconnectReasonCode = output.getDisconnectReasonCode(); reasonCode = output.getAckReasonCode() != null ? output.getAckReasonCode() : AckReasonCode.NOT_AUTHORIZED; reasonString = output.getReasonString() != null ? output.getReasonString() : getReasonString(connect); break; case FAIL: reasonCode = output.getAckReasonCode() != null ? output.getAckReasonCode() : AckReasonCode.NOT_AUTHORIZED; reasonString = output.getReasonString() != null ? output.getReasonString() : getReasonString(connect); break; case UNDECIDED: if (!output.isAuthorizerPresent()) { //providers never returned an authorizer, same as continue break; } reasonCode = AckReasonCode.NOT_AUTHORIZED; reasonString = getReasonString(connect); break; case SUCCESS: reasonCode = AckReasonCode.SUCCESS; break; case CONTINUE: break; default: //no state left throw new IllegalStateException("Unknown type"); }  final PublishAuthorizerResult result = new PublishAuthorizerResult(reasonCode, reasonString, output.isAuthorizerPresent(), disconnectReasonCode); ctx.pipeline().fireUserEventTriggered(new PluginAuthorizerServiceImpl.AuthorizeWillResultEvent(connect, result)); }
[*] target: assertNotNull(resultEvent)
[-] pred: org. junit. Assert. assertNotNull ( resultEvent )
************************************
************************************
[+] input: testGetBeanOperations() { BeanOperations ops = crane4jTemplate.getBeanOperations(Foo.class); Assert."<AssertPlaceHolder>"; Assert.assertEquals(1, ops.getAssembleOperations().size()); Assert.assertTrue(ops.getDisassembleOperations().isEmpty()); }
getBeanOperations(@NonNull AnnotatedElement element) { BeanOperationParser parser = configuration.getBeanOperationsParser(BeanOperationParser.class); return parser.parse(element); }
[*] target: assertNotNull(ops)
[-] pred: org. junit. Assert. assertNotNull ( ops )
************************************
************************************
[+] input: testEncrypt() { String dataId = "cipher-mockAlgo-application"; String content = "content"; String sec = mockEncryptionPluginService.generateSecretKey(); Pair<String, String> pair = EncryptionHandler.encryptHandler(dataId, content); Assert."<AssertPlaceHolder>"; Assert.assertEquals("should return encrypted content.", mockEncryptionPluginService.encrypt(sec, content), pair.getSecond()); Assert.assertEquals("should return encrypted secret key.", mockEncryptionPluginService.encryptSecretKey(sec), pair.getFirst()); }
encryptHandler(String dataId, String content) { if (!checkCipher(dataId)) { return Pair.with("", content); } Optional<String> algorithmName = parseAlgorithmName(dataId); Optional<EncryptionPluginService> optional = algorithmName.flatMap( EncryptionPluginManager.instance()::findEncryptionService); if (!optional.isPresent()) { LOGGER.warn("[EncryptionHandler] [encryptHandler] No encryption program with the corresponding name found"); return Pair.with("", content); } EncryptionPluginService encryptionPluginService = optional.get(); String secretKey = encryptionPluginService.generateSecretKey(); String encryptContent = encryptionPluginService.encrypt(secretKey, content); return Pair.with(encryptionPluginService.encryptSecretKey(secretKey), encryptContent); }
[*] target: assertNotNull(pair)
[-] pred: org. junit. Assert. assertNotNull ( pair )
************************************
************************************
[+] input: JsonProcessingException { ServerNamingAbility expected = new ServerNamingAbility(); expected.setSupportJraft(true); String serializeJson = jacksonMapper.writeValueAsString(expected); ServerNamingAbility actual = jacksonMapper.readValue(serializeJson, ServerNamingAbility.class); assertEquals(expected, actual); actual = new ServerNamingAbility(); assertNotEquals(expected, actual); actual.setSupportJraft(true); "<AssertPlaceHolder>"; }
setSupportJraft(boolean supportJraft) { this.supportJraft = supportJraft; }
[*] target: assertEquals(expected, actual)
[-] pred: org. junit. Assert. assertEquals ( expected, actual )
************************************
************************************
[+] input: IOException { ObjectId obj = insertBlobWithSize(100); try (DfsReader ctx = db.getObjectDatabase().newReader()) { CounterPackLoadListener listener = new CounterPackLoadListener(); ctx.addPackLoadListener(listener); boolean has = ctx.has(obj); "<AssertPlaceHolder>"; assertEquals(Integer.valueOf(1), listener.callsPerExt.get(PackExt.INDEX)); } }
has(AnyObjectId objectId) throws IOException { if (last != null && !skipGarbagePack(last) && last.hasObject(this, objectId)) return true; PackList packList = db.getPackList(); if (hasImpl(packList, objectId)) { return true; } else if (packList.dirty()) { stats.scanPacks++; return hasImpl(db.scanPacks(packList), objectId); } return false; }
[*] target: assertTrue(has)
[-] pred: org. junit. Assert. assertTrue ( has )
************************************
************************************
[+] input: shouldMarkStreamStreamJoinAsSelfJoinSingleStream() { // Given: props.put(StreamsConfig.TOPOLOGY_OPTIMIZATION_CONFIG, StreamsConfig.OPTIMIZE); final KStream<String, String> stream = builder.stream(Collections.singleton("t1"), consumed); stream.join(stream, MockValueJoiner.TOSTRING_JOINER, JoinWindows.ofTimeDifferenceWithNoGrace(ofMillis(100)));  // When: builder.buildAndOptimizeTopology(props);  // Then: final GraphNode join = getNodeByType(builder.root, StreamStreamJoinNode.class, new HashSet<>()); "<AssertPlaceHolder>"; assertTrue(((StreamStreamJoinNode) join).getSelfJoin()); final GraphNode parent = join.parentNodes().stream().findFirst().get(); final AtomicInteger count = new AtomicInteger(); countJoinWindowNodes(count, builder.root, new HashSet<>()); assertEquals(count.get(), 1); }
buildAndOptimizeTopology(final Properties props) { mergeDuplicateSourceNodes(); optimizeTopology(props); enableVersionedSemantics();  final PriorityQueue<GraphNode> graphNodePriorityQueue = new PriorityQueue<>(5, Comparator.comparing(GraphNode::buildPriority));  graphNodePriorityQueue.offer(root);  while (!graphNodePriorityQueue.isEmpty()) { final GraphNode streamGraphNode = graphNodePriorityQueue.remove();  if (LOG.isDebugEnabled()) { LOG.debug("Adding nodes to topology {} child nodes {}", streamGraphNode, streamGraphNode.children()); }  if (streamGraphNode.allParentsWrittenToTopology() && !streamGraphNode.hasWrittenToTopology()) { streamGraphNode.writeToTopology(internalTopologyBuilder); streamGraphNode.setHasWrittenToTopology(true); }  for (final GraphNode graphNode : streamGraphNode.children()) { graphNodePriorityQueue.offer(graphNode); } } internalTopologyBuilder.validateCopartition(); }
[*] target: assertNotNull(join)
[-] pred: org. junit. Assert. assertNotNull ( join )
************************************
************************************
[+] input: Exception { Ref ref = git.branchRename().setNewName(Constants.R_HEADS + "foo") .call(); assertEquals("Unexpected ref name", Constants.R_HEADS + Constants.R_HEADS + "foo", ref.getName()); // And check that we can rename it back to a sane name ref = git.branchRename().setNewName("foo").call(); "<AssertPlaceHolder>"; assertEquals("Unexpected ref name", Constants.R_HEADS + "foo", ref.getName()); }
call() throws GitAPIException, RefNotFoundException, InvalidRefNameException, RefAlreadyExistsException, DetachedHeadException { checkCallable();  if (newName == null) { throw new InvalidRefNameException(MessageFormat.format(JGitText .get().branchNameInvalid, "<null>")); //$NON-NLS-1$ } try { String fullOldName; String fullNewName; if (oldName != null) { // Don't just rely on findRef -- if there are local and remote // branches with the same name, and oldName is a short name, it // does not uniquely identify the ref and we might end up // renaming the wrong branch or finding a tag instead even // if a unique branch for the name exists! // // OldName may be a either a short or a full name. Ref ref = repo.exactRef(oldName); if (ref == null) { ref = repo.exactRef(Constants.R_HEADS + oldName); Ref ref2 = repo.exactRef(Constants.R_REMOTES + oldName); if (ref != null && ref2 != null) { throw new RefNotFoundException(MessageFormat.format( JGitText.get().renameBranchFailedAmbiguous, oldName, ref.getName(), ref2.getName())); } else if (ref == null) { if (ref2 != null) { ref = ref2; } else { throw new RefNotFoundException(MessageFormat.format( JGitText.get().refNotResolved, oldName)); } } } fullOldName = ref.getName(); } else { fullOldName = repo.getFullBranch(); if (fullOldName == null) { throw new NoHeadException( JGitText.get().invalidRepositoryStateNoHead); } if (ObjectId.isId(fullOldName)) throw new DetachedHeadException(); }  if (fullOldName.startsWith(Constants.R_REMOTES)) { fullNewName = Constants.R_REMOTES + newName; } else if (fullOldName.startsWith(Constants.R_HEADS)) { fullNewName = Constants.R_HEADS + newName; } else { throw new RefNotFoundException(MessageFormat.format( JGitText.get().renameBranchFailedNotABranch, fullOldName)); }  if (!Repository.isValidRefName(fullNewName)) { throw new InvalidRefNameException(MessageFormat.format(JGitText .get().branchNameInvalid, fullNewName)); } if (repo.exactRef(fullNewName) != null) { throw new RefAlreadyExistsException(MessageFormat .format(JGitText.get().refAlreadyExists1, fullNewName)); } RefRename rename = repo.renameRef(fullOldName, fullNewName); Result renameResult = rename.rename();  setCallable(false);  if (Result.RENAMED != renameResult) { throw new JGitInternalException(MessageFormat.format(JGitText .get().renameBranchUnexpectedResult, renameResult .name())); } if (fullNewName.startsWith(Constants.R_HEADS)) { String shortOldName = fullOldName.substring(Constants.R_HEADS .length()); final StoredConfig repoConfig = repo.getConfig(); // Copy all configuration values over to the new branch for (String name : repoConfig.getNames( ConfigConstants.CONFIG_BRANCH_SECTION, shortOldName)) { String[] values = repoConfig.getStringList( ConfigConstants.CONFIG_BRANCH_SECTION, shortOldName, name); if (values.length == 0) { continue; } // Keep any existing values already configured for the // new branch name String[] existing = repoConfig.getStringList( ConfigConstants.CONFIG_BRANCH_SECTION, newName, name); if (existing.length > 0) { String[] newValues = new String[values.length + existing.length]; System.arraycopy(existing, 0, newValues, 0, existing.length); System.arraycopy(values, 0, newValues, existing.length, values.length); values = newValues; }  repoConfig.setStringList( ConfigConstants.CONFIG_BRANCH_SECTION, newName, name, Arrays.asList(values)); } repoConfig.unsetSection(ConfigConstants.CONFIG_BRANCH_SECTION, shortOldName); repoConfig.save(); }  Ref resultRef = repo.exactRef(fullNewName); if (resultRef == null) { throw new JGitInternalException( JGitText.get().renameBranchFailedUnknownReason); } return resultRef; } catch (IOException ioe) { throw new JGitInternalException(ioe.getMessage(), ioe); } }
[*] target: assertNotNull(ref)
[-] pred: org. junit. Assert. assertNotNull ( ref )
************************************
************************************
[+] input: shouldOptimizeActiveTasks() { final Map<Subtopology, Set<TaskId>> tasksForTopicGroup = mkMap( mkEntry(new Subtopology(0, null), mkSet(TASK_0_0, TASK_0_1)), mkEntry(new Subtopology(1, null), mkSet(TASK_1_0, TASK_1_1)) ); final RackAwareTaskAssignor assignor = new RackAwareTaskAssignor( getClusterForAllTopics(), getTaskTopicPartitionMapForAllTasks(), mkMap(), tasksForTopicGroup, getProcessRacksForAllProcess(), mockInternalTopicManager, getRackAwareEnabledConfig(), time );  final ClientState clientState1 = new ClientState(emptySet(), emptySet(), emptyMap(), EMPTY_CLIENT_TAGS, 1); final ClientState clientState2 = new ClientState(emptySet(), emptySet(), emptyMap(), EMPTY_CLIENT_TAGS, 1); final ClientState clientState3 = new ClientState(emptySet(), emptySet(), emptyMap(), EMPTY_CLIENT_TAGS, 1);  clientState1.assignActiveTasks(mkSet(TASK_0_1, TASK_1_1)); clientState2.assignActive(TASK_1_0); clientState3.assignActive(TASK_0_0);  // task_0_0 has same rack as UUID_1 // task_0_1 has same rack as UUID_2 and UUID_3 // task_1_0 has same rack as UUID_1 and UUID_3 // task_1_1 has same rack as UUID_2 // Optimal assignment is UUID_1: {0_0, 1_0}, UUID_2: {1_1}, UUID_3: {0_1} which result in no cross rack traffic final SortedMap<UUID, ClientState> clientStateMap = new TreeMap<>(mkMap( mkEntry(UUID_1, clientState1), mkEntry(UUID_2, clientState2), mkEntry(UUID_3, clientState3) )); final SortedSet<TaskId> taskIds = mkSortedSet(TASK_0_0, TASK_0_1, TASK_1_0, TASK_1_1);  assertTrue(assignor.canEnableRackAwareAssignor()); int expected = stateful ? 40 : 4; final long originalCost = assignor.activeTasksCost(taskIds, clientStateMap, trafficCost, nonOverlapCost); assertEquals(expected, originalCost);  expected = stateful ? 4 : 0; final long cost = assignor.optimizeActiveTasks(taskIds, clientStateMap, trafficCost, nonOverlapCost); "<AssertPlaceHolder>";  assertEquals(mkSet(TASK_0_0, TASK_1_0), clientState1.activeTasks()); assertEquals(mkSet(TASK_1_1), clientState2.activeTasks()); assertEquals(mkSet(TASK_0_1), clientState3.activeTasks()); }
optimizeActiveTasks(final SortedSet<TaskId> activeTasks, final SortedMap<UUID, ClientState> clientStates, final int trafficCost, final int nonOverlapCost) { if (activeTasks.isEmpty()) { return 0; }  log.info("Assignment before active task optimization is {}\n with cost {}", clientStates, activeTasksCost(activeTasks, clientStates, trafficCost, nonOverlapCost));  final long startTime = time.milliseconds(); final List<UUID> clientList = new ArrayList<>(clientStates.keySet()); final List<TaskId> taskIdList = new ArrayList<>(activeTasks); final Map<TaskId, UUID> taskClientMap = new HashMap<>(); final Map<UUID, Integer> originalAssignedTaskNumber = new HashMap<>(); final RackAwareGraphConstructor<ClientState> graphConstructor = RackAwareGraphConstructorFactory.create(assignmentConfigs, tasksForTopicGroup); final Graph<Integer> graph = graphConstructor.constructTaskGraph( clientList, taskIdList, clientStates, taskClientMap, originalAssignedTaskNumber, ClientState::hasActiveTask, this::getCost, trafficCost, nonOverlapCost, false, false );  graph.solveMinCostFlow(); final long cost = graph.totalCost();  graphConstructor.assignTaskFromMinCostFlow(graph, clientList, taskIdList, clientStates, originalAssignedTaskNumber, taskClientMap, ClientState::assignActive, ClientState::unassignActive, ClientState::hasActiveTask);  final long duration = time.milliseconds() - startTime; log.info("Assignment after {} milliseconds for active task optimization is {}\n with cost {}", duration, clientStates, cost); return cost; }
[*] target: assertEquals(expected, cost)
[-] pred: org. junit. Assert. assertEquals ( expected, cost )
************************************
************************************
[+] input: onGetFailed_callWhenSessionGetFailed_callSucceed() { long timestamp = System.currentTimeMillis(); BaseConnectionSessionManager sessionManager = new DefaultConnectionSessionManager(getTaskManager(), new InMemoryConnectionSessionRepository() { @Override public ConnectionSession get(@NonNull String sessionId) { throw new RuntimeException(timestamp + ""); } }); Holder<Throwable> holder = new Holder<>(); TestSessionEventListener listener = new TestSessionEventListener() { @Override public void onCreateSucceed(ConnectionSession session) { // ignore }  @Override public void onGetFailed(String id, Throwable e) { holder.setValue(e); } }; sessionManager.addListener(listener);  ConnectionSession connectionSession = sessionManager.start(getSessionConnectionFactory(ConnectType.OB_ORACLE, true)); connectionSession = sessionManager.getSession(connectionSession.getId()); Assert."<AssertPlaceHolder>"; listener.doAssert(); Assert.assertEquals(holder.getValue().getMessage(), timestamp + ""); }
getId();  /** * Put {@link DataSource}
[*] target: assertNull(connectionSession)
[-] pred: org. junit. Assert. assertNull ( connectionSession )
************************************
************************************
[+] input: testMultiVersionAlias() { SortedSet<PluginDesc<SinkConnector>> sinkConnectors = new TreeSet<>(); // distinct versions don't cause an alias collision (the class name is the same) sinkConnectors.add(new PluginDesc<>(MockSinkConnector.class, null, PluginType.SINK, MockSinkConnector.class.getClassLoader())); sinkConnectors.add(new PluginDesc<>(MockSinkConnector.class, "1.0", PluginType.SINK, MockSinkConnector.class.getClassLoader())); assertEquals(2, sinkConnectors.size()); PluginScanResult result = new PluginScanResult( sinkConnectors, Collections.emptySortedSet(), Collections.emptySortedSet(), Collections.emptySortedSet(), Collections.emptySortedSet(), Collections.emptySortedSet(), Collections.emptySortedSet(), Collections.emptySortedSet(), Collections.emptySortedSet() ); Map<String, String> actualAliases = PluginUtils.computeAliases(result); Map<String, String> expectedAliases = new HashMap<>(); expectedAliases.put("MockSinkConnector", MockSinkConnector.class.getName()); expectedAliases.put("MockSink", MockSinkConnector.class.getName()); "<AssertPlaceHolder>"; }
computeAliases(PluginScanResult scanResult) { Map<String, Set<String>> aliasCollisions = new HashMap<>(); scanResult.forEach(pluginDesc -> { aliasCollisions.computeIfAbsent(simpleName(pluginDesc), ignored -> new HashSet<>()).add(pluginDesc.className()); aliasCollisions.computeIfAbsent(prunedName(pluginDesc), ignored -> new HashSet<>()).add(pluginDesc.className()); }); Map<String, String> aliases = new HashMap<>(); for (Map.Entry<String, Set<String>> entry : aliasCollisions.entrySet()) { String alias = entry.getKey(); Set<String> classNames = entry.getValue(); if (classNames.size() == 1) { aliases.put(alias, classNames.stream().findAny().get()); } else { log.debug("Ignoring ambiguous alias '{}' since it refers to multiple distinct plugins {}", alias, classNames); } } return aliases; }
[*] target: assertEquals(expectedAliases, actualAliases)
[-] pred: org. junit. Assert. assertEquals ( expectedAliases, actualAliases )
************************************
************************************
[+] input: test_constructMqtt5() { final PUBREL origin = new PUBREL( 1, Mqtt5PubRelReasonCode.PACKET_IDENTIFIER_NOT_FOUND, "reasonString", Mqtt5UserProperties.NO_USER_PROPERTIES); final PubrelPacketImpl packet = new PubrelPacketImpl(origin);  final PUBREL merged = PUBREL.from(packet);  "<AssertPlaceHolder>"; assertNotSame(origin, merged); assertPUBRELequals(origin, merged); }
from(final @NotNull PubrelPacketImpl packet) { return new PUBREL( packet.getPacketIdentifier(), Mqtt5PubRelReasonCode.from(packet.getReasonCode()), packet.getReasonString().orElse(null), Mqtt5UserProperties.of(packet.getUserProperties().asInternalList())); }
[*] target: assertNotNull(merged)
[-] pred: org. junit. Assert. assertNotNull ( merged )
************************************
************************************
[+] input: test() { ConversionService conversionService = DefaultConversionService.getSharedInstance(); SpringConverterManager converterManager = new SpringConverterManager(conversionService); Assert.assertSame(conversionService, converterManager.getConversionService());  BiFunction<String, Integer, Integer> converter = converterManager.getConverter(String.class, Integer.class); Assert."<AssertPlaceHolder>"; Assert.assertEquals((Integer)1, converter.apply("1", 0)); Assert.assertEquals((Integer)0, converter.apply("NaN", 0)); }
getConverter(Class<T> targetType, Class<R> resultType) { return (target, def) -> { try { return conversionService.convert(target, resultType); } catch (Exception e) { return def; } }; }
[*] target: assertNotNull(converter)
[-] pred: org. junit. Assert. assertNotNull ( converter )
************************************
************************************
[+] input: Exception { init("allowconflict", true, true);  Result result = applyPatchAllowConflicts();  assertEquals(result.getErrors().size(), 1); PatchApplier.Result.Error error = result.getErrors().get(0); assertEquals("cannot apply hunk", error.msg); assertEquals("allowconflict", error.oldFileName); "<AssertPlaceHolder>"; verifyChange(result, "allowconflict", true, 1); }
isGitConflict() { return isGitConflict; }
[*] target: assertTrue(error.isGitConflict())
[-] pred: org. junit. Assert. assertTrue ( error. isGitConflict() )
************************************
************************************
[+] input: testClear() { final Ref master = newRef("refs/heads/master", ID_ONE); loose = toList(master);  RefMap map = new RefMap("", packed, loose, resolved); assertSame(master, map.get("refs/heads/master"));  map.clear(); assertNull(map.get("refs/heads/master")); assertTrue(map.isEmpty()); "<AssertPlaceHolder>"; }
size() { if (!sizeIsValid) { size = 0; Iterator<?> i = entrySet().iterator(); for (; i.hasNext(); i.next()) size++; sizeIsValid = true; } return size; }
[*] target: assertEquals(0, map.size())
[-] pred: org. junit. Assert. assertEquals ( 0, map. size() )
************************************
************************************
[+] input: testMemberLeave() { Member member = Member.builder().ip("1.1.3.3").port(8848).state(NodeState.DOWN).build(); boolean joinResult = serverMemberManager.memberJoin(Collections.singletonList(member)); assertTrue(joinResult);  List<String> ips = serverMemberManager.getServerListUnhealth(); assertEquals(1, ips.size());  boolean result = serverMemberManager.memberLeave(Collections.singletonList(member)); "<AssertPlaceHolder>"; }
memberLeave(Collection<Member> members) { Set<Member> set = new HashSet<>(allMembers()); set.removeAll(members); return memberChange(set); }
[*] target: assertTrue(result)
[-] pred: org. junit. Assert. assertTrue ( result )
************************************
************************************
[+] input: IOException { Properties properties = ResourceUtils.getResourceAsProperties("resource_utils_test.properties"); "<AssertPlaceHolder>"; assertTrue(properties.containsKey("a")); }
getResourceAsProperties(String resource) throws IOException { ClassLoader loader = ResourceUtils.class.getClassLoader(); return getResourceAsProperties(loader, resource); }
[*] target: assertNotNull(properties)
[-] pred: org. junit. Assert. assertNotNull ( properties )
************************************
************************************
[+] input: testException() { com.amazonaws.services.sqs.model.Message message = new com.amazonaws.services.sqs.model.Message() .withMessageId("test") .withBody("") .withReceiptHandle("receiptHandle"); Answer<?> answer = (Answer<ReceiveMessageResult>) invocation -> new ReceiveMessageResult();  AmazonSQS client = mock(AmazonSQS.class); when(client.listQueues(any(ListQueuesRequest.class))) .thenReturn(new ListQueuesResult().withQueueUrls("junit_queue_url")); when(client.receiveMessage(any(ReceiveMessageRequest.class))) .thenThrow(new RuntimeException("Error in SQS communication")) .thenReturn(new ReceiveMessageResult().withMessages(message)) .thenAnswer(answer);  SQSObservableQueue queue = new SQSObservableQueue.Builder().withQueueName("junit").withClient(client).build(); queue.start();  List<Message> found = new LinkedList<>(); Observable<Message> observable = queue.observe(); assertNotNull(observable); observable.subscribe(found::add);  Uninterruptibles.sleepUninterruptibly(1000, TimeUnit.MILLISECONDS); "<AssertPlaceHolder>"; }
size() { GetQueueAttributesResult attributes = client.getQueueAttributes( queueURL, Collections.singletonList("ApproximateNumberOfMessages")); String sizeAsStr = attributes.getAttributes().get("ApproximateNumberOfMessages"); try { return Long.parseLong(sizeAsStr); } catch (Exception e) { return -1; } }
[*] target: assertEquals(1, found.size())
[-] pred: org. junit. Assert. assertEquals ( 1, found. size ( ) )
************************************
************************************
[+] input: testGetOrCreateLocalFile_Success() { MultipartFile mockFile = new MockMultipartFile("some-file", "some-file", null, new byte[10]); localFileOperator.saveLocalFile(BUCKET, mockFile.getOriginalFilename(), mockFile.getSize(), mockFile.getInputStream()); File file = localFileOperator.getOrCreateLocalFile(BUCKET, "some-file"); "<AssertPlaceHolder>"; assertTrue(file.exists()); }
getOrCreateLocalFile(String bucketName, String objectId) { Verify.notEmpty(bucketName, "bucketName"); Verify.notEmpty(objectId, "objectId"); PreConditions.validNoPathTraversal(generateFilePath(bucketName, objectId), generateFilePath(bucketName)); File file = new File(absolutePathName(bucketName, objectId)); createParentDirs(file); return file; }
[*] target: assertNotNull(file)
[-] pred: org. junit. Assert. assertNotNull ( file )
************************************
************************************
[+] input: shouldCreateWriteBatches() { final String key = "a"; final Collection<ConsumerRecord<byte[], byte[]>> records = new ArrayList<>(); records.add(new ConsumerRecord<>("", 0, 0L, serializeKey(new Windowed<>(key, windows[0]), true).get(), serializeValue(50L))); records.add(new ConsumerRecord<>("", 0, 0L, serializeKey(new Windowed<>(key, windows[3]), true).get(), serializeValue(100L))); final Map<S, WriteBatch> writeBatchMap = bytesStore.getWriteBatches(records); "<AssertPlaceHolder>";  final int expectedCount = getIndexSchema() == null ? 1 : 2; for (final WriteBatch batch : writeBatchMap.values()) { // 2 includes base and index record assertEquals(expectedCount, batch.count()); } }
getWriteBatches(final Collection<ConsumerRecord<byte[], byte[]>> records);  @Override public Position getPosition() { return position; }
[*] target: assertEquals(2, writeBatchMap.size())
[-] pred: org. junit. Assert. assertEquals ( 2, writeBatchMap. size ( ) )
************************************
************************************
[+] input: Exception { ConnectResetRequest request = new ConnectResetRequest(); request.setServerIp("127.0.0.1"); request.setServerPort("8888"); request.setRequestId("1"); request.setConnectionId("11111_127.0.0.1_8888"); String json = mapper.writeValueAsString(request); Assert."<AssertPlaceHolder>"; Assert.assertTrue(json.contains(""serverIp":"127.0.0.1"")); Assert.assertTrue(json.contains(""serverPort":"8888"")); Assert.assertTrue(json.contains(""module":"internal"")); Assert.assertTrue(json.contains(""requestId":"1"")); Assert.assertTrue(json.contains(""connectionId":"11111_127.0.0.1_8888"")); }
setConnectionId(String connectionId) { this.connectionId = connectionId; }
[*] target: assertNotNull(json)
[-] pred: org. junit. Assert. assertNotNull ( json )
************************************
************************************
[+] input: Exception { final DirCache dc = DirCache.newInCore();  final FileMode mode = FileMode.REGULAR_FILE; final String[] paths = { "git-gui/po/fr.po", "git_remote_helpers/git/repo.py" }; final DirCacheEntry[] ents = new DirCacheEntry[paths.length]; for (int i = 0; i < paths.length; i++) { ents[i] = new DirCacheEntry(paths[i]); ents[i].setFileMode(mode); }  final DirCacheBuilder b = dc.builder(); for (DirCacheEntry ent : ents) { b.add(ent); } b.finish();  DirCacheIterator dci = new DirCacheIterator(dc); assertFalse(dci.eof()); assertEquals("git-gui", dci.getEntryPathString()); dci.next(1); assertFalse(dci.eof()); assertEquals("git_remote_helpers", dci.getEntryPathString()); dci.back(1); assertFalse(dci.eof()); assertEquals("git-gui", dci.getEntryPathString()); dci.next(1); assertEquals("git_remote_helpers", dci.getEntryPathString()); dci.next(1); "<AssertPlaceHolder>";  }
eof() { return ptr == treeEnd; }
[*] target: assertTrue(dci.eof())
[-] pred: org. junit. Assert. assertTrue ( dci. eof() )
************************************
************************************
[+] input: oneNetaddressStrategyTest() { PlainAccessResource plainAccessResource = new PlainAccessResource(); plainAccessResource.setWhiteRemoteAddress("127.0.0.1"); RemoteAddressStrategy remoteAddressStrategy = remoteAddressStrategyFactory.getRemoteAddressStrategy(plainAccessResource); plainAccessResource.setWhiteRemoteAddress(""); boolean match = remoteAddressStrategy.match(plainAccessResource); Assert.assertFalse(match);  plainAccessResource.setWhiteRemoteAddress("127.0.0.2"); match = remoteAddressStrategy.match(plainAccessResource); Assert.assertFalse(match);  plainAccessResource.setWhiteRemoteAddress("127.0.0.1"); match = remoteAddressStrategy.match(plainAccessResource); Assert.assertTrue(match);  //        Ipv6 test plainAccessResource = new PlainAccessResource(); plainAccessResource.setWhiteRemoteAddress("::1"); remoteAddressStrategy = remoteAddressStrategyFactory.getRemoteAddressStrategy(plainAccessResource); plainAccessResource.setWhiteRemoteAddress(""); match = remoteAddressStrategy.match(plainAccessResource); Assert.assertFalse(match);  plainAccessResource.setWhiteRemoteAddress("::2"); match = remoteAddressStrategy.match(plainAccessResource); Assert.assertFalse(match);  plainAccessResource.setWhiteRemoteAddress("::1"); match = remoteAddressStrategy.match(plainAccessResource); Assert.assertTrue(match);  plainAccessResource.setWhiteRemoteAddress("0000:0000:0000:0000:0000:0000:0000:0001"); match = remoteAddressStrategy.match(plainAccessResource); Assert."<AssertPlaceHolder>"; }
match(PlainAccessResource plainAccessResource);
[*] target: assertTrue(match)
[-] pred: org. junit. Assert. assertTrue ( match )
************************************
************************************
[+] input: Exception { ConfigManager testConfigManager = buildTestConfigManager(); File file = createAndWriteFile(testConfigManager.configFilePath() + ".bak"); // invoke private method "loadBak()" Method declaredMethod = ConfigManager.class.getDeclaredMethod("loadBak"); declaredMethod.setAccessible(true); Boolean loadBakResult = (Boolean) declaredMethod.invoke(testConfigManager); "<AssertPlaceHolder>"; file.delete();  Boolean loadBakResult2 = (Boolean) declaredMethod.invoke(testConfigManager); assertTrue(loadBakResult2); declaredMethod.setAccessible(false); }
loadBak() { String fileName = null; try { fileName = this.configFilePath(); String jsonString = MixAll.file2String(fileName + ".bak"); if (jsonString != null && jsonString.length() > 0) { this.decode(jsonString); log.info("load " + fileName + " OK"); return true; } } catch (Exception e) { log.error("load " + fileName + " Failed", e); return false; }  return true; }
[*] target: assertTrue(loadBakResult)
[-] pred: org. junit. Assert. assertTrue ( loadBakResult )
************************************
************************************
[+] input: Exception { RawText rt = new RawText(Constants.encodeASCII("\nfoo")); assertEquals("\n", rt.getLineDelimiter()); "<AssertPlaceHolder>"; }
isMissingNewlineAtEnd() { final int end = lines.get(lines.size() - 1); if (end == 0) return true; return content[end - 1] != '\n'; }
[*] target: assertTrue(rt.isMissingNewlineAtEnd())
[-] pred: org. junit. Assert. assertTrue ( rt. isMissingNewlineAtEnd() )
************************************
************************************
[+] input: testClear() { Query query = Query.newInstance().addParam("key-1", "value-1").addParam("key-2", "value-2"); assertFalse(query.isEmpty()); assertEquals("value-1", query.getValue("key-1")); query.clear(); "<AssertPlaceHolder>"; }
isEmpty() { return isEmpty; }
[*] target: assertTrue(query.isEmpty())
[-] pred: org. junit. Assert. assertTrue ( query. isEmpty ( ) )
************************************
************************************
[+] input: Exception { WorkflowSummary oldWorkflow = TestUtils.loadWorkflowSnapshot(objectMapper, "workflow_summary"); oldWorkflow.setStatus(WorkflowStatus.RUNNING); oldWorkflow.setUpdateTime(getFormattedTime(new DateTime().minusHours(2).toDate()));  WorkflowSummary recentWorkflow = TestUtils.loadWorkflowSnapshot(objectMapper, "workflow_summary"); recentWorkflow.setStatus(WorkflowStatus.RUNNING); recentWorkflow.setUpdateTime(getFormattedTime(new DateTime().minusHours(1).toDate()));  WorkflowSummary tooRecentWorkflow = TestUtils.loadWorkflowSnapshot(objectMapper, "workflow_summary"); tooRecentWorkflow.setStatus(WorkflowStatus.RUNNING); tooRecentWorkflow.setUpdateTime(getFormattedTime(new DateTime().toDate()));  indexDAO.indexWorkflow(oldWorkflow); indexDAO.indexWorkflow(recentWorkflow); indexDAO.indexWorkflow(tooRecentWorkflow);  Thread.sleep(1000);  List<String> ids = indexDAO.searchRecentRunningWorkflows(2, 1);  "<AssertPlaceHolder>"; assertEquals(recentWorkflow.getWorkflowId(), ids.get(0)); }
searchRecentRunningWorkflows( int lastModifiedHoursAgoFrom, int lastModifiedHoursAgoTo) { DateTime dateTime = new DateTime(); QueryBuilder q = QueryBuilders.boolQuery() .must( QueryBuilders.rangeQuery("updateTime") .gt(dateTime.minusHours(lastModifiedHoursAgoFrom))) .must( QueryBuilders.rangeQuery("updateTime") .lt(dateTime.minusHours(lastModifiedHoursAgoTo))) .must(QueryBuilders.termQuery("status", "RUNNING"));  SearchResult<String> workflowIds; try { workflowIds = searchObjectIds( workflowIndexName, q, 0, 5000, Collections.singletonList("updateTime:ASC")); } catch (IOException e) { logger.error("Unable to communicate with ES to find recent running workflows", e); return Collections.emptyList(); }  return workflowIds.getResults(); }
[*] target: assertEquals(1, ids.size())
[-] pred: org. junit. Assert. assertEquals ( 1, ids. size ( ) )
************************************
************************************
[+] input: test1() { TestConditionAnnotationParser1 parser = new TestConditionAnnotationParser1(SimpleAnnotationFinder.INSTANCE); Field field1 = AbstractConditionParserTest.class.getDeclaredField("field1"); Assert.assertNotNull(field1); KeyTriggerOperation operation1 = SimpleKeyTriggerOperation.builder() .source(field1).id(field1.getName()).key(field1.getName()) .build(); Condition condition1 = CollectionUtils.getFirstNotNull(parser.parse(field1, operation1)); Assert."<AssertPlaceHolder>"; Assert.assertTrue(condition1.test(null, operation1)); }
parse( AnnotatedElement element, KeyTriggerOperation operation) { if (ignored.contains(element)) { return Collections.emptyList(); } List<Condition> results = doParse(element, operation); if (results.isEmpty()) { ignored.add(element); return Collections.emptyList(); } return results; }
[*] target: assertNotNull(condition1)
[-] pred: org. junit. Assert. assertNotNull ( condition1 )
************************************
************************************
[+] input: testMerge_PackedLooseLoose() { final Ref refA = newRef("A", ID_ONE); final Ref refB_ONE = newRef("B", ID_ONE); final Ref refB_TWO = newRef("B", ID_TWO); final Ref refc = newRef("c", ID_ONE);  packed = toList(refA, refB_ONE); loose = toList(refB_TWO, refc);  RefMap map = new RefMap("", packed, loose, resolved); assertEquals(3, map.size()); assertFalse(map.isEmpty()); assertTrue(map.containsKey(refA.getName())); assertSame(refA, map.get(refA.getName()));  // loose overrides packed given same name assertSame(refB_TWO, map.get(refB_ONE.getName()));  Iterator<Ref> itr = map.values().iterator(); assertTrue(itr.hasNext()); assertSame(refA, itr.next()); assertTrue(itr.hasNext()); assertSame(refB_TWO, itr.next()); assertTrue(itr.hasNext()); assertSame(refc, itr.next()); "<AssertPlaceHolder>"; }
hasNext() { if (next == null) next = peek(); return next != null; }
[*] target: assertFalse(itr.hasNext())
[-] pred: org. junit. Assert. assertFalse ( itr. hasNext() )
************************************
************************************
[+] input: testEquals() { Instance actual = new Instance(); setInstance(actual); actual.setMetadata(new HashMap<>()); actual.addMetadata("a", "b"); assertFalse(actual.equals(new Object())); Instance expected = new Instance(); setInstance(expected); expected.setMetadata(new HashMap<>()); expected.addMetadata("a", "b"); assertTrue(actual.equals(expected)); expected.addMetadata("a", "c"); "<AssertPlaceHolder>"; }
equals(final Object obj) { if (!(obj instanceof Instance)) { return false; }  final Instance host = (Instance) obj; return Instance.strEquals(host.toString(), toString()); }
[*] target: assertFalse(actual.equals(expected))
[-] pred: org. junit. Assert. assertFalse ( actual. equals ( expected ) )
************************************
************************************
[+] input: testGetRemoteExecutorQueueSize() { int defaultExpectVal = 1 << 14; int defaultVal = RemoteUtils.getRemoteExecutorQueueSize(); Assert.assertEquals(defaultExpectVal, defaultVal);  System.setProperty("remote.executor.queue.size", "10"); int val1 = RemoteUtils.getRemoteExecutorQueueSize(); Assert.assertEquals(10, val1);  System.setProperty("remote.executor.queue.size", "-1"); int val2 = RemoteUtils.getRemoteExecutorQueueSize(); Assert."<AssertPlaceHolder>"; }
getRemoteExecutorQueueSize() { String queueSizeString = System.getProperty("remote.executor.queue.size"); if (NumberUtils.isDigits(queueSizeString)) { int size = Integer.parseInt(queueSizeString); return size > 0 ? size : REMOTE_EXECUTOR_QUEUE_SIZE; } else { return REMOTE_EXECUTOR_QUEUE_SIZE; } }
[*] target: assertEquals(defaultExpectVal, val2)
[-] pred: org. junit. Assert. assertEquals ( defaultExpectVal, val2 )
************************************
************************************
[+] input: Exception { when(channel.isWritable()).thenReturn(true); final SettableFuture<PublishStatus> future = SettableFuture.create(); final PUBLISH publish = new PUBLISHFactory.Mqtt3Builder() .withHivemqId("hivemqId") .withPayload(new byte[]{0}) .withTopic("topic") .withQoS(QoS.AT_MOST_ONCE) .withOnwardQos(QoS.AT_MOST_ONCE) .withMessageExpiryInterval(MESSAGE_EXPIRY_INTERVAL_NOT_SET) .withPublishId(1L) .withPersistence(publishPayloadPersistence) .build(); final PublishWithFuture publishWithFuture = new PublishWithFuture(publish, future, false, publishPayloadPersistence); final boolean messageDropped = handler.checkChannelNotWritable(ctx, publishWithFuture, promise); "<AssertPlaceHolder>"; assertEquals(false, future.isDone()); // will be set in the Ordered topic handler verify(promise, never()).setSuccess(); verify(counter, never()).inc(); verify(publishPayloadPersistence, never()).decrementReferenceCounter(1); }
checkChannelNotWritable(final ChannelHandlerContext ctx, final @NotNull Object msg, final @NotNull ChannelPromise promise) throws Exception { if (!ctx.channel().isWritable()) {  if (msg instanceof PUBLISH) { if (notWritableMessages.get() < notWritableQueueSize) { notWritableMessages.incrementAndGet(); promise.addListeners(decrementCounterListener); return false; }  final PUBLISH publish = (PUBLISH) msg; if ((publish).getQoS() == QoS.AT_MOST_ONCE) { if (msg instanceof PublishWithFuture) { final SettableFuture<PublishStatus> future = ((PublishWithFuture) msg).getFuture(); future.set(PublishStatus.CHANNEL_NOT_WRITABLE); } //Drop message final String clientId = ctx.channel().attr(ClientConnection.CHANNEL_ATTRIBUTE_NAME).get().getClientId(); log.trace("Dropped qos 0 message for client {} on topic {} because the channel was not writable", clientId, publish.getTopic()); messageDroppedService.notWritable(clientId, publish.getTopic(), publish.getQoS().getQosNumber()); promise.setSuccess(); return true; } } }  return false; }
[*] target: assertFalse(messageDropped)
[-] pred: org. junit. Assert. assertFalse ( messageDropped )
************************************
************************************
[+] input: InterruptedException { final List<String> input = Arrays.asList("1", "2", "3"); final List<String> output = new ArrayList<>();  final AllItemsItemCallback<String> stringCallback = new AllItemsItemCallback<>(MoreExecutors.directExecutor(), (ctx, item) -> { output.add(item); });  final ListenableFuture<Boolean> future = stringCallback.onItems(input);  "<AssertPlaceHolder>"; assertEquals(input, output); }
onItems(final @NotNull Collection<T> items) { final IterationContextImpl iterationContext = new IterationContextImpl(); final SettableFuture<Boolean> resultFuture = SettableFuture.create();  callbackExecutor.execute(() -> {  final ClassLoader contextClassLoader = Thread.currentThread().getContextClassLoader(); try { Thread.currentThread().setContextClassLoader(callback.getClass().getClassLoader()); for (final T item : items) {  callback.iterate(iterationContext, item);  if (iterationContext.isAborted()) { resultFuture.set(false); return; } } } catch (final Throwable t) { resultFuture.setException(t); return; } finally { Thread.currentThread().setContextClassLoader(contextClassLoader); } resultFuture.set(true); });  return resultFuture; }
[*] target: assertTrue(future.get())
[-] pred: org. junit. Assert. assertTrue ( future. get ( ) )
************************************
************************************
[+] input: testRemoveLastSubmittedRecord() { SubmittedRecord submittedRecord = submittedRecords.submit(PARTITION1, newOffset());  CommittableOffsets committableOffsets = submittedRecords.committableOffsets(); assertEquals(Collections.emptyMap(), committableOffsets.offsets()); assertMetadata(committableOffsets, 0, 1, 1, 1, PARTITION1);  assertTrue("First attempt to remove record from submitted queue should succeed", submittedRecord.drop()); assertFalse("Attempt to remove already-removed record from submitted queue should fail", submittedRecord.drop());  committableOffsets = submittedRecords.committableOffsets(); // Even if SubmittedRecords::remove is broken, we haven't ack'd anything yet, so there should be no committable offsets assertTrue(committableOffsets.isEmpty());  submittedRecord.ack(); committableOffsets = submittedRecords.committableOffsets(); // Even though the record has somehow been acknowledged, it should not be counted when collecting committable offsets "<AssertPlaceHolder>"; }
isEmpty() { return numCommittableMessages == 0 && numUncommittableMessages == 0 && offsets.isEmpty(); }
[*] target: assertTrue(committableOffsets.isEmpty())
[-] pred: org. junit. Assert. assertTrue ( committableOffsets. isEmpty() )
************************************
************************************
[+] input: TimeoutException { RequestGrpc.RequestFutureStub stub = mockStub(new ServerCheckResponse(), null); doReturn(stub).when(grpcClient).createNewChannelStub(any(ManagedChannel.class)); Connection connection = grpcClient.connectToServer(serverInfo); "<AssertPlaceHolder>"; assertTrue(connection instanceof GrpcConnection); assertEquals(stub, ((GrpcConnection) connection).getGrpcFutureServiceStub()); }
connectToServer(ServerInfo serverInfo) { // the newest connection id String connectionId = ""; try { if (grpcExecutor == null) { this.grpcExecutor = createGrpcExecutor(serverInfo.getServerIp()); } int port = serverInfo.getServerPort() + rpcPortOffset(); ManagedChannel managedChannel = createNewManagedChannel(serverInfo.getServerIp(), port); RequestGrpc.RequestFutureStub newChannelStubTemp = createNewChannelStub(managedChannel);  Response response = serverCheck(serverInfo.getServerIp(), port, newChannelStubTemp); if (!(response instanceof ServerCheckResponse)) { shuntDownChannel(managedChannel); return null; } // submit ability table as soon as possible // ability table will be null if server doesn't support ability table ServerCheckResponse serverCheckResponse = (ServerCheckResponse) response; connectionId = serverCheckResponse.getConnectionId();  BiRequestStreamGrpc.BiRequestStreamStub biRequestStreamStub = BiRequestStreamGrpc .newStub(newChannelStubTemp.getChannel()); GrpcConnection grpcConn = new GrpcConnection(serverInfo, grpcExecutor); grpcConn.setConnectionId(connectionId); // if not supported, it will be false if (serverCheckResponse.isSupportAbilityNegotiation()) { // mark this.recAbilityContext.reset(grpcConn); // promise null if no abilities receive grpcConn.setAbilityTable(null); }  //create stream request and bind connection event to this connection. StreamObserver<Payload> payloadStreamObserver = bindRequestStream(biRequestStreamStub, grpcConn);  // stream observer to send response to server grpcConn.setPayloadStreamObserver(payloadStreamObserver); grpcConn.setGrpcFutureServiceStub(newChannelStubTemp); grpcConn.setChannel(managedChannel); //send a  setup request. ConnectionSetupRequest conSetupRequest = new ConnectionSetupRequest(); conSetupRequest.setClientVersion(VersionUtils.getFullClientVersion()); conSetupRequest.setLabels(super.getLabels()); // set ability table conSetupRequest .setAbilityTable(NacosAbilityManagerHolder.getInstance().getCurrentNodeAbilities(abilityMode())); conSetupRequest.setTenant(super.getTenant()); grpcConn.sendRequest(conSetupRequest); // wait for response if (recAbilityContext.isNeedToSync()) { // try to wait for notify response recAbilityContext.await(this.clientConfig.capabilityNegotiationTimeout(), TimeUnit.MILLISECONDS); // if no server abilities receiving, then reconnect if (!recAbilityContext.check(grpcConn)) { return null; } } else { // leave for adapting old version server // registration is considered successful by default after 100ms // wait to register connection setup Thread.sleep(100L); } return grpcConn; } catch (Exception e) { LOGGER.error("[{}]Fail to connect to server!,error={}", GrpcClient.this.getName(), e); // remove and notify recAbilityContext.release(null); } return null; }
[*] target: assertNotNull(connection)
[-] pred: org. junit. Assert. assertNotNull ( connection )
************************************
************************************
[+] input: testErrorThroughRpc() { final AtomicReference<Response> reference = new AtomicReference<>();  RpcContext context = new RpcContext() { @Override public void sendResponse(Object responseObj) { reference.set((Response) responseObj); }  @Override public Connection getConnection() { return null; }  @Override public String getRemoteAddress() { return null; } }; AbstractProcessor processor = new NacosWriteRequestProcessor(server, SerializeFactory.getDefault()); processor.execute(server, context, WriteRequest.newBuilder().build(), new JRaftServer.RaftGroupTuple());  Response response = reference.get(); Assert."<AssertPlaceHolder>";  Assert.assertEquals("Error message transmission", response.getErrMsg()); Assert.assertFalse(response.getSuccess()); }
execute(JRaftServer server, final RpcContext asyncCtx, final Message message, final JRaftServer.RaftGroupTuple tuple) { FailoverClosure closure = new FailoverClosure() {  Response data;  Throwable ex;  @Override public void setResponse(Response data) { this.data = data; }  @Override public void setThrowable(Throwable throwable) { this.ex = throwable; }  @Override public void run(Status status) { if (Objects.nonNull(ex)) { Loggers.RAFT.error("execute has error : ", ex); asyncCtx.sendResponse(Response.newBuilder().setErrMsg(ex.toString()).setSuccess(false).build()); } else { asyncCtx.sendResponse(data); } } };  server.applyOperation(tuple.getNode(), message, closure); }
[*] target: assertNotNull(response)
[-] pred: org. junit. Assert. assertNotNull ( response )
************************************
************************************
[+] input: testPeekAndPoll() { try { ClosableBlockingQueue<String> queue = new ClosableBlockingQueue<>();  assertNull(queue.peek()); assertNull(queue.peek()); assertNull(queue.poll()); assertNull(queue.poll());  assertEquals(0, queue.size());  queue.add("a"); queue.add("b"); queue.add("c");  assertEquals(3, queue.size());  assertEquals("a", queue.peek()); assertEquals("a", queue.peek()); assertEquals("a", queue.peek());  assertEquals(3, queue.size());  assertEquals("a", queue.poll()); assertEquals("b", queue.poll());  assertEquals(1, queue.size());  assertEquals("c", queue.peek()); assertEquals("c", queue.peek());  assertEquals("c", queue.poll());  assertEquals(0, queue.size()); "<AssertPlaceHolder>"; assertNull(queue.peek()); assertNull(queue.peek());  assertTrue(queue.close());  try { queue.peek(); fail("should cause an exception"); } catch (IllegalStateException ignored) { // expected }  try { queue.poll(); fail("should cause an exception"); } catch (IllegalStateException ignored) { // expected } } catch (Exception e) { e.printStackTrace(); fail(e.getMessage()); } }
poll() { lock.lock(); try { if (open) { if (elements.size() > 0) { return elements.removeFirst(); } else { return null; } } else { throw new IllegalStateException("queue is closed"); } } finally { lock.unlock(); } }
[*] target: assertNull(queue.poll())
[-] pred: org. junit. Assert. assertNull ( queue. poll ( ) )
************************************
************************************
[+] input: testToByteArray() { GeometryBuffer buffer = GeometryBufferFactory.create(bufferType, 2); buffer.putByte(0, (byte) 1); buffer.putByte(1, (byte) 2); byte[] bytes = buffer.toByteArray(); "<AssertPlaceHolder>"; assertEquals((byte) 1, bytes[0]); assertEquals((byte) 2, bytes[1]); }
toByteArray();
[*] target: assertEquals(2, bytes.length)
[-] pred: org. junit. Assert. assertEquals ( 2, bytes. length )
************************************
************************************
[+] input: JsonProcessingException { String json = "{"supportRemoteConnection":true,"grpcReportEnabled":true}"; ServerRemoteAbility abilities = mapper.readValue(json, ServerRemoteAbility.class); assertTrue(abilities.isSupportRemoteConnection()); "<AssertPlaceHolder>"; }
isGrpcReportEnabled() { return grpcReportEnabled; }
[*] target: assertTrue(abilities.isGrpcReportEnabled())
[-] pred: org. junit. Assert. assertTrue ( abilities. isGrpcReportEnabled() )
************************************
************************************
[+] input: testGetAllClientsSubscribeService() {  Collection<String> allClientsSubscribeService = clientServiceIndexesManager .getAllClientsSubscribeService(service);  Assert."<AssertPlaceHolder>"; Assert.assertEquals(allClientsSubscribeService.size(), 1); }
getAllClientsSubscribeService(Service service) { return subscriberIndexes.containsKey(service) ? subscriberIndexes.get(service) : new ConcurrentHashSet<>(); }
[*] target: assertNotNull(allClientsSubscribeService)
[-] pred: org. junit. Assert. assertNotNull ( allClientsSubscribeService )
************************************
************************************
[+] input: getSynonym_testPublicSynonymInfoForOracle() { DBSynonym synonym = accessor.getSynonym(getOracleSchema(), "PUBLIC_SYNONYM_ACCESSOR", DBSynonymType.PUBLIC); Assert."<AssertPlaceHolder>"; Assert.assertEquals(DBSynonymType.PUBLIC, synonym.getSynonymType()); Assert.assertEquals("PUBLIC_SYNONYM_ACCESSOR", synonym.getSynonymName()); }
getSynonym(String schemaName, String synonymName, DBSynonymType synonymType) { OracleSqlBuilder sb = new OracleSqlBuilder(); sb.append( "select s.OWNER,s.SYNONYM_NAME,s.TABLE_OWNER,s.TABLE_NAME,s.DB_LINK,o.CREATED,o.LAST_DDL_TIME,o.STATUS from "); sb.append(dataDictTableNames.SYNONYMS()); sb.append(" s left join (select * from "); sb.append(dataDictTableNames.OBJECTS()); sb.append(" where OBJECT_TYPE='SYNONYM') o on s.SYNONYM_NAME=o.OBJECT_NAME and s.OWNER=o.OWNER where s.OWNER="); sb.value(getSynonymOwnerSymbol(synonymType, schemaName)); sb.append(" and s.SYNONYM_NAME="); sb.value(synonymName);  DBSynonym synonym = new DBSynonym(); synonym.setSynonymType(synonymType); jdbcOperations.query(sb.toString(), rs -> { synonym.setOwner(rs.getString("OWNER")); synonym.setSynonymName(rs.getString("SYNONYM_NAME")); synonym.setTableOwner(rs.getString("TABLE_OWNER")); synonym.setTableName(rs.getString("TABLE_NAME")); synonym.setDbLink(rs.getString("DB_LINK")); synonym.setCreated(rs.getTimestamp("CREATED")); synonym.setLastDdlTime(rs.getTimestamp("LAST_DDL_TIME")); synonym.setStatus(rs.getString("STATUS")); }); synonym.setDdl(getSynonymDDL(synonym));  return synonym; }
[*] target: assertNotNull(synonym)
[-] pred: org. junit. Assert. assertNotNull ( synonym )
************************************
************************************
[+] input: test_messages_sent_on_connack_success() {  channel.writeInbound(new CONNECT.Mqtt3Builder().withProtocolVersion(ProtocolVersion.MQTTv3_1_1).withClientIdentifier("clientID").build());  channel.writeInbound(TestMessageUtil.createMqtt3Publish()); channel.writeInbound(new SUBSCRIBE(ImmutableList.of(), 1));  assertEquals(2, messageBarrier.getQueue().size());  final AtomicInteger counter = new AtomicInteger(0);  channel.pipeline().addAfter(MQTT_MESSAGE_BARRIER, "test", new ChannelDuplexHandler() {  @Override public void channelRead(final ChannelHandlerContext ctx, final Object msg) {  if (msg instanceof PUBLISH || msg instanceof SUBSCRIBE) { counter.incrementAndGet(); } } });  channel.writeOutbound(ConnackMessages.ACCEPTED_MSG_NO_SESS);  "<AssertPlaceHolder>"; assertFalse(channel.pipeline().names().contains(MQTT_MESSAGE_BARRIER)); }
channelRead(final @NotNull ChannelHandlerContext ctx, final @NotNull Object msg) {  if (msg instanceof Message) { if (msg instanceof CONNECT) { connectReceived = true; suspendRead(ctx.channel()); } else if (!connectReceived) { serverDisconnector.logAndClose(ctx.channel(), "A client (IP: {}) sent other message before CONNECT. Disconnecting client.", "Sent other message before CONNECT"); return; } else if (msg instanceof AUTH) { suspendRead(ctx.channel()); } else if (!connackSent) { messageQueue.add((Message) msg); return; } } ctx.fireChannelRead(msg); }
[*] target: assertEquals(2, counter.get())
[-] pred: org. junit. Assert. assertEquals ( 2, counter. get ( ) )
************************************
************************************
[+] input: testCreateOperatorProxy() { Crane4jTemplate.OpsForProxy ops = crane4jTemplate.opsForProxy(); TestOperatorProxy proxy = ops.createOperatorProxy(TestOperatorProxy.class); Assert."<AssertPlaceHolder>"; Foo foo = new Foo("1"); proxy.fill(foo); Assert.assertEquals("name" + foo.getId(), foo.getName()); }
createOperatorProxy(@NonNull Class<T> operator) { return operatorProxyFactory.get(operator); }
[*] target: assertNotNull(proxy)
[-] pred: org. junit. Assert. assertNotNull ( proxy )
************************************
************************************
[+] input: Exception { List<RevCommit> commits = new ArrayList<>(); Git git = Git.wrap(db);  writeTrashFile("Test.txt", "Hello world"); git.add().addFilepattern("Test.txt").call(); commits.add(git.commit().setMessage("initial commit").call());  git.branchCreate().setName("branch1").call(); Ref checkedOut = git.checkout().setName("branch1").call(); assertEquals("refs/heads/branch1", checkedOut.getName()); writeTrashFile("Test1.txt", "Hello world!"); git.add().addFilepattern("Test1.txt").call(); commits.add(git.commit().setMessage("branch1 commit").call());  checkedOut = git.checkout().setName("master").call(); assertEquals("refs/heads/master", checkedOut.getName()); writeTrashFile("Test2.txt", "Hello world!!"); git.add().addFilepattern("Test2.txt").call(); commits.add(git.commit().setMessage("branch1 commit").call());  Iterator<RevCommit> log = git.log().all().call().iterator(); "<AssertPlaceHolder>"; assertTrue(commits.contains(log.next())); assertTrue(log.hasNext()); assertTrue(commits.contains(log.next())); assertTrue(log.hasNext()); assertTrue(commits.contains(log.next())); assertFalse(log.hasNext()); }
call() throws GitAPIException, NoHeadException { checkCallable(); List<TreeFilter> filters = new ArrayList<>(); if (!pathFilters.isEmpty()) { filters.add(AndTreeFilter.create(PathFilterGroup.create(pathFilters), TreeFilter.ANY_DIFF)); } if (!excludeTreeFilters.isEmpty()) { for (TreeFilter f : excludeTreeFilters) { filters.add(AndTreeFilter.create(f, TreeFilter.ANY_DIFF)); } } if (!filters.isEmpty()) { if (filters.size() == 1) { filters.add(TreeFilter.ANY_DIFF); } walk.setTreeFilter(AndTreeFilter.create(filters));  } if (skip > -1 && maxCount > -1) walk.setRevFilter(AndRevFilter.create(SkipRevFilter.create(skip), MaxCountRevFilter.create(maxCount))); else if (skip > -1) walk.setRevFilter(SkipRevFilter.create(skip)); else if (maxCount > -1) walk.setRevFilter(MaxCountRevFilter.create(maxCount)); if (!startSpecified) { try { ObjectId headId = repo.resolve(Constants.HEAD); if (headId == null) throw new NoHeadException( JGitText.get().noHEADExistsAndNoExplicitStartingRevisionWasSpecified); add(headId); } catch (IOException e) { // all exceptions thrown by add() shouldn't occur and represent // severe low-level exception which are therefore wrapped throw new JGitInternalException( JGitText.get().anExceptionOccurredWhileTryingToAddTheIdOfHEAD, e); } }  if (this.revFilter != null) { walk.setRevFilter(this.revFilter); }  setCallable(false); return walk; }
[*] target: assertTrue(log.hasNext())
[-] pred: org. junit. Assert. assertTrue ( log. hasNext ( ) )
************************************
************************************
[+] input: Exception { CommitConfig cfg = parse("[core]\n\tcommentChar = auto\n"); assertEquals('#', cfg.getCommentChar()); "<AssertPlaceHolder>"; }
isAutoCommentChar() { return autoCommentChar; }
[*] target: assertTrue(cfg.isAutoCommentChar())
[-] pred: org. junit. Assert. assertTrue ( cfg. isAutoCommentChar ( ) )
************************************
************************************
[+] input: Exception { PowerMockito.whenNew(DefaultConnector.class).withAnyArguments().thenReturn(defaultConnector); Method methodGetObVersion = PowerMockito.method(ObConnectTemplate.class, "getObVersion"); PowerMockito.replace(methodGetObVersion).with((proxy, method, args) -> "2.4.0");  ObOperator operator = ObOperators.newObOperator(connectProperties.withCompatibilityMode(CompatibilityMode.MYSQL)); "<AssertPlaceHolder>"; assertNotNull(operator.cluster()); assertNotNull(operator.resource()); assertNotNull(operator.session()); assertNotNull(operator.stats()); assertNotNull(operator.tenant()); }
newObOperator(ConnectProperties connectProperties) { validate(connectProperties);  ObConnectTemplate obConnectTemplate = new ObConnectTemplate(connectProperties); return ObOperator.builder() .resourceOperator(newResourceOperator(obConnectTemplate)) .objectOperator(newObjectOperator(obConnectTemplate)) .clusterOperator(newClusterOperator(obConnectTemplate)) .parameterOperator(newParameterOperator(obConnectTemplate)) .sessionOperator(newSessionOperator(obConnectTemplate)) .statsOperator(newStatsOperator(obConnectTemplate)) .tenantOperator(newTenantOperator(obConnectTemplate)) .sqlTuningOperator(newSqlTuningOperator(obConnectTemplate)) .sqlExecuteOperator(newSqlExecuteOperator(obConnectTemplate)) .sqlAuditOperator(newSqlAuditOperator(obConnectTemplate)) .compactionOperator(newCompactionOperator(obConnectTemplate)) .sqlPlanOperator(newSqlPlanOperator(obConnectTemplate)) .sqlPlanExplainOperator(newSqlPlanExplainOperator(obConnectTemplate)) .build(); }
[*] target: assertNotNull(operator)
[-] pred: org. junit. Assert. assertNotNull ( operator )
************************************
************************************
[+] input: Exception { config("hOsT orcz\nConnectionAttempts 3\n"); final Host h = osc.lookup("orcz"); assertNotNull(h); "<AssertPlaceHolder>"; }
getConnectionAttempts() { return connectionAttempts; }
[*] target: assertEquals(3, h.getConnectionAttempts())
[-] pred: org. junit. Assert. assertEquals ( 3, h. getConnectionAttempts ( ) )
************************************
************************************
[+] input: shouldNotUseCommitFlagForHashcodeAndEquals() { final ProcessorMetadata metadata1 = new ProcessorMetadata(); metadata1.setNeedsCommit(true); final ProcessorMetadata metadata2 = new ProcessorMetadata(); metadata2.setNeedsCommit(false);  assertEquals(metadata1, metadata2); "<AssertPlaceHolder>"; }
hashCode() { // needsCommit is not considered in hashCode or equals return Objects.hashCode(metadata); }
[*] target: assertEquals(metadata1.hashCode(), metadata2.hashCode())
[-] pred: org. junit. Assert. assertEquals ( metadata1. hashCode(), metadata2. hashCode() )
************************************
************************************
[+] input: testLoadSnapshotOperate() { List<SnapshotOperation> snapshotOperations = serviceMetadataProcessor.loadSnapshotOperate();  Assert."<AssertPlaceHolder>"; Assert.assertEquals(snapshotOperations.size(), 1); }
loadSnapshotOperate() { return Collections.singletonList(new ServiceMetadataSnapshotOperation(namingMetadataManager, lock)); }
[*] target: assertNotNull(snapshotOperations)
[-] pred: org. junit. Assert. assertNotNull ( snapshotOperations )
************************************
************************************
[+] input: test_RAW() { String raw = RandomStringUtils.random(256); Encryption encryption = createEncryption(EncryptionAlgorithm.RAW); String encrypted = EncryptionUtil.encrypt(raw, encryption); Assert.assertEquals(raw, encrypted); String decrypted = EncryptionUtil.decrypt(encrypted, encryption); Assert."<AssertPlaceHolder>"; }
decrypt(String encryptedText, Encryption encryption) { return Objects.requireNonNull(encryptorCache.get(encryption)).decrypt(encryptedText); }
[*] target: assertEquals(raw, decrypted)
[-] pred: org. junit. Assert. assertEquals ( raw, decrypted )
************************************
************************************
[+] input: Exception { initCursor(ITEM_TYPE_APPLICATION, ""); assertTrue(mLoaderCursor.moveToNext());  ComponentName cn = new ComponentName(mContext.getPackageName(), "placeholder-do"); WorkspaceItemInfo info = Executors.MODEL_EXECUTOR.submit(() -> mLoaderCursor.getAppShortcutInfo( new Intent().setComponent(cn), true  /* allowMissingTarget */, true)) .get(); "<AssertPlaceHolder>"; assertTrue(PackageManagerHelper.isLauncherAppTarget(info.getIntent())); }
getAppShortcutInfo( Intent intent, boolean allowMissingTarget, boolean useLowResIcon) { return getAppShortcutInfo(intent, allowMissingTarget, useLowResIcon, true); }
[*] target: assertNotNull(info)
[-] pred: org. junit. Assert. assertNotNull ( info )
************************************
************************************
[+] input: testGetRemoteExecutorTimesOfProcessors() { int defaultExpectVal = 1 << 4; int defaultVal = RemoteUtils.getRemoteExecutorTimesOfProcessors(); Assert.assertEquals(defaultExpectVal, defaultVal);  System.setProperty("remote.executor.times.of.processors", "10"); int val1 = RemoteUtils.getRemoteExecutorTimesOfProcessors(); Assert.assertEquals(10, val1);  System.setProperty("remote.executor.times.of.processors", "-1"); int val2 = RemoteUtils.getRemoteExecutorTimesOfProcessors(); Assert."<AssertPlaceHolder>"; }
getRemoteExecutorTimesOfProcessors() { String timesString = System.getProperty("remote.executor.times.of.processors"); if (NumberUtils.isDigits(timesString)) { int times = Integer.parseInt(timesString); return times > 0 ? times : REMOTE_EXECUTOR_TIMES_OF_PROCESSORS; } else { return REMOTE_EXECUTOR_TIMES_OF_PROCESSORS; } }
[*] target: assertEquals(defaultExpectVal, val2)
[-] pred: org. junit. Assert. assertEquals ( defaultExpectVal, val2 )
************************************
************************************
[+] input: get() { List<Container<Object>> containers = factory.get(service, annotatedMethod, findAnnotations(annotatedMethod)); Container<Object> container = CollectionUtils.get(containers, 0); Assert.assertTrue(container instanceof CacheableContainer);  Object cachedA = container.get(Collections.singleton("a")).get("a"); Assert.assertNotNull(cachedA); Object a = container.get(Collections.singleton("a")).get("a"); Assert."<AssertPlaceHolder>"; }
get(@Nullable Object source, Method method, Collection<ContainerMethod> annotations) { log.debug("create cacheable method container from [{}]", method); ContainerCache annotation = annotationFinder.findAnnotation(method, ContainerCache.class); if (Objects.isNull(annotation)) { return super.get(source, method, annotations); } // wrap method container as cacheable container String managerName = StringUtils.emptyToDefault(annotation.cacheManager(), CacheManager.DEFAULT_MAP_CACHE_MANAGER_NAME); CacheManager cacheManager = configuration.getCacheManager(managerName); return super.get(source, method, annotations).stream() .map(container -> { CacheDefinition cacheDefinition = new CacheDefinition.Impl( container.getNamespace(), managerName, annotation.expirationTime(), annotation.timeUnit() ); return new CacheableContainer<>(container, cacheDefinition, cacheManager); }) .collect(Collectors.toList()); }
[*] target: assertSame(cachedA, a)
[-] pred: org. junit. Assert. assertSame ( cachedA, a )
************************************
************************************
[+] input: getConverter() { HutoolConverterManager hutoolConverterManager = new HutoolConverterManager(); // force cast object to collection hutoolConverterManager.getConverter(Object.class, Collection.class); @SuppressWarnings("rawtypes") BiFunction<Object, Collection, Collection> converter = hutoolConverterManager .getConverter(Object.class, Collection.class); Assert."<AssertPlaceHolder>";  Object obj = new Object(); Assert.assertEquals(CollectionUtils.newCollection(ArrayList::new, obj), converter.apply(obj, null)); Assert.assertEquals(converter.apply(Collections.singleton(obj), null), converter.apply(Collections.singleton(obj), null)); }
getConverter(Class<T> targetType, Class<R> resultType) { return (source, defaultValue) -> { if (resultType.isInstance(source)) { return (R)source; } return Convert.convert(resultType, source, defaultValue); }; }
[*] target: assertNotNull(converter)
[-] pred: org. junit. Assert. assertNotNull ( converter )
************************************
************************************
[+] input: shouldReturnSessionStore() { final GlobalStateStoreProvider provider = new GlobalStateStoreProvider(stores); final List<ReadOnlySessionStore<String, String>> stores = provider.stores("s-store", QueryableStoreTypes.sessionStore()); "<AssertPlaceHolder>"; for (final ReadOnlySessionStore<String, String> store : stores) { assertThat(store, instanceOf(ReadOnlySessionStore.class)); } }
stores(final String storeName, final QueryableStoreType<T> queryableStoreType) { final StateStore store = globalStateStores.get(storeName); if (store == null || !queryableStoreType.accepts(store)) { return Collections.emptyList(); } if (!store.isOpen()) { throw new InvalidStateStoreException("the state store, " + storeName + ", is not open."); } if (store instanceof TimestampedKeyValueStore && queryableStoreType instanceof QueryableStoreTypes.KeyValueStoreType) { return (List<T>) Collections.singletonList(new ReadOnlyKeyValueStoreFacade((TimestampedKeyValueStore<Object, Object>) store)); } else if (store instanceof TimestampedWindowStore && queryableStoreType instanceof QueryableStoreTypes.WindowStoreType) { return (List<T>) Collections.singletonList(new ReadOnlyWindowStoreFacade((TimestampedWindowStore<Object, Object>) store)); } return (List<T>) Collections.singletonList(store); }
[*] target: assertEquals(1, stores.size())
[-] pred: org. junit. Assert. assertEquals ( 1, stores. size ( ) )
************************************
************************************
[+] input: Exception { AtomicReference<Exception> testThreadException = new AtomicReference<>(); TestConvertingFutureCallback testCallback = new TestConvertingFutureCallback(); final Object expectedConversion = new Object(); executor.submit(() -> { try { testCallback.waitForGet(); testCallback.onCompletion(null, expectedConversion); } catch (Exception e) { testThreadException.compareAndSet(null, e); } }); assertFalse(testCallback.isDone()); "<AssertPlaceHolder>"; assertEquals(1, testCallback.numberOfConversions()); assertTrue(testCallback.isDone()); if (testThreadException.get() != null) { throw testThreadException.get(); } }
get() throws InterruptedException, ExecutionException { finishedLatch.await(); return result(); }
[*] target: assertEquals(expectedConversion, testCallback.get())
[-] pred: org. junit. Assert. assertEquals ( expectedConversion, testCallback. get() )
************************************
************************************
[+] input: Exception { PowerMockito.whenNew(DefaultConnector.class).withAnyArguments().thenReturn(defaultConnector); Method methodGetObVersion = PowerMockito.method(ObConnectTemplate.class, "getObVersion"); PowerMockito.replace(methodGetObVersion).with((proxy, method, args) -> "2.4.0");  ObAccessor accessor = ObAccessors.newObAccessor(connectProperties.withCompatibilityMode(CompatibilityMode.MYSQL)); "<AssertPlaceHolder>"; assertNotNull(accessor.session()); assertNotNull(accessor.variable()); assertNotNull(accessor.user()); assertNotNull(accessor.database()); }
newObAccessor(ConnectProperties connectProperties) { Validate.notNull(connectProperties, "The input connectProperties is null."); connectProperties.validate(); ObAccessor obAccessor = holder.get(connectProperties); if (obAccessor != null) { return obAccessor; }  ObConnectTemplate obConnectTemplate = new ObConnectTemplate(connectProperties); obAccessor = ObAccessor.builder() .infoAccessor(newInfoAccessor(obConnectTemplate)) .variableAccessor(newVariableAccessor(obConnectTemplate)) .parameterAccessor(newParameterAccessor(obConnectTemplate)) .userAccessor(newUserAccessor(obConnectTemplate)) .databaseAccessor(newDatabaseAccessor(obConnectTemplate)) .objectAccessor(newObjectAccessor(obConnectTemplate)) .sessionAccessor(newSessionAccessor(obConnectTemplate)) .sqlTuningAccessor(newSqlTuningAccessor(obConnectTemplate)) .build();  holder.put(connectProperties, obAccessor); return obAccessor; }
[*] target: assertNotNull(accessor)
[-] pred: org. junit. Assert. assertNotNull ( accessor )
************************************
************************************
[+] input: shouldReturnWindowStore() { final GlobalStateStoreProvider provider = new GlobalStateStoreProvider(stores); final List<ReadOnlyWindowStore<String, String>> stores = provider.stores("w-store", QueryableStoreTypes.windowStore()); "<AssertPlaceHolder>"; for (final ReadOnlyWindowStore<String, String> store : stores) { assertThat(store, instanceOf(ReadOnlyWindowStore.class)); assertThat(store, not(instanceOf(TimestampedWindowStore.class))); } }
stores(final String storeName, final QueryableStoreType<T> queryableStoreType) { final StateStore store = globalStateStores.get(storeName); if (store == null || !queryableStoreType.accepts(store)) { return Collections.emptyList(); } if (!store.isOpen()) { throw new InvalidStateStoreException("the state store, " + storeName + ", is not open."); } if (store instanceof TimestampedKeyValueStore && queryableStoreType instanceof QueryableStoreTypes.KeyValueStoreType) { return (List<T>) Collections.singletonList(new ReadOnlyKeyValueStoreFacade((TimestampedKeyValueStore<Object, Object>) store)); } else if (store instanceof TimestampedWindowStore && queryableStoreType instanceof QueryableStoreTypes.WindowStoreType) { return (List<T>) Collections.singletonList(new ReadOnlyWindowStoreFacade((TimestampedWindowStore<Object, Object>) store)); } return (List<T>) Collections.singletonList(store); }
[*] target: assertEquals(1, stores.size())
[-] pred: org. junit. Assert. assertEquals ( 1, stores. size ( ) )
************************************
************************************
[+] input: getTokens_justName_returnOneToken() { String dataTypeName = "Binary_float"; List<DataTypeToken> tokens = DataTypeParser.getTokens(dataTypeName); Assert."<AssertPlaceHolder>";  DataTypeToken token = tokens.get(0); Assert.assertEquals(dataTypeName, token.getText()); Assert.assertEquals(DataTypeToken.NAME_TYPE, token.getType()); }
getTokens(String content) { if (StringUtils.isBlank(content)) { return Collections.emptyList(); } int length = content.length(); List<DataTypeToken> tokens = new LinkedList<>(); int start = 0; boolean matches = false; for (int i = 1; i <= length; i++) { String text = content.substring(start, i); if (text.trim().length() == 0) { start = i; continue; } int type = getType(text); if (type == DataTypeToken.INVALID_TYPE && !matches) { tokens.add(getToken(content, start, i)); start = i; } else if (type != DataTypeToken.INVALID_TYPE) { matches = true; } else { i--; tokens.add(getToken(content, start, i)); start = i; matches = false; } } if (start < length) { String text = content.substring(start, length); if (text.trim().length() != 0) { tokens.add(getToken(content, start, length)); } } return tokens; }
[*] target: assertEquals(1, tokens.size())
[-] pred: org. junit. Assert. assertEquals ( 1, tokens. size ( ) )
************************************
************************************
[+] input: Exception { final DirCache tree0 = db.readDirCache(); final DirCache tree1 = db.readDirCache(); { final DirCacheBuilder b0 = tree0.builder(); final DirCacheBuilder b1 = tree1.builder();  b0.add(createEntry("a", REGULAR_FILE)); b1.add(createEntry("a.b", EXECUTABLE_FILE)); b1.add(createEntry("a/b", REGULAR_FILE)); b0.add(createEntry("a0b", SYMLINK)); b1.add(createEntry("a0b", SYMLINK));  b0.finish(); b1.finish(); assertEquals(2, tree0.getEntryCount()); assertEquals(3, tree1.getEntryCount()); }  try (NameConflictTreeWalk tw = new NameConflictTreeWalk(db)) { tw.addTree(new DirCacheIterator(tree0)); tw.addTree(new DirCacheIterator(tree1));  assertModes("a", REGULAR_FILE, TREE, tw); assertTrue(tw.isSubtree()); assertTrue(tw.isDirectoryFileConflict()); tw.enterSubtree(); assertModes("a/b", MISSING, REGULAR_FILE, tw); assertTrue(tw.isDirectoryFileConflict()); assertModes("a.b", MISSING, EXECUTABLE_FILE, tw); assertFalse(tw.isDirectoryFileConflict()); assertModes("a0b", SYMLINK, SYMLINK, tw); "<AssertPlaceHolder>"; } }
isDirectoryFileConflict() { return dfConflict != null; }
[*] target: assertFalse(tw.isDirectoryFileConflict())
[-] pred: org. junit. Assert. assertFalse ( tw. isDirectoryFileConflict() )
************************************
************************************
[+] input: testGetAllClientsRegisteredService() { Collection<String> allClientsRegisteredService = clientServiceIndexesManager .getAllClientsRegisteredService(service);  Assert."<AssertPlaceHolder>"; Assert.assertEquals(allClientsRegisteredService.size(), 1); }
getAllClientsRegisteredService(Service service) { return publisherIndexes.containsKey(service) ? publisherIndexes.get(service) : new ConcurrentHashSet<>(); }
[*] target: assertNotNull(allClientsRegisteredService)
[-] pred: org. junit. Assert. assertNotNull ( allClientsRegisteredService )
************************************
************************************
[+] input: testElementsWithNulls() { Record recordTemplate = GenericRecord.create(STRUCT_TYPE); Record record1 = recordTemplate.copy("id", 1, "data", null); Record record2 = recordTemplate.copy("id", 2, "data", null);  Set<StructLike> set = StructLikeSet.create(STRUCT_TYPE); set.add(record1); set.add(record2);  Assert.assertTrue(set.contains(record1)); Assert.assertTrue(set.contains(record2));  Record record3 = record1.copy(); Assert.assertTrue(set.contains(record3));  boolean removed = set.remove(record3); Assert."<AssertPlaceHolder>"; }
remove(Object obj) { if (obj instanceof StructLike || obj == null) { StructLikeWrapper wrapper = wrappers.get(); boolean result = wrapperSet.remove(wrapper.set((StructLike) obj)); wrapper.set(null); // don't hold a reference to the value return result; } return false; }
[*] target: assertTrue(removed)
[-] pred: org. junit. Assert. assertTrue ( removed )
************************************
************************************
[+] input: testNoRemoteRepository() { NoRemoteRepositoryException openFetchException = new NoRemoteRepositoryException( new URIish(), "not found"); IOException ioException = new IOException("not read");  try (FailingBasePackPushConnection fbppc = new FailingBasePackPushConnection(openFetchException)) { TransportException result = fbppc.noRepository(ioException);  "<AssertPlaceHolder>"; assertThat(Arrays.asList(result.getSuppressed()), hasItem(ioException)); } }
noRepository(Throwable cause) { // Sadly we cannot tell the "invalid URI" case from "push not allowed". // Opening a fetch connection can help us tell the difference, as any // useful repository is going to support fetch if it also would allow // push. So if fetch throws NoRemoteRepositoryException we know the // URI is wrong. Otherwise we can correctly state push isn't allowed // as the fetch connection opened successfully. // TransportException te; try { transport.openFetch().close(); te = new TransportException(uri, JGitText.get().pushNotPermitted); } catch (NoRemoteRepositoryException e) { // Fetch concluded the repository doesn't exist. te = e; } catch (NotSupportedException | TransportException e) { te = new TransportException(uri, JGitText.get().pushNotPermitted, e); } te.addSuppressed(cause); return te; }
[*] target: assertEquals(openFetchException, result)
[-] pred: org. junit. Assert. assertEquals ( openFetchException, result )
************************************
************************************
[+] input: testDefault() { DefaultGrpcClientConfig config = (DefaultGrpcClientConfig) DefaultGrpcClientConfig.newBuilder().build(); assertNull(config.name()); assertEquals(3, config.retryTimes()); assertEquals(3000L, config.timeOutMills()); assertEquals(5000L, config.connectionKeepAlive()); assertEquals(10000L, config.threadPoolKeepAlive()); assertEquals(4, config.threadPoolCoreSize()); assertEquals(16, config.threadPoolMaxSize()); assertEquals(3000L, config.serverCheckTimeOut()); assertEquals(10000, config.threadPoolQueueSize()); assertEquals(10 * 1024 * 1024, config.maxInboundMessageSize()); assertEquals(6 * 60 * 1000, config.channelKeepAlive()); assertEquals(TimeUnit.SECONDS.toMillis(20L), config.channelKeepAliveTimeout()); assertEquals(3, config.healthCheckRetryTimes()); assertEquals(3000L, config.healthCheckTimeOut()); assertEquals(5000L, config.capabilityNegotiationTimeout()); assertEquals(1, config.labels().size()); "<AssertPlaceHolder>"; }
tlsConfig() { return tlsConfig; }
[*] target: assertNotNull(config.tlsConfig())
[-] pred: org. junit. Assert. assertNotNull ( config. tlsConfig() )
************************************
************************************
[+] input: test_fail_code() { output.authorizerPresent(); output.failAuthorization(AckReasonCode.TOPIC_NAME_INVALID); task.onSuccess(output);  channel.runPendingTasks();  final AuthorizeWillResultEvent resultEvent = eventsCollector.pollEvent(); "<AssertPlaceHolder>"; assertEquals(AckReasonCode.TOPIC_NAME_INVALID, resultEvent.getResult().getAckReasonCode()); assertEquals( "Not allowed to connect with Will Publish for unauthorized topic 'topic' with QoS '2' and retain 'false'", resultEvent.getResult().getReasonString()); }
onSuccess(@Nullable final PublishAuthorizerOutputImpl output) { if (output == null) { //this does not happen return; }  DisconnectReasonCode disconnectReasonCode = null; AckReasonCode reasonCode = null; String reasonString = null;  switch (output.getAuthorizationState()) { case DISCONNECT: disconnectReasonCode = output.getDisconnectReasonCode(); reasonCode = output.getAckReasonCode() != null ? output.getAckReasonCode() : AckReasonCode.NOT_AUTHORIZED; reasonString = output.getReasonString() != null ? output.getReasonString() : getReasonString(connect); break; case FAIL: reasonCode = output.getAckReasonCode() != null ? output.getAckReasonCode() : AckReasonCode.NOT_AUTHORIZED; reasonString = output.getReasonString() != null ? output.getReasonString() : getReasonString(connect); break; case UNDECIDED: if (!output.isAuthorizerPresent()) { //providers never returned an authorizer, same as continue break; } reasonCode = AckReasonCode.NOT_AUTHORIZED; reasonString = getReasonString(connect); break; case SUCCESS: reasonCode = AckReasonCode.SUCCESS; break; case CONTINUE: break; default: //no state left throw new IllegalStateException("Unknown type"); }  final PublishAuthorizerResult result = new PublishAuthorizerResult(reasonCode, reasonString, output.isAuthorizerPresent(), disconnectReasonCode); ctx.pipeline().fireUserEventTriggered(new PluginAuthorizerServiceImpl.AuthorizeWillResultEvent(connect, result)); }
[*] target: assertNotNull(resultEvent)
[-] pred: org. junit. Assert. assertNotNull ( resultEvent )
************************************
************************************
[+] input: test_fail_code_string() { output.authorizerPresent(); output.failAuthorization(AckReasonCode.TOPIC_NAME_INVALID, "test-string"); task.onSuccess(output);  channel.runPendingTasks();  final AuthorizeWillResultEvent resultEvent = eventsCollector.pollEvent(); "<AssertPlaceHolder>"; assertEquals(AckReasonCode.TOPIC_NAME_INVALID, resultEvent.getResult().getAckReasonCode()); assertEquals("test-string", resultEvent.getResult().getReasonString()); }
onSuccess(@Nullable final PublishAuthorizerOutputImpl output) { if (output == null) { //this does not happen return; }  DisconnectReasonCode disconnectReasonCode = null; AckReasonCode reasonCode = null; String reasonString = null;  switch (output.getAuthorizationState()) { case DISCONNECT: disconnectReasonCode = output.getDisconnectReasonCode(); reasonCode = output.getAckReasonCode() != null ? output.getAckReasonCode() : AckReasonCode.NOT_AUTHORIZED; reasonString = output.getReasonString() != null ? output.getReasonString() : getReasonString(connect); break; case FAIL: reasonCode = output.getAckReasonCode() != null ? output.getAckReasonCode() : AckReasonCode.NOT_AUTHORIZED; reasonString = output.getReasonString() != null ? output.getReasonString() : getReasonString(connect); break; case UNDECIDED: if (!output.isAuthorizerPresent()) { //providers never returned an authorizer, same as continue break; } reasonCode = AckReasonCode.NOT_AUTHORIZED; reasonString = getReasonString(connect); break; case SUCCESS: reasonCode = AckReasonCode.SUCCESS; break; case CONTINUE: break; default: //no state left throw new IllegalStateException("Unknown type"); }  final PublishAuthorizerResult result = new PublishAuthorizerResult(reasonCode, reasonString, output.isAuthorizerPresent(), disconnectReasonCode); ctx.pipeline().fireUserEventTriggered(new PluginAuthorizerServiceImpl.AuthorizeWillResultEvent(connect, result)); }
[*] target: assertNotNull(resultEvent)
[-] pred: org. junit. Assert. assertNotNull ( resultEvent )
************************************
************************************
[+] input: IllegalAccessException { HttpClientFactory factory = new AbstractApacheHttpClientFactory() { @Override protected HttpClientConfig buildHttpClientConfig() { return HttpClientConfig.builder().build(); }  @Override protected Logger assignLogger() { return logger; } }; NacosRestTemplate template = factory.createNacosRestTemplate(); "<AssertPlaceHolder>"; Field field = NacosRestTemplate.class.getDeclaredField("requestClient"); field.setAccessible(true); HttpClientRequest requestClient = (HttpClientRequest) field.get(template); assertTrue(requestClient instanceof DefaultHttpClientRequest); }
createNacosRestTemplate() { final HttpClientConfig originalRequestConfig = buildHttpClientConfig(); final RequestConfig defaultConfig = getRequestConfig(); return new NacosRestTemplate(assignLogger(), new DefaultHttpClientRequest( HttpClients.custom() .addInterceptorLast(new RequestContent(true)) .setDefaultRequestConfig(defaultConfig) .setUserAgent(originalRequestConfig.getUserAgent()) .setMaxConnTotal(originalRequestConfig.getMaxConnTotal()) .setMaxConnPerRoute(originalRequestConfig.getMaxConnPerRoute()) .setConnectionTimeToLive(originalRequestConfig.getConnTimeToLive(), originalRequestConfig.getConnTimeToLiveTimeUnit()).build(), defaultConfig)); }
[*] target: assertNotNull(template)
[-] pred: org. junit. Assert. assertNotNull ( template )
************************************
************************************
[+] input: shouldInstantiateAndConfigureExplicitlySetHeaderConverterWithCurrentClassLoader() { assertNotNull(props.get(WorkerConfig.HEADER_CONVERTER_CLASS_CONFIG)); HeaderConverter headerConverter = plugins.newHeaderConverter(config, WorkerConfig.HEADER_CONVERTER_CLASS_CONFIG, ClassLoaderUsage.CURRENT_CLASSLOADER); assertNotNull(headerConverter); assertInstanceOf(TestHeaderConverter.class, headerConverter); this.headerConverter = (TestHeaderConverter) headerConverter;  // Validate extra configs got passed through to overridden converters assertConverterType(ConverterType.HEADER, this.headerConverter.configs); assertEquals("baz", this.headerConverter.configs.get("extra.config"));  headerConverter = plugins.newHeaderConverter(config, WorkerConfig.HEADER_CONVERTER_CLASS_CONFIG, ClassLoaderUsage.PLUGINS); "<AssertPlaceHolder>"; assertInstanceOf(TestHeaderConverter.class, headerConverter); this.headerConverter = (TestHeaderConverter) headerConverter;  // Validate extra configs got passed through to overridden converters assertConverterType(ConverterType.HEADER, this.headerConverter.configs); assertEquals("baz", this.headerConverter.configs.get("extra.config")); }
newHeaderConverter(AbstractConfig config, String classPropertyName, ClassLoaderUsage classLoaderUsage) { Class<? extends HeaderConverter> klass = null; switch (classLoaderUsage) { case CURRENT_CLASSLOADER: if (!config.originals().containsKey(classPropertyName)) { // This connector configuration does not define the header converter via the specified property name return null; } // Attempt to load first with the current classloader, and plugins as a fallback. // Note: we can't use config.getConfiguredInstance because we have to remove the property prefixes // before calling config(...) klass = pluginClassFromConfig(config, classPropertyName, HeaderConverter.class, scanResult.headerConverters()); break; case PLUGINS: // Attempt to load with the plugin class loader, which uses the current classloader as a fallback. // Note that there will always be at least a default header converter for the worker String converterClassOrAlias = config.getClass(classPropertyName).getName(); try { klass = pluginClass( delegatingLoader, converterClassOrAlias, HeaderConverter.class ); } catch (ClassNotFoundException e) { throw new ConnectException( "Failed to find any class that implements HeaderConverter and which name matches " + converterClassOrAlias + ", available header converters are: " + pluginNames(scanResult.headerConverters()) ); } } if (klass == null) { throw new ConnectException("Unable to initialize the HeaderConverter specified in '" + classPropertyName + "'"); }  String configPrefix = classPropertyName + "."; Map<String, Object> converterConfig = config.originalsWithPrefix(configPrefix); converterConfig.put(ConverterConfig.TYPE_CONFIG, ConverterType.HEADER.getName()); log.debug("Configuring the header converter with configuration keys:{}{}", System.lineSeparator(), converterConfig.keySet());  HeaderConverter plugin; try (LoaderSwap loaderSwap = withClassLoader(klass.getClassLoader())) { plugin = newPlugin(klass); plugin.configure(converterConfig); } return plugin; }
[*] target: assertNotNull(headerConverter)
[-] pred: org. junit. Assert. assertNotNull ( headerConverter )
************************************
************************************
[+] input: test_get_tls_with_everything() {  clientConnection.setAuthCipherSuite("cipher"); clientConnection.setAuthProtocol("TLSv1.2"); clientConnection.setAuthSniHostname("test.hostname.domain");  final SslClientCertificate clientCertificate = Mockito.mock(SslClientCertificate.class);  clientConnection.setAuthCertificate(clientCertificate);  final X509Certificate[] chain = new X509Certificate[3]; chain[0] = new TestCert(); chain[1] = new TestCert(); chain[2] = new TestCert();  final TestCert testCert = new TestCert();  when(clientCertificate.certificate()).thenReturn(testCert); when(clientCertificate.certificateChain()).thenReturn(chain);  final ClientTlsInformation clientTlsInformation = ExtensionInformationUtil.getTlsInformationFromChannel(channel); "<AssertPlaceHolder>"; assertEquals("cipher", clientTlsInformation.getCipherSuite()); assertEquals("TLSv1.2", clientTlsInformation.getProtocol()); assertTrue(clientTlsInformation.getHostname().isPresent()); assertEquals("test.hostname.domain", clientTlsInformation.getHostname().get()); assertTrue(clientTlsInformation.getClientCertificate().isPresent()); assertNotNull(((TlsInformation) clientTlsInformation).getCertificate()); assertNotNull(((TlsInformation) clientTlsInformation).getCertificateChain()); }
getTlsInformationFromChannel(final @NotNull Channel channel) {  Preconditions.checkNotNull(channel, "channel must never be null");  final ClientConnection clientConnection = channel.attr(ClientConnection.CHANNEL_ATTRIBUTE_NAME).get(); try { final String cipher = clientConnection.getAuthCipherSuite(); final String protocol = clientConnection.getAuthProtocol(); final String sniHostname = clientConnection.getAuthSniHostname();  final SslClientCertificate sslClientCertificate = clientConnection.getAuthCertificate();  if (cipher == null || protocol == null) { return null; }  if (sslClientCertificate == null) { return new ClientTlsInformationImpl(null, null, cipher, protocol, sniHostname);  } else { final X509Certificate certificate = (X509Certificate) sslClientCertificate.certificate(); final X509Certificate[] certificateChain = (X509Certificate[]) sslClientCertificate.certificateChain();  return new ClientTlsInformationImpl(certificate, certificateChain, cipher, protocol, sniHostname); }  } catch (final Exception e) { log.debug("Tls information creation failed: ", e); }  return null; }
[*] target: assertNotNull(clientTlsInformation)
[-] pred: org. junit. Assert. assertNotNull ( clientTlsInformation )
************************************
************************************
[+] input: setReasonString_null() { final PubrelPacketImpl packet = new PubrelPacketImpl( 1, PubrelReasonCode.SUCCESS, "reason", UserPropertiesImpl.of(ImmutableList.of())); final ModifiablePubrelPacketImpl modifiablePacket = new ModifiablePubrelPacketImpl(packet, configurationService);  assertFalse(modifiablePacket.isModified());  modifiablePacket.setReasonString(null);  assertEquals(Optional.empty(), modifiablePacket.getReasonString()); "<AssertPlaceHolder>"; }
isModified() { return modified || userProperties.isModified(); }
[*] target: assertTrue(modifiablePacket.isModified())
[-] pred: org. junit. Assert. assertTrue ( modifiablePacket. isModified() )
************************************
************************************
[+] input: IOException { String dataId = "testDataIdBeta"; String group = "testGroup"; String tenant = "testTenant"; String content = "testContentBeta你好" + System.currentTimeMillis(); long time = System.currentTimeMillis(); ConfigInfoBetaWrapper configInfoWrapper = new ConfigInfoBetaWrapper(); configInfoWrapper.setDataId(dataId); configInfoWrapper.setGroup(group); configInfoWrapper.setTenant(tenant); configInfoWrapper.setContent(content); configInfoWrapper.setLastModified(time); String betaIps = "127.0.0.1123,127.0.0.11"; configInfoWrapper.setBetaIps(betaIps);  Mockito.when(configInfoBetaPersistService.findConfigInfo4Beta(eq(dataId), eq(group), eq(tenant))) .thenReturn(configInfoWrapper);  String handlerIp = "127.0.0.1"; long lastModified = System.currentTimeMillis(); DumpTask dumpTask = new DumpTask(GroupKey2.getKey(dataId, group, tenant), true, false, false, null, lastModified, handlerIp); boolean process = dumpProcessor.process(dumpTask); Assert.assertTrue(process);  //Check cache CacheItem contentCache = ConfigCacheService.getContentCache(GroupKey2.getKey(dataId, group, tenant)); Assert.assertEquals(MD5Utils.md5Hex(content, "UTF-8"), contentCache.getConfigCacheBeta().getMd5Utf8()); Assert.assertEquals(time, contentCache.getConfigCacheBeta().getLastModifiedTs()); Assert.assertTrue(contentCache.ips4Beta.containsAll(Arrays.asList(betaIps.split(",")))); //check disk String contentFromDisk = ConfigDiskServiceFactory.getInstance().getBetaContent(dataId, group, tenant); Assert.assertEquals(content, contentFromDisk);  // remove Mockito.when(configInfoBetaPersistService.findConfigInfo4Beta(eq(dataId), eq(group), eq(tenant))) .thenReturn(null); boolean processRemove = dumpProcessor.process(dumpTask); Assert."<AssertPlaceHolder>";  //Check cache CacheItem contentCacheAfterRemove = ConfigCacheService.getContentCache(GroupKey2.getKey(dataId, group, tenant)); Assert.assertTrue(contentCacheAfterRemove == null || contentCacheAfterRemove.getConfigCacheBeta() == null); //check disk String contentFromDiskAfterRemove = ConfigDiskServiceFactory.getInstance() .getBetaContent(dataId, group, tenant); Assert.assertNull(contentFromDiskAfterRemove);  }
process(NacosTask task) { DumpTask dumpTask = (DumpTask) task; String[] pair = GroupKey2.parseKey(dumpTask.getGroupKey()); String dataId = pair[0]; String group = pair[1]; String tenant = pair[2]; long lastModifiedOut = dumpTask.getLastModified(); String handleIp = dumpTask.getHandleIp(); boolean isBeta = dumpTask.isBeta(); String tag = dumpTask.getTag(); ConfigDumpEvent.ConfigDumpEventBuilder build = ConfigDumpEvent.builder().namespaceId(tenant).dataId(dataId) .group(group).isBeta(isBeta).tag(tag).handleIp(handleIp); String type = "formal"; if (isBeta) { type = "beta"; } else if (StringUtils.isNotBlank(tag)) { type = "tag-" + tag; } LogUtil.DUMP_LOG.info("[dump] process {} task. groupKey={}", type, dumpTask.getGroupKey());  if (isBeta) { // if publish beta, then dump config, update beta cache ConfigInfoBetaWrapper cf = configInfoBetaPersistService.findConfigInfo4Beta(dataId, group, tenant); build.remove(Objects.isNull(cf)); build.betaIps(Objects.isNull(cf) ? null : cf.getBetaIps()); build.content(Objects.isNull(cf) ? null : cf.getContent()); build.type(Objects.isNull(cf) ? null : cf.getType()); build.encryptedDataKey(Objects.isNull(cf) ? null : cf.getEncryptedDataKey()); build.lastModifiedTs(Objects.isNull(cf) ? lastModifiedOut : cf.getLastModified()); return DumpConfigHandler.configDump(build.build()); }  if (StringUtils.isNotBlank(tag)) { ConfigInfoTagWrapper cf = configInfoTagPersistService.findConfigInfo4Tag(dataId, group, tenant, tag); build.remove(Objects.isNull(cf)); build.content(Objects.isNull(cf) ? null : cf.getContent()); build.type(Objects.isNull(cf) ? null : cf.getType()); build.encryptedDataKey(Objects.isNull(cf) ? null : cf.getEncryptedDataKey()); build.lastModifiedTs(Objects.isNull(cf) ? lastModifiedOut : cf.getLastModified()); return DumpConfigHandler.configDump(build.build()); }  ConfigInfoWrapper cf = configInfoPersistService.findConfigInfo(dataId, group, tenant); build.remove(Objects.isNull(cf)); build.content(Objects.isNull(cf) ? null : cf.getContent()); build.type(Objects.isNull(cf) ? null : cf.getType()); build.encryptedDataKey(Objects.isNull(cf) ? null : cf.getEncryptedDataKey()); build.lastModifiedTs(Objects.isNull(cf) ? lastModifiedOut : cf.getLastModified()); return DumpConfigHandler.configDump(build.build());  }
[*] target: assertTrue(processRemove)
[-] pred: org. junit. Assert. assertTrue ( processRemove )
************************************
************************************
[+] input: test_constructMqtt5_withUserProperties() { final Mqtt5UserProperties userProperties = Mqtt5UserProperties.of( new MqttUserProperty("user1", "value1"), new MqttUserProperty("user2", "value2"), new MqttUserProperty("user3", "value3"));  final PUBACK origin = new PUBACK(1, Mqtt5PubAckReasonCode.NOT_AUTHORIZED, "NotAuthorized", userProperties); final PubackPacketImpl packet = new PubackPacketImpl(origin);  final PUBACK merged = PUBACK.from(packet);  "<AssertPlaceHolder>"; assertNotSame(origin, merged); assertPUBACKequals(origin, merged); }
from(final @NotNull PubackPacketImpl packet) { return new PUBACK( packet.getPacketIdentifier(), Mqtt5PubAckReasonCode.from(packet.getReasonCode()), packet.getReasonString().orElse(null), Mqtt5UserProperties.of(packet.getUserProperties().asInternalList())); }
[*] target: assertNotNull(merged)
[-] pred: org. junit. Assert. assertNotNull ( merged )
************************************
************************************
[+] input: testTaskOps() { List<TaskModel> tasks = new LinkedList<>(); String workflowId = UUID.randomUUID().toString();  for (int i = 0; i < 3; i++) { TaskModel task = new TaskModel(); task.setScheduledTime(1L); task.setSeq(1); task.setTaskId(workflowId + "_t" + i); task.setReferenceTaskName("testTaskOps" + i); task.setRetryCount(0); task.setWorkflowInstanceId(workflowId); task.setTaskDefName("testTaskOps" + i); task.setStatus(TaskModel.Status.IN_PROGRESS); tasks.add(task); }  for (int i = 0; i < 3; i++) { TaskModel task = new TaskModel(); task.setScheduledTime(1L); task.setSeq(1); task.setTaskId("x" + workflowId + "_t" + i); task.setReferenceTaskName("testTaskOps" + i); task.setRetryCount(0); task.setWorkflowInstanceId("x" + workflowId); task.setTaskDefName("testTaskOps" + i); task.setStatus(TaskModel.Status.IN_PROGRESS); getExecutionDAO().createTasks(Collections.singletonList(task)); }  List<TaskModel> created = getExecutionDAO().createTasks(tasks); assertEquals(tasks.size(), created.size());  List<TaskModel> pending = getExecutionDAO().getPendingTasksForTaskType(tasks.get(0).getTaskDefName()); assertNotNull(pending); assertEquals(2, pending.size()); // Pending list can come in any order.  finding the one we are looking for and then // comparing TaskModel matching = pending.stream() .filter(task -> task.getTaskId().equals(tasks.get(0).getTaskId())) .findAny() .get(); assertTrue(EqualsBuilder.reflectionEquals(matching, tasks.get(0)));  for (int i = 0; i < 3; i++) { TaskModel found = getExecutionDAO().getTask(workflowId + "_t" + i); assertNotNull(found); found.getOutputData().put("updated", true); found.setStatus(TaskModel.Status.COMPLETED); getExecutionDAO().updateTask(found); }  List<String> taskIds = tasks.stream().map(TaskModel::getTaskId).collect(Collectors.toList()); List<TaskModel> found = getExecutionDAO().getTasks(taskIds); assertEquals(taskIds.size(), found.size()); found.forEach( task -> { assertTrue(task.getOutputData().containsKey("updated")); assertEquals(true, task.getOutputData().get("updated")); boolean removed = getExecutionDAO().removeTask(task.getTaskId()); assertTrue(removed); });  found = getExecutionDAO().getTasks(taskIds); "<AssertPlaceHolder>"; }
getTasks(List<String> taskIds);
[*] target: assertTrue(found.isEmpty())
[-] pred: org. junit. Assert. assertTrue ( found. isEmpty ( ) )
************************************
************************************
[+] input: getClaims_getJwtLoad_succeed() { Map<String, Object> map = new HashMap<>(); map.put("userId", 123); map.put("username", "testUser"); String token = jwtService.sign(map); Map<String, Claim> claims = jwtService.getClaims(token); Assert."<AssertPlaceHolder>"; Assert.assertEquals(new Integer(123), claims.get("userId").asInt()); Assert.assertEquals("testUser", claims.get("username").asString()); }
getClaims(String token) { Algorithm algorithm = Algorithm.HMAC256(jwtProperties.getTokenSecret()); JWTVerifier verifier = JWT.require(algorithm).build(); return verifier.verify(token).getClaims(); }
[*] target: assertNotNull(claims)
[-] pred: org. junit. Assert. assertNotNull ( claims )
************************************
************************************
[+] input: Exception { Collection<ReflogEntry> reflog = git.reflog().call(); "<AssertPlaceHolder>"; assertEquals(3, reflog.size()); ReflogEntry[] reflogs = reflog.toArray(new ReflogEntry[0]); assertEquals(reflogs[2].getComment(), "commit (initial): Initial commit"); assertEquals(reflogs[2].getNewId(), commit1.getId()); assertEquals(reflogs[2].getOldId(), ObjectId.zeroId()); assertEquals(reflogs[1].getComment(), "checkout: moving from master to b1"); assertEquals(reflogs[1].getNewId(), commit1.getId()); assertEquals(reflogs[1].getOldId(), commit1.getId()); assertEquals(reflogs[0].getComment(), "commit: Removed file"); assertEquals(reflogs[0].getNewId(), commit2.getId()); assertEquals(reflogs[0].getOldId(), commit1.getId()); }
call() throws GitAPIException, InvalidRefNameException { checkCallable();  try { ReflogReader reader = repo.getReflogReader(ref); if (reader == null) throw new RefNotFoundException(MessageFormat.format( JGitText.get().refNotResolved, ref)); return reader.getReverseEntries(); } catch (IOException e) { throw new InvalidRefNameException(MessageFormat.format( JGitText.get().cannotRead, ref), e); } }
[*] target: assertNotNull(reflog)
[-] pred: org. junit. Assert. assertNotNull ( reflog )
